Here is an overview of the entire project for your context:

Phase 0:

M0 - environment_foundation

**Purpose:**

Lock in the actual environment & runtimes.

- Define:

- MC 1.7.10 + Forge 10.13.4.1614 + GTNH 2.8.1 run profile

- Decision: external bot client vs in-process Forge mod with IPC

- Hardware constraints for local LLMs

- **Dependencies:** None

- **Difficulty:** ⭐

- **Scalability notes:**

- Document this in a single config file / README; future changes (new model, new server host) should not touch code.

M1 - agent_architecture_spec

**Purpose:**  
Unify Mineflayer + Voyager insights into a **single architecture spec**.

- Extract from Mineflayer:
    
    - Bot lifecycle
        
    - World model
        
    - Pathfinding
        
    - Action abstraction
        
- Extract from Voyager:
    
    - Planner → Skill library → Execution loop
        
    - Reflection & learning
        
- **Dependencies:** `M0`
    
- **Difficulty:** ⭐⭐
    
- **Scalability notes:**
    
    - Produce one canonical architecture doc: diagrams + interfaces.
        
    - This is the contract everything else conforms to.


Phase 1

M2 - llm_stack_local

**Purpose:**  
Provide reusable interfaces around local models.

- Implement:
    
    - `PlannerModel`: high-level plan generation
        
    - `CodeModel`: skill/code generation
        
    - `CriticModel`: evaluation / refinement
        
- Unified tool schema:
    
    - Input: structured state / goal
        
    - Output: JSON plan / skill spec, no direct MC calls
        
- **Dependencies:** `M1`
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Centralize model loading & caching.
        
    - Make batch calls possible.
        
    - Log prompts/responses for replay.

M3 - world_semantics_gtnh

**Purpose:**  
Define GTNH tech + world understanding as **data + logic**.

- Data layer (config files):
    
    - Block categories (ores, machines, cables, etc.)
        
    - Item categories (plates, circuits, tools)
        
    - Tech states & prereqs (LV steam, MV, etc.)
        
- Logic layer (Python):
    
    - `infer_tech_state(inventory, machines)`
        
    - `suggest_next_targets(tech_state)`
        
    - `craftable_items(inventory, known_recipes)`
        
- **Dependencies:** `M1`
    
- **Difficulty:** ⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Keep recipes & categories in JSON/YAML, not code.
        
    - Cache derived graphs (like tech dependency DAGs).

M4 - virtue_lattice

**Purpose:**  
Encapsulate your Sefirot-based virtues as a reusable scoring layer.

- Define:
    
    - Virtue nodes: Efficiency, Safety, Sustainability, etc.
        
    - Configurable weights per context (e.g., early LV vs late HV)
        
- APIs:
    
    - `score_plan(plan, context) -> dict[virtue -> score]`
        
    - `compare_plans(plans, context) -> best_plan`
        
- **Dependencies:** `M3` (for context & environment semantics)
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Pure functions, stateless, easy to unit test.
        
    - Configurable weights → you can tune without code changes.

M5 - skill_registry

**Purpose:**  
Central place for skill definitions and metadata.

- Skill spec:
    
    - Name, parameters
        
    - Preconditions (what world/tech state is required)
        
    - Effects (changes in world/tech state)
        
    - Tags (e.g., mining, crafting, building)
        
- LLM interaction:
    
    - Planner only sees skill metadata, not raw code.
        
    - Skill implementations live as Python methods or small scripts.
        
- **Dependencies:** `M1`, `M3`
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Skills registered via decorators or config files.
        
    - Easy to version and deprecate skills over time.

Phase 2:

M6 - bot_core_1_7_10

**Purpose:**  
Provide a stable, testable “body” that can be used by any controller.

- Capabilities:
    
    - Connect/keepalive
        
    - World tracking (chunks, entities)
        
    - Navigation (A* or similar)
        
    - Actions:
        
        - Move, jump, break block, place block, use item, interact with tile entities
            
- API:
    
    - `observe() -> RawWorldSnapshot`
        
    - `execute_action(Action) -> Result`
        
- **Dependencies:** `M0`, `M1`
    
- **Difficulty:** ⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Keep logic modular: pathfinding, inventory, world tracking as submodules.
        
    - Limit unnecessary packet decoding; cache what you can.

M7 - observation_encoding

**Purpose:**  
Map `RawWorldSnapshot` from `M6` into semantic state used by LLMs & planners.

- Functions:
    
    - `encode_for_planner(raw_snapshot, tech_state) -> JSON`
        
    - `encode_for_critic(trace) -> JSON`
        
- Uses:
    
    - `M3` (semantics)
        
    - `M4` (virtues context)
        
- **Dependencies:** `M3`, `M6`
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Keep encodings compact. Summaries + key entities, not entire chunks.
        
    - Enforce stable schema to avoid breaking old skills.

Phase 3:

M8 - agent_loop_v1

**Purpose:**  
Implement the core loop: observe → plan → choose skills → act → evaluate.

- High-level algorithm:
    
    1. `state = observe()`
        
    2. `tech_state = infer_tech_state(state)`
        
    3. `plan = planner_model.call(state, tech_state, skill_registry, virtues)`
        
    4. Decompose plan into skill invocations
        
    5. Execute via `bot_core_1_7_10`
        
    6. Log result for learning (`M10`)
        
- Strict separation:
    
    - No direct packet calls here.
        
    - No GTNH-hardcoded weirdness here; that lives in `M3` and `M5`.
        
- **Dependencies:**
    
    - `M2` (LLM stack)
        
    - `M3` (world semantics)
        
    - `M4` (virtues)
        
    - `M5` (skills)
        
    - `M6` (bot core)
        
    - `M7` (observation encoding)
        
- **Difficulty:** ⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Design as a state machine with clear states (Idle, Planning, Executing, Recovering).
        
    - Rate-limit LLM calls, reuse plans until invalidated.

M9 - monitoring_and_tools

**Purpose:**  
Give you observability and a control surface before the system gaslights you.

- Features:
    
    - Structured logs (JSON)
        
    - Web or TUI dashboard:
        
        - World overview
            
        - Current plan & skills
            
        - Virtue scores
            
        - Tech state
            
    - Manual controls:
        
        - Pause, step, cancel plan, inspect memory
            
- **Dependencies:** `M8`
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Central logger used by all modules.
        
    - Minimal UI first; upgrade visuals later.


Phase 4:

M10 - skill_learning

**Purpose:**  
Voyager-style learning: derive new skills from experience and refine existing ones.

- Components:
    
    - Experience buffer:
        
        - `{state, goal, plan, actions, outcomes, virtue_scores}`
            
    - LLM-based synthesizer:
        
        - Turn repeated success traces into new skill definitions
            
    - Evaluator:
        
        - Compare new vs existing skills on:
            
            - Success rate
                
            - Cost (time, resources)
                
            - Virtue scores
                
- **Dependencies:** `M8` (loop), `M2` (LLMs), `M5` (skill registry), `M4` (virtue scoring)
    
- **Difficulty:** ⭐⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Learning should be offline or scheduled, not constant.
        
    - Skills versioned and can be rolled back if regressions appear.


M11 - gtnh_curriculum_and_specialization

**Purpose:**  
Turn the generic learning agent into a **GTNH-native progression engine**.

- Define:
    
    - Curricula per phase:
        
        - Early LV goals
            
        - Steam infra goals
            
        - MV automation goals
            
    - Long-horizon projects:
        
        - Stargate, high-tier reactors, etc.
            
- The curriculum is:
    
    - A sequence of target tech states
        
    - Each with:
        
        - Reward shaping (virtue weight tweaks)
            
        - Suggested skills to prioritize / learn
            
- **Dependencies:** `M3`, `M5`, `M8`, `M10`
    
- **Difficulty:** ⭐⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Curriculum is config, not code.
        
    - Multiple curricula can be swapped (e.g. “eco base”, “speedrun”, “aesthetic build”).


Shortcut View:
# **Phase P0 — Foundations**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M0**|environment_foundation|⭐|0.5–2 days|Lock runtime, modpack, IPC choice|
|**M1**|agent_architecture_spec|⭐⭐|2–4 days|Full architecture doc|

### **Phase P0 Total:**

**Difficulty Avg:** ⭐⭐  
**Time:** ~3–6 days

---

# **Phase P1 — Offline Core Pillars (No Minecraft)**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M2**|llm_stack_local|⭐⭐–⭐⭐⭐|3–7 days|Local models, prompt tooling|
|**M3**|world_semantics_gtnh|⭐⭐⭐⭐|7–14 days|Tech tree + ontology mapping|
|**M4**|virtue_lattice|⭐⭐–⭐⭐⭐|3–6 days|Scoring/weights system|
|**M5**|skill_registry|⭐⭐–⭐⭐⭐|3–6 days|Skill definitions, metadata|

### **Phase P1 Total:**

**Difficulty Avg:** ⭐⭐⭐  
**Time:** ~2–4 weeks

---

# **Phase P2 — Minecraft Integration Layer**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M6**|bot_core_1_7_10|⭐⭐⭐⭐|2–4 weeks|Pathfinding, inventory, world tracking|
|**M7**|observation_encoding|⭐⭐–⭐⭐⭐|3–7 days|Convert raw MC data → semantic state|

### **Phase P2 Total:**

**Difficulty Avg:** ⭐⭐⭐⭐  
**Time:** ~3–5 weeks

---

# **Phase P3 — Agent Orchestration & Tooling**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M8**|agent_loop_v1|⭐⭐⭐⭐|1–2 weeks|Full observe → plan → act|
|**M9**|monitoring_and_tools|⭐⭐–⭐⭐⭐|3–7 days|Logs, dashboards, step controls|

### **Phase P3 Total:**

**Difficulty Avg:** ⭐⭐⭐⭐  
**Time:** ~2–3 weeks

---

# **Phase P4 — Learning & Specialization**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M10**|skill_learning|⭐⭐⭐⭐⭐|2–4 weeks|Voyager-style skill synthesis|
|**M11**|gtnh_curriculum_and_specialization|⭐⭐⭐⭐⭐|multi-week ongoing|Long-horizon GTNH progression logic|

### **Phase P4 Total:**

**Difficulty Avg:** ⭐⭐⭐⭐⭐  
**Time:** ~4–8+ weeks (ongoing beyond initial build)

---

# **Grand Totals (First-Pass Implementation)**

|Phase|Difficulty Avg|Total Time|
|---|---|---|
|**P0**|⭐⭐|3–6 days|
|**P1**|⭐⭐⭐|2–4 weeks|
|**P2**|⭐⭐⭐⭐|3–5 weeks|
|**P3**|⭐⭐⭐⭐|2–3 weeks|
|**P4**|⭐⭐⭐⭐⭐|4–8+ weeks|

---

# **Overall Estimate**

**Minimum:** ~11 weeks  
**Expected:** ~14–18 weeks  
**Ambitious agent with learning + GTNH specialization:** ~20–30 weeks ongoing refinement


File Structure:


```
GTNH_Agent/                                   # Root of the GTNH agent project (package + scripts + configs)
├── bootstrap_structure.py                    # One-shot scaffolding script to create the base project layout & stub files
├── config/                                   # All declarative config: env profiles, models, skills, tech graph, virtues, etc.
│   ├── curricula/                            # High-level progression “paths” / curricula for the agent
│   │   ├── aesthetic_megabase.yaml           # Curriculum focused on pretty megabase building goals
│   │   ├── default_speedrun.yaml             # Curriculum for efficient tech / progression speedrun goals
│   │   └── eco_factory.yaml                  # Curriculum for sustainable / eco-style factory goals
│   ├── env.yaml                              # Top-level environment profiles (dev/prod, bot_mode, active model profile)
│   ├── gtnh_blocks.yaml                      # Canonical block definitions / tags for GTNH (names, categories, maybe metadata)
│   ├── gtnh_items.yaml                       # Canonical item definitions / tags for GTNH (materials, parts, consumables)
│   ├── gtnh_recipes.json                     # Crafting / processing recipes dataset for GTNH (input/output graph)
│   ├── gtnh_tech_graph.yaml                  # Tech progression graph: unlock dependencies, tiers, milestones
│   ├── hardware.yaml                         # Host hardware + backend tuning knobs (GPU, threads, etc.) per profile
│   ├── llm_roles.yaml                        # System / role prompts and LLM personas for different stack components
│   ├── minecraft.yaml                        # Minecraft / server config: version, world, IPC/mod settings
│   ├── models.yaml                           # Logical model profiles: paths, backend, context length, n_gpu_layers, etc.
│   ├── skills/                               # YAML skill specs the LLM uses to reason about available actions
│   │   ├── chop_tree.yaml                    # Spec for “chop_tree” skill: params, description, constraints
│   │   ├── feed_coke_ovens.yaml              # Spec for “feed_coke_ovens” skill
│   │   └── plant_sapling.yaml                # Spec for “plant_sapling” skill
│   ├── skills_candidates/                    # Staging area for draft / experimental skill definitions (currently empty)
│   ├── tools/                                # Small standalone config tools
│   │   ├── print_env.py                      # CLI helper to print resolved EnvProfile for debugging
│   │   └── validate_env.py                   # Schema / consistency validator for env+models+hardware YAML
│   └── virtues.yaml                          # Declarative definition of virtue lattice: weights, names, dimensions
├── docs/
│   └── architecture.md                       # Human-readable architecture overview & design notes
├── .github/
│   └── workflows/
│       └── ci.yml                            # CI pipeline: lint/tests/whatever runs on push/PR
├── .gitignore                                # Git ignore rules (venv, cache, etc.)
├── logs/
│   └── llm/                                  # JSON logs from LLM stack runs (per component / call)
│       ├── 20251127T154508_30389_error_model_analyze_failure.json  # Error model run log (failure case)
│       ├── 20251127T154508_30389_plan_code_plan.json               # PlanCodeModel planning log
│       ├── 20251127T154508_30389_scribe_summarize_trace.json       # Scribe summarization log for trace
│       ├── 20251127T154653_30421_plan_code_plan.json               # Additional plan_code run log
│       ├── 20251127T154929_30485_error_model_analyze_failure.json  # Another error_model failure log
│       ├── 20251127T155054_30542_scribe_summarize_trace.json       # Another scribe log
│       ├── 20251127T171641_54578_plan_code_plan.json               # More planning logs (timestamped)
│       ├── 20251127T172238_54966_plan_code_plan.json
│       ├── 20251127T172404_55071_plan_code_plan.json
│       ├── 20251127T181107_57121_plan_code_plan.json
│       └── 20251127T181432_57416_plan_code_plan.json
├── pyproject.toml                            # Project metadata: package name, deps, tooling (pytest, ruff, etc.)
├── .pytest_cache/                            # Pytest internal cache (can be nuked anytime)
│   ├── CACHEDIR.TAG
│   ├── .gitignore
│   ├── README.md
│   └── v/
│       └── cache/
│           ├── lastfailed                    # Which tests failed last run
│           └── nodeids                       # Internal mapping of collected tests
├── .python-version                           # Pyenv version pin for this project (Python 3.x selection)
├── README.md                                 # Top-level project description, usage, status
├── scripts/                                  # Manual entrypoints / demos / smoke tests
│   ├── demo_offline_agent_step.py           # Replay a single offline agent step (no live Minecraft) for debugging
│   ├── dev_shell.py                         # Developer shell: quick stack harness for ad-hoc LLM / planning calls
│   ├── smoke_error_model.py                 # Simple script to exercise ErrorModel on fake or real traces
│   ├── smoke_llm_stack.py                   # Smoke + perf harness for LLMStack (plan_code etc.)
│   └── smoke_scribe_model.py                # Smoke test for Scribe summarization / trace compression
├── src/                                      # All actual library code
│   ├── agent_loop/
│   │   ├── __init__.py                      # Package marker, exports for agent_loop
│   │   ├── loop.py                          # Main agent loop orchestration (plan → act → observe cycle)
│   │   ├── schema.py                        # Pydantic/dataclass schemas for agent loop inputs/outputs
│   │   └── state.py                         # Agent state representation across timesteps / episodes
│   ├── app/
│   │   ├── __init__.py
│   │   └── runtime.py                       # Top-level runtime wiring: env, stack, bot_core, monitoring bootstrap
│   ├── bot_core/
│   │   ├── actions.py                       # Primitive actions exposed by the bot (move, place, break, etc.)
│   │   ├── core.py                          # Bot high-level control: tick loop, dispatch, basic behavior glue
│   │   ├── __init__.py
│   │   ├── nav/
│   │   │   ├── grid.py                      # Navigation grid / voxel representation for pathfinding
│   │   │   ├── __init__.py
│   │   │   ├── mover.py                     # Movement executor: follow paths, handle jumps, micro-moves
│   │   │   └── pathfinder.py                # Pathfinding algorithms (A*, cost heuristics, etc.)
│   │   ├── net/
│   │   │   ├── client.py                    # Minecraft client / protocol bridge into the game
│   │   │   ├── __init__.py
│   │   │   └── ipc.py                       # IPC abstraction (e.g. between Python agent and Forge mod / proxy)
│   │   ├── snapshot.py                      # World snapshot extraction from bot/client into structured form
│   │   └── world_tracker.py                 # Tracks world state over time (blocks, entities, deltas)
│   ├── curriculum/
│   │   ├── engine.py                        # Curriculum engine: picks next tasks/goals from YAML curricula
│   │   ├── __init__.py
│   │   ├── loader.py                        # Load & validate curriculum configs from config/curricula
│   │   └── schema.py                        # Schemas for curriculum definitions
│   ├── env/
│   │   ├── __init__.py
│   │   ├── loader.py                        # Reads env.yaml, hardware.yaml, models.yaml → EnvProfile object
│   │   └── schema.py                        # EnvProfile and related config schemas
│   ├── __init__.py                          # Top-level src package marker (exports if needed)
│   ├── learning/
│   │   ├── buffer.py                        # Experience buffer / replay store
│   │   ├── evaluator.py                     # Evaluation routines for learned policies/skills
│   │   ├── __init__.py
│   │   ├── manager.py                       # Learning lifecycle manager: triggers training, updates policies
│   │   ├── schema.py                        # Schemas for experiences, metrics, training configs
│   │   └── synthesizer.py                   # Synthesizes new tasks/experiences from traces or curricula
│   ├── llm_stack/
│   │   ├── backend_llamacpp.py              # llama.cpp-powered backend implementation (local GGUF models)
│   │   ├── backend.py                       # Abstract backend interface (generate, chat, config)
│   │   ├── codegen.py                       # Turn plans / specs into code snippets (skills, scripts, etc.)
│   │   ├── config.py                        # ModelConfig, ModelProfile, stack config helpers
│   │   ├── critic.py                        # Critic model wrapper: score plans / actions / traces
│   │   ├── error_model.py                   # ErrorModel wrapper: analyze failures & propose corrections
│   │   ├── __init__.py                      # Expose LLMStack & key helpers
│   │   ├── json_utils.py                    # Robust JSON coercion / partial recovery from messy LLM output
│   │   ├── log_files.py                     # File-based logging helpers for LLM calls (to logs/llm/)
│   │   ├── plan_code.py                     # PlanCodeModel: plan JSON + code-generation pipeline
│   │   ├── planner.py                       # Planning-only model wrapper (structured plans without code)
│   │   ├── presets.py                       # Prompt / parameter presets for different LLM roles
│   │   ├── schema.py                        # Schemas for prompts, responses, stack configs
│   │   ├── scribe.py                        # Scribe model interface: summarization and trace compression
│   │   └── stack.py                         # Orchestrator composing planner, codegen, critic, scribe, error_model
│   ├── monitoring/
│   │   ├── bus.py                           # Event bus for monitoring / logging signals
│   │   ├── controller.py                    # Central monitor controller: subscriptions, routing
│   │   ├── dashboard_tui.py                 # Terminal UI dashboard for live agent stats
│   │   ├── events.py                        # Event types and schemas (LLM calls, actions, errors, etc.)
│   │   ├── __init__.py
│   │   └── logger.py                        # Logging bridge into files / console / structured logs
│   ├── observation/
│   │   ├── encoder.py                       # Convert raw bot_core snapshots into Observation objects
│   │   ├── __init__.py
│   │   ├── schema.py                        # Observation, TechState, and related schema definitions
│   │   └── trace_schema.py                  # Schema for full episode traces / timelines
│   ├── semantics/
│   │   ├── categorize.py                    # Semantic tagging: map blocks/items to categories / roles
│   │   ├── crafting.py                      # Crafting-specific semantic helpers around gtnh_recipes
│   │   ├── __init__.py
│   │   ├── loader.py                        # Load GTNH semantic datasets (blocks/items/tech_graph/recipes)
│   │   ├── schema.py                        # Schemas for semantic datasets
│   │   └── tech_state.py                    # Compute current tech state from world / inventory / unlocks
│   ├── skills/
│   │   ├── base/
│   │   │   ├── chop_tree.py                 # Concrete implementation of chop_tree skill
│   │   │   ├── feed_coke_ovens.py           # Concrete implementation of feed_coke_ovens skill
│   │   │   └── __init__.py
│   │   ├── __init__.py
│   │   ├── registry.py                      # Skill registry: maps skill names → callable implementations
│   │   └── schema.py                        # Skill metadata / parameter schema definitions
│   ├── spec/
│   │   ├── agent_loop.py                    # Spec types for agent_loop API surfaces
│   │   ├── bot_core.py                      # Spec types for bot_core behavior / contracts
│   │   ├── experience.py                    # Spec types for learning experiences
│   │   ├── __init__.py
│   │   ├── llm.py                           # Spec types for LLM requests/responses
│   │   ├── skills.py                        # Spec types for skill definitions / calls
│   │   └── types.py                         # Core shared types (Observation, Plan, etc.)
│   └── virtues/
│       ├── __init__.py
│       ├── lattice.py                       # Computation on the virtue lattice (score, combine, compare)
│       ├── loader.py                        # Load virtues.yaml into in-memory lattice structures
│       ├── metrics.py                       # Metrics derived from virtue scores (alignment, tradeoffs)
│       └── schema.py                        # Schemas for virtues, dimensions, weights
└── tests/                                    # Test suite for all layers
    ├── conftest.py                           # Pytest fixtures/shared setup for tests
    ├── fakes/                                # Fake implementations used for unit tests
    │   ├── fake_bot_core.py                  # Fake bot_core for tests without Minecraft
    │   ├── fake_llm_stack.py                 # Fake LLMStack backend for deterministic tests
    │   ├── fake_skills.py                    # Fake skills for isolated skill/loop testing
    │   └── __init__.py
    ├── __init__.py
    ├── test_agent_loop_v1.py                 # Tests for agent_loop (planning/acting integration)
    ├── test_architecture_integration.py      # High-level “does the wiring hold together” integration test
    ├── test_env_loader.py                    # Tests for env.loader (env/models/hardware YAML loading & validation)
    ├── test_error_model_with_fake_backend.py # ErrorModel behavior using fake backend
    ├── test_llm_stack_fake_backend.py        # LLMStack orchestration using fake backend
    ├── test_observation_critic_encoding.py   # Encoding path from observation → critic model inputs
    ├── test_observation_planner_encoding.py  # Encoding path from observation → planner model inputs
    ├── test_phase0_runtime.py                # Phase 0 runtime smoke/integration tests
    └── test_scribe_model_with_fake_backend.py# Scribe behavior using fake backend

```

# **GTNH_AGENT: PROJECT SUMMARY & KNOWLEDGE CAPSULE**

_(Phase 0 Completion + Early Phase 1 Validation)_  
Version: 2025-11-27

---

# **1. High-Level State of the Project**

You have:

- A **fully bootstrapped, production-grade project skeleton.**
    
- A clean, validated **YAML-driven configuration system** (env, hardware, models, skills, tech graph, virtues).
    
- A functioning **LLMStack** that can:
    
    - Load **local GGUF models via llama.cpp**
        
    - Generate **structured plans**
        
    - Produce **JSON plan outputs** even from chaotic models
        
    - Log every call into `logs/llm/`
        
- A **working perf harness** (`smoke_llm_stack.py --perf`) producing ~52 tok/s on a 14B model.
    
- A **full test suite** for:
    
    - Env loader
        
    - Planner encoding
        
    - Critic encoding
        
    - Error model
        
    - Scribe
        
    - Agent loop scaffolding
        
    - Fake backend behavior
        
- A fully modular **directory structure** scaled for future online agent operation.
    

Phase 0 is not “done.”  
Phase 0 is **obliterated** and its atoms used as pigment to paint the beginning of Phase 1.

---

# **2. Core Definitions (Long-Term Reference)**

### **EnvProfile**

Declarative bundle of:

- Minecraft runtime context
    
- Bot mode
    
- Active model profile
    
- Hardware settings  
    Used to decide:
    
- Backend (llama-cpp / vLLM / OpenAI wrapper)
    
- Model paths
    
- Context length
    
- GPU offload config
    

### **LLMStack**

Composite of:

- Planner → JSON plan
    
- Codegen → skill code or scaffolding
    
- Critic → rank / reject plans
    
- Scribe → summarize traces
    
- Error Model → diagnose failures
    

Everything logs JSON traces under `logs/llm/`.

### **Skill Specs (YAML)**

Formal definitions that the planner uses:

- Name
    
- Description
    
- Params
    
- Preconditions / constraints (soon)
    
- Action shape
    

These map directly into `src/skills/base/*.py`.

### **Virtue Lattice**

Aesthetic/ethical scoring structure.  
Represents:

- Dimensions of evaluation
    
- Weights
    
- How to combine virtues
    
- How to score plan quality or agent integrity
    

Acts like a **moral + functional compass** for plan ranking.

### **Curriculum Engine**

Reads high-level goals:

- Speedrun
    
- Eco factory
    
- Megabase aesthetic  
    Turns them into intermediate **tasks** as structural scaffolding for agent learning.
    

### **Semantics Layer**

Loads:

- GTNH blocks
    
- GTNH items
    
- GTNH recipes
    
- GTNH tech graph  
    Provides:
    
- Category tagging
    
- Crafting inference
    
- Tech state computation
    

This is the agent’s “world model.”

---

# **3. Technical Insights Gained (the gold)**

### **Backend architecture**

- llama.cpp Python wheels take forever to build because you’re basically compiling a baby GPU-powered deity.
    
- Avoid `model_path=` kwargs mismatch with backend signature.
    
- GPU offload behavior is extremely strict; hardware config must match.
    

### **Performance Tuning**

- n_gpu_layers is sanity gas.
    
- 14B Qwen at Q5_K on a 5070 gets ~50 tok/s in planning mode.
    
- Context length matters; don’t ask a 131k context model to run at 131k.
    

### **JSON Recovery**

LLMStack’s JSON coercion layer is mandatory because LLMs:

- hallucinate
    
- forget braces
    
- pretend commas are optional
    
- sprinkle Unicode where ASCII belongs
    

Your error model + recovery logic already works.

### **Testing Strategy Win**

Using:

- fake backend,
    
- fake skills,
    
- fake bot core
    

…lets you test orchestration without booting Minecraft or touching GPU.

### **Project Layout Discipline**

The whole project is now:

- Declarative first
    
- Modular second
    
- LLM-agnostic
    
- Future-proof
    

You set yourself up for “swap backend, no rewrite” architecture.

---

# **4. What’s Working Right Now**

- `env.loader` is airtight and validated.
    
- `LLMStack.plan_code` runs end-to-end with real local models.
    
- CPU offload issues have been resolved.
    
- `smoke_llm_stack.py --perf` gives accurate timing and performance numbers.
    
- Logging is perfect and each LLM call is captured.
    
- Project structure is readable, stable, and ready for real code.

---

# **5. What’s Next (Phase 1 Roadmap)**

_This is the actionable part._

## **A. Data Layer Build-Out (Config First)**

You need to finish building the semantic foundation as _declarative data_, not code.  
Everything here lives in `config/`.

### **Block Categories**

-  Define canonical block types used in GTNH:
    
    - `gt_machine`
        
    - `ore`
        
    - `fluid_tank`
        
    - `cable`
        
    - `multiblock_part`
        
    - `decoration`
        
    - etc.
        

### **Item Categories**

-  Define item classes used by crafting logic:
    
    - `ingot`, `dust`, `plate`
        
    - `circuit_lv`, `circuit_mv`, …
        
    - `tool`
        
    - `component`
        
    - etc.
        

### **Tech Graph**

-  Encode GTNH tech progression:
    
    - LV Steam → LV Electric → MV → HV → EV → IV → LuV → ZPM → UV → UH → MAX
        
-  For each tier, define:
    
    - Required machines
        
    - Required capabilities
        
    - Required materials
        
    - Unlock effects
        

### **Recipe DB (already present)**

-  Extend or clean `gtnh_recipes.json` if needed
    
-  Ensure recipe format matches what M3 logic expects
    

---

## **B. Logic Layer (Python)**

Everything here lives under `src/semantics/`.

### **Tech State Inference**

-  Implement:
Python:
```
infer_tech_state(inventory, machines) -> TechState

```
- Determines "where the player is" in GTNH tech.
    

### **Craftability**

-  Implement:
Python:
```
craftable_items(inventory, known_recipes, machines) -> list[str]

```
- Returns all items the agent could craft _right now_.
    

### **Next Targets**

-  Implement:
Python:
```
suggest_next_targets(tech_state) -> list[NextMilestone]

```
- Picks meaningful GTNH goals from the tech graph:
    
    - First LV steam setup
        
    - First macerator
        
    - First LV circuits
        
    - First MV power
        
    - etc.
        

### **Categorization Helpers**

-  Functions to map items/blocks → semantic categories:
Python:
```
categorize_item(item_id) -> category
categorize_block(block_id) -> category

```

---

## **C. Integration Points**

These are quick stubs you'll also need inside M3:

### **Loaders**

-  Implement `config/` loaders for:
    
    - items
        
    - blocks
        
    - recipes
        
    - tech graph
        

### **Schema**

-  Write Pydantic/dataclass schemas for:
    
    - `ItemCategory`
        
    - `BlockCategory`
        
    - `TechState`
        
    - `Recipe`
        
    - `TechGraphNode`
        

---

## **D. Tests for M3**

Yes, you test this layer heavily because it’s deterministic and pure.

-  Test category lookup
    
-  Test recipe loading
    
-  Test tech-state inference
    
-  Test next-target suggestions
    
-  Test craftability logic
    

No mocks needed except fake inventories.

---

## **E. Scope Boundaries (things M3 DOES NOT include)**

So you don’t drift:

- No LLM calls
    
- No planning
    
- No curriculum selection
    
- No learning
    
- No agent loop execution
    
- No Minecraft snapshots
    

This is **pure semantics**.  
Pure data + pure logic.  
A hermit module.

---

## **TL;DR of What’s Next**

You’re building the agent’s **semantic brain**:  
the part that actually understands GTNH as a structured system rather than a pile of names and NBT.

This is the part that turns “I see a machine” into:  
“that's an LV Bronze Blast Furnace, which means we are in early LV steam with access to wrought iron but not steel automation, and the next upgrade target is MV circuits.”

The actual intelligence starts here.

---

# **6. Long-Term Direction**

Everything you’ve built so far pushes you toward:

- Deterministic planning
    
- Semantic awareness grounded in GTNH data
    
- Moral/virtue-guided task selection
    
- Eventually a **persistent agent** with memory + learning
    

Phase 2 is where the real bot wakes up.

---