Here is an overview of the entire project for your context:

Phase 0:

M0 - environment_foundation

**Purpose:**

Lock in the actual environment & runtimes.

- Define:

- MC 1.7.10 + Forge 10.13.4.1614 + GTNH 2.8.1 run profile

- Decision: external bot client vs in-process Forge mod with IPC

- Hardware constraints for local LLMs

- **Dependencies:** None

- **Difficulty:** ⭐

- **Scalability notes:**

- Document this in a single config file / README; future changes (new model, new server host) should not touch code.

M1 - agent_architecture_spec

**Purpose:**  
Unify Mineflayer + Voyager insights into a **single architecture spec**.

- Extract from Mineflayer:
    
    - Bot lifecycle
        
    - World model
        
    - Pathfinding
        
    - Action abstraction
        
- Extract from Voyager:
    
    - Planner → Skill library → Execution loop
        
    - Reflection & learning
        
- **Dependencies:** `M0`
    
- **Difficulty:** ⭐⭐
    
- **Scalability notes:**
    
    - Produce one canonical architecture doc: diagrams + interfaces.
        
    - This is the contract everything else conforms to.


Phase 1

M2 - llm_stack_local

**Purpose:**  
Provide reusable interfaces around local models.

- Implement:
    
    - `PlannerModel`: high-level plan generation
        
    - `CodeModel`: skill/code generation
        
    - `CriticModel`: evaluation / refinement
        
- Unified tool schema:
    
    - Input: structured state / goal
        
    - Output: JSON plan / skill spec, no direct MC calls
        
- **Dependencies:** `M1`
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Centralize model loading & caching.
        
    - Make batch calls possible.
        
    - Log prompts/responses for replay.

M3 - world_semantics_gtnh

**Purpose:**  
Define GTNH tech + world understanding as **data + logic**.

- Data layer (config files):
    
    - Block categories (ores, machines, cables, etc.)
        
    - Item categories (plates, circuits, tools)
        
    - Tech states & prereqs (LV steam, MV, etc.)
        
- Logic layer (Python):
    
    - `infer_tech_state(inventory, machines)`
        
    - `suggest_next_targets(tech_state)`
        
    - `craftable_items(inventory, known_recipes)`
        
- **Dependencies:** `M1`
    
- **Difficulty:** ⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Keep recipes & categories in JSON/YAML, not code.
        
    - Cache derived graphs (like tech dependency DAGs).

M4 - virtue_lattice

**Purpose:**  
Encapsulate your Sefirot-based virtues as a reusable scoring layer.

- Define:
    
    - Virtue nodes: Efficiency, Safety, Sustainability, etc.
        
    - Configurable weights per context (e.g., early LV vs late HV)
        
- APIs:
    
    - `score_plan(plan, context) -> dict[virtue -> score]`
        
    - `compare_plans(plans, context) -> best_plan`
        
- **Dependencies:** `M3` (for context & environment semantics)
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Pure functions, stateless, easy to unit test.
        
    - Configurable weights → you can tune without code changes.

M5 - skill_registry

**Purpose:**  
Central place for skill definitions and metadata.

- Skill spec:
    
    - Name, parameters
        
    - Preconditions (what world/tech state is required)
        
    - Effects (changes in world/tech state)
        
    - Tags (e.g., mining, crafting, building)
        
- LLM interaction:
    
    - Planner only sees skill metadata, not raw code.
        
    - Skill implementations live as Python methods or small scripts.
        
- **Dependencies:** `M1`, `M3`
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Skills registered via decorators or config files.
        
    - Easy to version and deprecate skills over time.

Phase 2:

M6 - bot_core_1_7_10

**Purpose:**  
Provide a stable, testable “body” that can be used by any controller.

- Capabilities:
    
    - Connect/keepalive
        
    - World tracking (chunks, entities)
        
    - Navigation (A* or similar)
        
    - Actions:
        
        - Move, jump, break block, place block, use item, interact with tile entities
            
- API:
    
    - `observe() -> RawWorldSnapshot`
        
    - `execute_action(Action) -> Result`
        
- **Dependencies:** `M0`, `M1`
    
- **Difficulty:** ⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Keep logic modular: pathfinding, inventory, world tracking as submodules.
        
    - Limit unnecessary packet decoding; cache what you can.

M7 - observation_encoding

**Purpose:**  
Map `RawWorldSnapshot` from `M6` into semantic state used by LLMs & planners.

- Functions:
    
    - `encode_for_planner(raw_snapshot, tech_state) -> JSON`
        
    - `encode_for_critic(trace) -> JSON`
        
- Uses:
    
    - `M3` (semantics)
        
    - `M4` (virtues context)
        
- **Dependencies:** `M3`, `M6`
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Keep encodings compact. Summaries + key entities, not entire chunks.
        
    - Enforce stable schema to avoid breaking old skills.

Phase 3:

M8 - agent_loop_v1

**Purpose:**  
Implement the core loop: observe → plan → choose skills → act → evaluate.

- High-level algorithm:
    
    1. `state = observe()`
        
    2. `tech_state = infer_tech_state(state)`
        
    3. `plan = planner_model.call(state, tech_state, skill_registry, virtues)`
        
    4. Decompose plan into skill invocations
        
    5. Execute via `bot_core_1_7_10`
        
    6. Log result for learning (`M10`)
        
- Strict separation:
    
    - No direct packet calls here.
        
    - No GTNH-hardcoded weirdness here; that lives in `M3` and `M5`.
        
- **Dependencies:**
    
    - `M2` (LLM stack)
        
    - `M3` (world semantics)
        
    - `M4` (virtues)
        
    - `M5` (skills)
        
    - `M6` (bot core)
        
    - `M7` (observation encoding)
        
- **Difficulty:** ⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Design as a state machine with clear states (Idle, Planning, Executing, Recovering).
        
    - Rate-limit LLM calls, reuse plans until invalidated.

M9 - monitoring_and_tools

**Purpose:**  
Give you observability and a control surface before the system gaslights you.

- Features:
    
    - Structured logs (JSON)
        
    - Web or TUI dashboard:
        
        - World overview
            
        - Current plan & skills
            
        - Virtue scores
            
        - Tech state
            
    - Manual controls:
        
        - Pause, step, cancel plan, inspect memory
            
- **Dependencies:** `M8`
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Central logger used by all modules.
        
    - Minimal UI first; upgrade visuals later.


Phase 4:

M10 - skill_learning

**Purpose:**  
Voyager-style learning: derive new skills from experience and refine existing ones.

- Components:
    
    - Experience buffer:
        
        - `{state, goal, plan, actions, outcomes, virtue_scores}`
            
    - LLM-based synthesizer:
        
        - Turn repeated success traces into new skill definitions
            
    - Evaluator:
        
        - Compare new vs existing skills on:
            
            - Success rate
                
            - Cost (time, resources)
                
            - Virtue scores
                
- **Dependencies:** `M8` (loop), `M2` (LLMs), `M5` (skill registry), `M4` (virtue scoring)
    
- **Difficulty:** ⭐⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Learning should be offline or scheduled, not constant.
        
    - Skills versioned and can be rolled back if regressions appear.


M11 - gtnh_curriculum_and_specialization

**Purpose:**  
Turn the generic learning agent into a **GTNH-native progression engine**.

- Define:
    
    - Curricula per phase:
        
        - Early LV goals
            
        - Steam infra goals
            
        - MV automation goals
            
    - Long-horizon projects:
        
        - Stargate, high-tier reactors, etc.
            
- The curriculum is:
    
    - A sequence of target tech states
        
    - Each with:
        
        - Reward shaping (virtue weight tweaks)
            
        - Suggested skills to prioritize / learn
            
- **Dependencies:** `M3`, `M5`, `M8`, `M10`
    
- **Difficulty:** ⭐⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Curriculum is config, not code.
        
    - Multiple curricula can be swapped (e.g. “eco base”, “speedrun”, “aesthetic build”).


Shortcut View:
# **Phase P0 — Foundations**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M0**|environment_foundation|⭐|0.5–2 days|Lock runtime, modpack, IPC choice|
|**M1**|agent_architecture_spec|⭐⭐|2–4 days|Full architecture doc|

### **Phase P0 Total:**

**Difficulty Avg:** ⭐⭐  
**Time:** ~3–6 days

---

# **Phase P1 — Offline Core Pillars (No Minecraft)**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M2**|llm_stack_local|⭐⭐–⭐⭐⭐|3–7 days|Local models, prompt tooling|
|**M3**|world_semantics_gtnh|⭐⭐⭐⭐|7–14 days|Tech tree + ontology mapping|
|**M4**|virtue_lattice|⭐⭐–⭐⭐⭐|3–6 days|Scoring/weights system|
|**M5**|skill_registry|⭐⭐–⭐⭐⭐|3–6 days|Skill definitions, metadata|

### **Phase P1 Total:**

**Difficulty Avg:** ⭐⭐⭐  
**Time:** ~2–4 weeks

---

# **Phase P2 — Minecraft Integration Layer**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M6**|bot_core_1_7_10|⭐⭐⭐⭐|2–4 weeks|Pathfinding, inventory, world tracking|
|**M7**|observation_encoding|⭐⭐–⭐⭐⭐|3–7 days|Convert raw MC data → semantic state|

### **Phase P2 Total:**

**Difficulty Avg:** ⭐⭐⭐⭐  
**Time:** ~3–5 weeks

---

# **Phase P3 — Agent Orchestration & Tooling**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M8**|agent_loop_v1|⭐⭐⭐⭐|1–2 weeks|Full observe → plan → act|
|**M9**|monitoring_and_tools|⭐⭐–⭐⭐⭐|3–7 days|Logs, dashboards, step controls|

### **Phase P3 Total:**

**Difficulty Avg:** ⭐⭐⭐⭐  
**Time:** ~2–3 weeks

---

# **Phase P4 — Learning & Specialization**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M10**|skill_learning|⭐⭐⭐⭐⭐|2–4 weeks|Voyager-style skill synthesis|
|**M11**|gtnh_curriculum_and_specialization|⭐⭐⭐⭐⭐|multi-week ongoing|Long-horizon GTNH progression logic|

### **Phase P4 Total:**

**Difficulty Avg:** ⭐⭐⭐⭐⭐  
**Time:** ~4–8+ weeks (ongoing beyond initial build)

---

# **Grand Totals (First-Pass Implementation)**

|Phase|Difficulty Avg|Total Time|
|---|---|---|
|**P0**|⭐⭐|3–6 days|
|**P1**|⭐⭐⭐|2–4 weeks|
|**P2**|⭐⭐⭐⭐|3–5 weeks|
|**P3**|⭐⭐⭐⭐|2–3 weeks|
|**P4**|⭐⭐⭐⭐⭐|4–8+ weeks|

---

# **Overall Estimate**

**Minimum:** ~11 weeks  
**Expected:** ~14–18 weeks  
**Ambitious agent with learning + GTNH specialization:** ~20–30 weeks ongoing refinement


File Structure:
```
GTNH_Agent/                          # Project root: the whole GTNH Agent codebase
├── bootstrap_structure.py           # One-shot scaffolder that originally created this layout
├── config/                          # All declarative config; no logic, just data
│   ├── curricula/                   # High-level progression presets (what the agent "wants" long-term)
│   │   ├── aesthetic_megabase.yaml  # Curriculum: prioritize pretty, large bases & builds
│   │   ├── default_speedrun.yaml    # Curriculum: optimize for fast tech progression
│   │   └── eco_factory.yaml         # Curriculum: prioritize efficiency/sustainability-style goals
│   ├── env.yaml                     # Env profiles: dev/prod, active model profile, bot_mode, etc.
│   ├── gtnh_blocks.generated.yaml   # Auto-ingested block semantics from Nerd/NEI dumps (do not hand-edit)
│   ├── gtnh_blocks.yaml             # Hand-authored block overrides / manual tags for important blocks
│   ├── gtnh_items.generated.yaml    # Auto-ingested item semantics (huge but structured)
│   ├── gtnh_items.yaml              # Hand-authored item overrides / special cases
│   ├── gtnh_recipes.agent.json      # Compressed, agent-ready recipe set (~215MB); primary recipe source
│   ├── gtnh_recipes.generated.json  # Raw-ish generated recipe dump (~400MB); kept as backup/reference
│   ├── gtnh_recipes.json            # Manual / future overrides for specific recipes (currently minimal/empty)
│   ├── gtnh_tech_graph.yaml         # Tech progression DAG: stone_age → steam → LV → MV etc + requirements
│   ├── hardware.yaml                # Host hardware profiles (GPU, threads, n_gpu_layers, etc.)
│   ├── llm_roles.yaml               # System prompts / roles for planner, critic, scribe, error model, etc.
│   ├── minecraft.yaml               # Minecraft runtime config: server info, world, IPC/mod settings
│   ├── models.yaml                  # Logical model profiles: which backend, which GGUF, context length, etc.
│   ├── raw/                         # Raw dumps from NEI / Nerd; ingestion inputs, not used directly by agent
│   │   ├── block.csv                # Block registry dump from NEI (name/id/mod/class/etc.)
│   │   ├── item.csv                 # Item registry dump from NEI
│   │   ├── recipes.json             # Absurd NEI recipe dump (pre-processed into agent/generated JSONs)
│   │   └── recipes_stacks.json      # Stack metadata used to resolve NEI’s weird itemSlug format
│   ├── skills/                      # YAML skill specifications (what the planner sees)
│   │   ├── chop_tree.yaml           # Spec for basic tree-chopping skill
│   │   ├── feed_coke_ovens.yaml     # Spec for keeping coke ovens fed
│   │   └── plant_sapling.yaml       # Spec for planting saplings post-chop
│   ├── skills_candidates/           # Staging folder for new skills auto-synthesized or WIP (currently empty)
│   ├── tools/                       # Tiny CLI helpers for config/env sanity
│   │   ├── print_env.py             # Print resolved EnvProfile for debugging (what profile actually resolves to)
│   │   └── validate_env.py          # Schema & consistency checks for env/models/hardware YAML
│   └── virtues.yaml                 # Virtue lattice definition: names, weights, dimensions per context
├── docs/
│   └── architecture.md              # Human-readable architecture spec for the whole M0–M11 system
├── .github/
│   └── workflows/
│       └── ci.yml                   # CI config: lint/tests on push/PR
├── .gitignore                       # Ignore venvs, caches, logs & other cruft
├── logs/
│   └── llm/                         # All LLM call traces (planner, critic, scribe, error model)
│       ├── 2025..._..._plan_code_plan.json           # Planner/codegen run logs (inputs/outputs/timings)
│       ├── 2025..._..._scribe_summarize_trace.json   # Scribe summarization / trace compression logs
│       └── 2025..._..._error_model_analyze_failure.json # Error model diagnosis run logs
├── pyproject.toml                   # Project metadata, dependencies, tooling (pytest, ruff, etc.)
├── .pytest_cache/                   # Pytest internals; auto-generated junk
│   ├── CACHEDIR.TAG
│   ├── .gitignore
│   ├── README.md
│   └── v/
│       └── cache/
│           ├── lastfailed           # Which tests failed last run
│           └── nodeids              # Collected test IDs
├── .python-version                  # Pyenv version pin (Python 3.12.x)
├── README.md                        # Top-level description, setup, quickstart, status
├── scripts/                         # Manual entrypoints, dev tools, ingestion & smoke tests
│   ├── compact_recipes_for_agent.py # Compress big recipe dump → gtnh_recipes.agent.json
│   ├── demo_offline_agent_step.py   # Run a single offline agent step using fake world/LLM
│   ├── dev_shell.py                 # Interactive dev REPL: quick stack/semantics poking
│   ├── ingest_gtnh_semantics.py     # Orchestrator: runs the various ingestion passes into generated configs
│   ├── ingest_nerd_csv_semantics.py # Convert Nerd/NEI block/item CSVs → gtnh_{blocks,items}.generated.yaml
│   ├── ingest_nerd_recipes.py       # Convert NEI recipe dumps → standardized recipe JSON format(s)
│   ├── smoke_error_model.py         # Quick harness to exercise ErrorModel end-to-end
│   ├── smoke_llm_stack.py           # Smoke & perf test for LLMStack / PlanCodeModel (tok/s, stability)
│   └── smoke_scribe_model.py        # Smoke test for Scribe summarization / compression
├── src/                             # Actual library code (this is the package)
│   ├── agent_loop/                  # M8: Agent orchestration core (observe → plan → act → evaluate)
│   │   ├── __init__.py
│   │   ├── loop.py                  # Main agent loop logic / state machine
│   │   ├── schema.py                # Dataclasses/schemas for loop input/output structures
│   │   └── state.py                 # AgentState representation across timesteps/episodes
│   ├── app/
│   │   ├── __init__.py
│   │   └── runtime.py               # Top-level wiring: load env, init LLMStack, semantics, bot_core, monitoring
│   ├── bot_core/                    # M6: Bot body & Minecraft protocol-facing logic
│   │   ├── actions.py               # Primitive actions (move, break, use, interact, etc.)
│   │   ├── core.py                  # Bot control loop; dispatches actions & tracks high-level state
│   │   ├── __init__.py
│   │   ├── nav/
│   │   │   ├── grid.py              # Voxel/grid representation for pathfinding
│   │   │   ├── __init__.py
│   │   │   ├── mover.py             # Low-level movement executor following paths
│   │   │   └── pathfinder.py        # A*/cost heuristics & navigation algorithms
│   │   ├── net/
│   │   │   ├── client.py            # Minecraft client / protocol bridge to server or Forge mod
│   │   │   ├── __init__.py
│   │   │   └── ipc.py               # IPC abstraction between Python and in-game integration
│   │   ├── snapshot.py              # Build raw world snapshots for observation encoder
│   │   └── world_tracker.py         # Tracks world state over time (chunks, entities, block deltas)
│   ├── curriculum/                  # M11-adjacent: curriculum engine implementation
│   │   ├── engine.py                # Selects next tasks/goals from curricula based on state
│   │   ├── __init__.py
│   │   ├── loader.py                # Loads curriculum YAMLs into in-memory structures
│   │   └── schema.py                # Dataclasses for curriculum definitions
│   ├── env/                         # M0: environment config loading & schema
│   │   ├── __init__.py
│   │   ├── loader.py                # Reads env.yaml + models.yaml + hardware.yaml → EnvProfile
│   │   └── schema.py                # EnvProfile & related config types
│   ├── gtnh_agent.egg-info/         # Packaging metadata generated by `pip install -e .`
│   │   ├── dependency_links.txt
│   │   ├── PKG-INFO
│   │   ├── requires.txt             # Installed dependencies list
│   │   ├── SOURCES.txt              # Files included in the distribution
│   │   └── top_level.txt            # Top-level package name(s)
│   ├── __init__.py                  # Makes `src` a package; can export root-level symbols later
│   ├── learning/                    # M10: skill learning & experience-based improvements
│   │   ├── buffer.py                # Experience buffer / replay storage
│   │   ├── evaluator.py             # Evaluate learned skills/strategies against metrics
│   │   ├── __init__.py
│   │   ├── manager.py               # Orchestrates learning phases, triggers training, updates registry
│   │   ├── schema.py                # Schemas for experiences, metrics, training configs
│   │   └── synthesizer.py           # Generates synthetic tasks/traces from curricula or logs
│   ├── llm_stack/                   # M2: Local LLM plumbing & orchestration
│   │   ├── backend_llamacpp.py      # llama.cpp backend wrapper (local GGUF w/ GPU offload)
│   │   ├── backend.py               # Abstract LLMBackend protocol/interface
│   │   ├── codegen.py               # Turn plans/specs into code (skills, helpers)
│   │   ├── config.py                # ModelConfig, ModelProfile etc. for LLMStack
│   │   ├── critic.py                # Critic model wrapper: score plans/actions/traces
│   │   ├── error_model.py           # ErrorModel: analyze failures, suggest fixes / retries
│   │   ├── __init__.py              # Exposes LLMStack & key helpers
│   │   ├── json_utils.py            # Robust JSON parsing/coercion from messy LLM output
│   │   ├── log_files.py             # Structured logging helpers for LLM calls → logs/llm
│   │   ├── plan_code.py             # PlanCodeModel: plan + code generation pipeline
│   │   ├── planner.py               # Planning-only model wrapper (structured plans, no code)
│   │   ├── presets.py               # Prompt/parameter presets for specific roles & modes
│   │   ├── schema.py                # Types for prompts, responses, configs
│   │   ├── scribe.py                # Scribe model: summarization & trace compression
│   │   └── stack.py                 # High-level LLMStack orchestrator composing all sub-models
│   ├── monitoring/                  # M9: Observability & controls
│   │   ├── bus.py                   # Event bus for logging/monitoring events
│   │   ├── controller.py            # Central controller: subscriptions, routing, wiring
│   │   ├── dashboard_tui.py         # Terminal UI dashboard for live stats & debugging
│   │   ├── events.py                # Event type definitions (LLM calls, actions, errors, etc.)
│   │   ├── __init__.py
│   │   └── logger.py                # Logging bridge: write to files/console/etc.
│   ├── observation/                 # M7: Encoding raw snapshots to LLM-ready observations
│   │   ├── encoder.py               # Build normalized WorldState from BotCore snapshots
│   │   ├── __init__.py
│   │   ├── schema.py                # Observation & related schema definitions
│   │   └── trace_schema.py          # Episode trace schemas (for learning & debugging)
│   ├── semantics/                   # M3: GTNH semantics, tech graph, and craftability logic
│   │   ├── cache.py                 # Singleton helpers so SemanticsDB/TechGraph only init once
│   │   ├── categorize.py            # Helpers to map items/blocks to semantic categories
│   │   ├── crafting.py              # `craftable_items` & inventory/machine helpers
│   │   ├── ingest/                  # Python package marker for ingest-related helpers (future)
│   │   │   └── __init__.py
│   │   ├── __init__.py              # Exposes semantics public API (db, helpers)
│   │   ├── loader.py                # Loads & merges blocks/items/recipes configs into SemanticsDB
│   │   ├── schema.py                # BlockInfo, ItemInfo, TechState, TechTarget, CraftOption types
│   │   └── tech_state.py            # TechGraph & `infer_tech_state_from_world` / `suggest_next_targets`
│   ├── skills/                      # M5: Skill registry & implementations
│   │   ├── base/
│   │   │   ├── chop_tree.py         # Concrete chop_tree skill implementation
│   │   │   ├── feed_coke_ovens.py   # Concrete feed_coke_ovens implementation
│   │   │   └── __init__.py
│   │   ├── __init__.py
│   │   ├── registry.py              # Registers skills & maps names → callables
│   │   └── schema.py                # Skill metadata, parameter schemas
│   ├── spec/                        # M1: formal interfaces / shared spec types
│   │   ├── agent_loop.py            # Spec types for agent loop interfaces
│   │   ├── bot_core.py              # Spec for bot_core interface (actions, results)
│   │   ├── experience.py            # Spec for learning/experience structures
│   │   ├── __init__.py
│   │   ├── llm.py                   # Spec types for LLM requests/responses
│   │   ├── skills.py                # Spec for skill definitions and calls
│   │   └── types.py                 # Core shared types (WorldState, Action, Observation, etc.)
│   └── virtues/                     # M4: Virtue lattice & metrics
│       ├── __init__.py
│       ├── lattice.py               # Core virtue lattice operations & scoring
│       ├── loader.py                # Load virtues.yaml into in-memory structures
│       ├── metrics.py               # Derived metrics, tradeoffs, global "alignment" scores
│       └── schema.py                # Virtue dimension schemas
└── tests/                           # Full unit/integration test suite
    ├── conftest.py                  # Shared fixtures & setup
    ├── fakes/                       # Fake implementations for isolated tests
    │   ├── fake_bot_core.py         # Fake bot core (no Minecraft) for agent loop tests
    │   ├── fake_llm_stack.py        # Deterministic fake LLMStack backend
    │   ├── fake_skills.py           # Simple fake skills for planning/execution tests
    │   └── __init__.py
    ├── __init__.py
    ├── test_agent_loop_v1.py        # Agent loop integration tests
    ├── test_architecture_integration.py # Sanity: wiring holds together across major modules
    ├── test_env_loader.py           # env.loader, YAML configs, and EnvProfile tests
    ├── test_error_model_with_fake_backend.py # ErrorModel behavior with fake backend
    ├── test_llm_stack_fake_backend.py        # LLMStack orchestration w/ fake backend
    ├── test_observation_critic_encoding.py   # Observation → critic encoding schema/path
    ├── test_observation_planner_encoding.py  # Observation → planner encoding schema/path
    ├── test_observation_worldstate_normalization.py # Ensures encoder builds normalized WorldState
    ├── test_phase0_runtime.py        # Phase 0 integration smoke tests (env + runtime wiring)
    ├── test_scribe_model_with_fake_backend.py # Scribe summarization behavior
    ├── test_semantics_caching_singleton.py    # SemanticsDB/TechGraph singleton caching semantics
    ├── test_semantics_categorization.py       # Block/item category & material inference
    ├── test_semantics_craftability.py         # craftable_items behavior & constraints
    ├── test_semantics_tech_inference.py       # infer_tech_state & suggest_next_targets behavior
    ├── test_semantics_tolerant_fallbacks.py   # Legacy / sloppy input tolerance in semantics
    └── test_semantics_with_normalized_worldstate.py # End-to-end semantics using encoder-built WorldState

```

# **GTNH_Agent – Phase P1/P2 Knowledge Capsule**

### **Context**

This project is a fully local AI-driven Minecraft agent designed specifically for **GregTech New Horizons (GTNH 2.8.1)**.  
By M3, the agent now has:

- A stable architecture (M0–M1)
    
- A fully functional LLM backend stack (M2)
    
- A complete, real-world semantics engine for GTNH (M3)
    
- A reproducible ingestion pipeline for turning raw NEI/Nerd dumps into agent-readable semantics
    

This capsule captures the finished work up to this point and prepares the ground for Phase P1–P2.

---

# **1. Architecture Summary (What the Agent Is Made Of)**

### **Core Modules (M0–M3 Completed)**

#### **M0 – Environment Foundation**

- Defines the **environment profile** via `env.yaml`, `models.yaml`, `hardware.yaml`, `minecraft.yaml`.
    
- Ensures all configs load cleanly.
    
- Provides `validate_env.py` and `print_env.py`.
    

#### **M1 – Agent Architecture Spec**

- Defines the core schemas:
    
    - `WorldState`
        
    - `Action`, `ActionResult`
        
    - `Observation`
        
- Standardizes interfaces between BotCore → Observation → Planner → Agent Loop.
    

#### **M2 – Local LLM Stack**

- Integration of **llama.cpp** backend with GPU offload.
    
- Achieves ~50 tokens/sec locally.
    
- Planner, Critic, Scribe, and ErrorModel implemented.
    
- Unified logging strategy under `logs/llm/`.
    

#### **M3 – World Semantics (GTNH)**

Now fully complete. Includes:

- **Item semantics** (category, material, variants)
    
- **Block semantics**
    
- **Recipe semantics** via `SemanticsDB`
    
- **Tech graph inference** via `TechGraph`
    
- **Craftability engine**
    

### **Ingestion Pipeline**

GTNH’s massive data is ingested from:

- NEI block/item CSVs
    
- Nerd’s chonky recipe JSON dump (400MB)
    

Transformed into:

- `gtnh_blocks.generated.yaml`
    
- `gtnh_items.generated.yaml`
    
- `gtnh_recipes.agent.json` (215MB compressed)
    
- Fully merged with hand-authored overrides.
    

### **Ingestion Principles**

- Hand-authored always overrides generated.
    
- Generated is the authoritative baseline.
    
- Loader merges:
    
    - Blocks: base + generated
        
    - Items: base + generated
        
    - Recipes: base + agent.json (or generated)
        
- SemanticsDB loads everything in <1 second.
    

---

# **2. Key Definitions (Mental Models for Future You)**

### **SemanticsDB**

Single in-memory database holding:

- All GTNH items and block definitions
    
- All recipes (machine + crafting)
    
- All categories + materials + variants
    

Provides:
Python:
```
db.get_item_info(item_id, variant)
db.get_block_info(block_id, variant)
db.recipes

```

### **TechGraph**

- DAG of the entire GTNH progression chain.
    
- Reads `gtnh_tech_graph.yaml`
    
- Finds your current tech level from:
    
    - Machines present
        
    - Items present
        
    - Derived flags
        
- Suggests next reachable targets.
    

### **Craftability**

Given a WorldState:

- Check machine availability.
    
- Check if all materials exist.
    
- Calculate limiting resources.
    
- Return craftable `CraftOption`s.
    

### **Observation Encoder**

Normalizes BotCore snapshots into stable schemas:

- Fixes item IDs
    
- Resolves variants
    
- Normalizes machine entries
    
- Guarantees clean input for M3 and planner.
    

---

# **3. Insights Learned**

### **1. GTNH Semantics Are Huge**

- The modpack is effectively a knowledge graph with thousands of nodes.
    
- Manual semantics creation is unreasonably expensive.
    
- Automated ingestion is required.
    

### **2. NEI/Nerd Dumps Are Messy**

- NEI produces unusable itemSlug formats.
    
- Nerd’s recipe JSON is structurally inconsistent but salvageable.
    
- CSV → YAML is the right path for items/blocks.
    
- Recipes must be heavily sanitized and compressed.
    

### **3. Loader Architecture Matters**

- Merging base + generated + agent-optimized recipes gives control without redesign.
    
- Semantics must be normalized once at startup, not every loop.
    

### **4. Test Coverage = Stability**

- You now have tests for:
    
    - Categorization
        
    - Craftability
        
    - Fallback tolerance
        
    - Tech inference
        
    - WorldState normalization
        
    - Semantics caching
        

### **5. Performance Requires Sharding**

- The 215MB JSON file is acceptable for now.
    
- But future shards are inevitable:
    
    - By mod
        
    - By machine type
        
    - By tier (steam/lv/mv/hv/etc.)
        

---

# **4. To-Do List for Upcoming Phases**

## **Phase P1 – Offline Components**

### **Target: M4–M6**

#### **M4 – Virtue Lattice (Scoring)**

- Integrate semantics and tech state with virtue scoring.
    
- Design plan scoring functions using `virtues.yaml`.
    
- Implement composite scoring:
    
    - Efficiency
        
    - Safety
        
    - Sustainability
        
    - Complexity
        
    - Creativity
        
- Unit test every scoring rule.
    

#### **M5 – Skills Layer**

- Flesh out actual skill implementations.
    
- Ensure skills load from YAML cleanly via registry.
    
- Add auto-synthesized skill generation (later M10 will expand this).
    
- Add more basic LV-era skills:
    
    - Smelt plate → ingot → machine casing assembly
        
    - Steam infrastructure maintenance
        
    - Furnace/crafting automation tasks
        

#### **M6 – BotCore Integration**

- Build IPC layer for Mineflayer or GC2 mod interface.
    
- Define snapshot schema produced by in-game mod.
    
- Map raw blocks/entities/inventory into normalized form.
    
- Implement navigation actions:
    
    - MoveTo
        
    - BreakBlock
        
    - UseItem
        
    - InteractMachine
        

---

## **Phase P2 – Runtime Agent Loop**

### **Target: M7–M9**

#### **M7 – Observation Encoder**

- Already built; now test with real Minecraft snapshots.
    

#### **M8 – Agent Loop**

- Connect:
    
    - WorldState → Planner
        
    - Planner → Skills
        
    - Skills → BotCore actions
        
    - Critic/Evaluator → scoring loop
        

#### **M9 – Monitoring & Dashboard**

- Hook up TUI dashboard for live debugging.
    
- Real-time LLM logs & world-state deltas.
    

---

## **Phase P3 – Learning / Autonomy**

### **Target: M10–M11**

#### **M10 – Experience Learning**

- Build experience converter for planning traces.
    
- Create replay buffer system.
    
- Add synthetic curriculum generation.
    
- Begin training local patterns (non-LLM heuristics).
    

#### **M11 – Curriculum Engine**

- A true progression engine matching GTNH’s pace.
    
- Integrate tech state, virtue scoring, and skill selection.
    
- Pilot tasks:
    
    - “Reach LV”
        
    - “Build steam mega-boiler”
        
    - “Automate plate production”
        
    - “Feed coke ovens forever”
        
    - “Stargate construction roadmap”
        

---

# **5. High-Level Trajectory**

You’ve built **the most complex part of the entire agent**: its world model and semantics engine.

This unlocks:

- Tech inference
    
- Craftability
    
- Category reasoning
    
- Semantic planning
    
- Long-horizon task decomposition
    

Now the agent can _think_ in the language of GTNH rather than “some cubes and pain.”

Next, you give it a **body (BotCore)** and **agency (Planner/Skills)**.