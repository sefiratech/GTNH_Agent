Here is an overview of the entire project for your context:

Phase 0:

M0 - environment_foundation

**Purpose:**

Lock in the actual environment & runtimes.

- Define:

- MC 1.7.10 + Forge 10.13.4.1614 + GTNH 2.8.1 run profile

- Decision: external bot client vs in-process Forge mod with IPC

- Hardware constraints for local LLMs

- **Dependencies:** None

- **Difficulty:** ⭐

- **Scalability notes:**

- Document this in a single config file / README; future changes (new model, new server host) should not touch code.

M1 - agent_architecture_spec

**Purpose:**  
Unify Mineflayer + Voyager insights into a **single architecture spec**.

- Extract from Mineflayer:
    
    - Bot lifecycle
        
    - World model
        
    - Pathfinding
        
    - Action abstraction
        
- Extract from Voyager:
    
    - Planner → Skill library → Execution loop
        
    - Reflection & learning
        
- **Dependencies:** `M0`
    
- **Difficulty:** ⭐⭐
    
- **Scalability notes:**
    
    - Produce one canonical architecture doc: diagrams + interfaces.
        
    - This is the contract everything else conforms to.


Phase 1

M2 - llm_stack_local

**Purpose:**  
Provide reusable interfaces around local models.

- Implement:
    
    - `PlannerModel`: high-level plan generation
        
    - `CodeModel`: skill/code generation
        
    - `CriticModel`: evaluation / refinement
        
- Unified tool schema:
    
    - Input: structured state / goal
        
    - Output: JSON plan / skill spec, no direct MC calls
        
- **Dependencies:** `M1`
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Centralize model loading & caching.
        
    - Make batch calls possible.
        
    - Log prompts/responses for replay.

M3 - world_semantics_gtnh

**Purpose:**  
Define GTNH tech + world understanding as **data + logic**.

- Data layer (config files):
    
    - Block categories (ores, machines, cables, etc.)
        
    - Item categories (plates, circuits, tools)
        
    - Tech states & prereqs (LV steam, MV, etc.)
        
- Logic layer (Python):
    
    - `infer_tech_state(inventory, machines)`
        
    - `suggest_next_targets(tech_state)`
        
    - `craftable_items(inventory, known_recipes)`
        
- **Dependencies:** `M1`
    
- **Difficulty:** ⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Keep recipes & categories in JSON/YAML, not code.
        
    - Cache derived graphs (like tech dependency DAGs).

M4 - virtue_lattice

**Purpose:**  
Encapsulate your Sefirot-based virtues as a reusable scoring layer.

- Define:
    
    - Virtue nodes: Efficiency, Safety, Sustainability, etc.
        
    - Configurable weights per context (e.g., early LV vs late HV)
        
- APIs:
    
    - `score_plan(plan, context) -> dict[virtue -> score]`
        
    - `compare_plans(plans, context) -> best_plan`
        
- **Dependencies:** `M3` (for context & environment semantics)
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Pure functions, stateless, easy to unit test.
        
    - Configurable weights → you can tune without code changes.

M5 - skill_registry

**Purpose:**  
Central place for skill definitions and metadata.

- Skill spec:
    
    - Name, parameters
        
    - Preconditions (what world/tech state is required)
        
    - Effects (changes in world/tech state)
        
    - Tags (e.g., mining, crafting, building)
        
- LLM interaction:
    
    - Planner only sees skill metadata, not raw code.
        
    - Skill implementations live as Python methods or small scripts.
        
- **Dependencies:** `M1`, `M3`
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Skills registered via decorators or config files.
        
    - Easy to version and deprecate skills over time.

Phase 2:

M6 - bot_core_1_7_10

**Purpose:**  
Provide a stable, testable “body” that can be used by any controller.

- Capabilities:
    
    - Connect/keepalive
        
    - World tracking (chunks, entities)
        
    - Navigation (A* or similar)
        
    - Actions:
        
        - Move, jump, break block, place block, use item, interact with tile entities
            
- API:
    
    - `observe() -> RawWorldSnapshot`
        
    - `execute_action(Action) -> Result`
        
- **Dependencies:** `M0`, `M1`
    
- **Difficulty:** ⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Keep logic modular: pathfinding, inventory, world tracking as submodules.
        
    - Limit unnecessary packet decoding; cache what you can.

M7 - observation_encoding

**Purpose:**  
Map `RawWorldSnapshot` from `M6` into semantic state used by LLMs & planners.

- Functions:
    
    - `encode_for_planner(raw_snapshot, tech_state) -> JSON`
        
    - `encode_for_critic(trace) -> JSON`
        
- Uses:
    
    - `M3` (semantics)
        
    - `M4` (virtues context)
        
- **Dependencies:** `M3`, `M6`
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Keep encodings compact. Summaries + key entities, not entire chunks.
        
    - Enforce stable schema to avoid breaking old skills.

Phase 3:

M8 - agent_loop_v1

**Purpose:**  
Implement the core loop: observe → plan → choose skills → act → evaluate.

- High-level algorithm:
    
    1. `state = observe()`
        
    2. `tech_state = infer_tech_state(state)`
        
    3. `plan = planner_model.call(state, tech_state, skill_registry, virtues)`
        
    4. Decompose plan into skill invocations
        
    5. Execute via `bot_core_1_7_10`
        
    6. Log result for learning (`M10`)
        
- Strict separation:
    
    - No direct packet calls here.
        
    - No GTNH-hardcoded weirdness here; that lives in `M3` and `M5`.
        
- **Dependencies:**
    
    - `M2` (LLM stack)
        
    - `M3` (world semantics)
        
    - `M4` (virtues)
        
    - `M5` (skills)
        
    - `M6` (bot core)
        
    - `M7` (observation encoding)
        
- **Difficulty:** ⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Design as a state machine with clear states (Idle, Planning, Executing, Recovering).
        
    - Rate-limit LLM calls, reuse plans until invalidated.

M9 - monitoring_and_tools

**Purpose:**  
Give you observability and a control surface before the system gaslights you.

- Features:
    
    - Structured logs (JSON)
        
    - Web or TUI dashboard:
        
        - World overview
            
        - Current plan & skills
            
        - Virtue scores
            
        - Tech state
            
    - Manual controls:
        
        - Pause, step, cancel plan, inspect memory
            
- **Dependencies:** `M8`
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Central logger used by all modules.
        
    - Minimal UI first; upgrade visuals later.


Phase 4:

M10 - skill_learning

**Purpose:**  
Voyager-style learning: derive new skills from experience and refine existing ones.

- Components:
    
    - Experience buffer:
        
        - `{state, goal, plan, actions, outcomes, virtue_scores}`
            
    - LLM-based synthesizer:
        
        - Turn repeated success traces into new skill definitions
            
    - Evaluator:
        
        - Compare new vs existing skills on:
            
            - Success rate
                
            - Cost (time, resources)
                
            - Virtue scores
                
- **Dependencies:** `M8` (loop), `M2` (LLMs), `M5` (skill registry), `M4` (virtue scoring)
    
- **Difficulty:** ⭐⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Learning should be offline or scheduled, not constant.
        
    - Skills versioned and can be rolled back if regressions appear.


M11 - gtnh_curriculum_and_specialization

**Purpose:**  
Turn the generic learning agent into a **GTNH-native progression engine**.

- Define:
    
    - Curricula per phase:
        
        - Early LV goals
            
        - Steam infra goals
            
        - MV automation goals
            
    - Long-horizon projects:
        
        - Stargate, high-tier reactors, etc.
            
- The curriculum is:
    
    - A sequence of target tech states
        
    - Each with:
        
        - Reward shaping (virtue weight tweaks)
            
        - Suggested skills to prioritize / learn
            
- **Dependencies:** `M3`, `M5`, `M8`, `M10`
    
- **Difficulty:** ⭐⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Curriculum is config, not code.
        
    - Multiple curricula can be swapped (e.g. “eco base”, “speedrun”, “aesthetic build”).


Shortcut View:
# **Phase P0 — Foundations**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M0**|environment_foundation|⭐|0.5–2 days|Lock runtime, modpack, IPC choice|
|**M1**|agent_architecture_spec|⭐⭐|2–4 days|Full architecture doc|

### **Phase P0 Total:**

**Difficulty Avg:** ⭐⭐  
**Time:** ~3–6 days

---

# **Phase P1 — Offline Core Pillars (No Minecraft)**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M2**|llm_stack_local|⭐⭐–⭐⭐⭐|3–7 days|Local models, prompt tooling|
|**M3**|world_semantics_gtnh|⭐⭐⭐⭐|7–14 days|Tech tree + ontology mapping|
|**M4**|virtue_lattice|⭐⭐–⭐⭐⭐|3–6 days|Scoring/weights system|
|**M5**|skill_registry|⭐⭐–⭐⭐⭐|3–6 days|Skill definitions, metadata|

### **Phase P1 Total:**

**Difficulty Avg:** ⭐⭐⭐  
**Time:** ~2–4 weeks

---

# **Phase P2 — Minecraft Integration Layer**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M6**|bot_core_1_7_10|⭐⭐⭐⭐|2–4 weeks|Pathfinding, inventory, world tracking|
|**M7**|observation_encoding|⭐⭐–⭐⭐⭐|3–7 days|Convert raw MC data → semantic state|

### **Phase P2 Total:**

**Difficulty Avg:** ⭐⭐⭐⭐  
**Time:** ~3–5 weeks

---

# **Phase P3 — Agent Orchestration & Tooling**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M8**|agent_loop_v1|⭐⭐⭐⭐|1–2 weeks|Full observe → plan → act|
|**M9**|monitoring_and_tools|⭐⭐–⭐⭐⭐|3–7 days|Logs, dashboards, step controls|

### **Phase P3 Total:**

**Difficulty Avg:** ⭐⭐⭐⭐  
**Time:** ~2–3 weeks

---

# **Phase P4 — Learning & Specialization**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M10**|skill_learning|⭐⭐⭐⭐⭐|2–4 weeks|Voyager-style skill synthesis|
|**M11**|gtnh_curriculum_and_specialization|⭐⭐⭐⭐⭐|multi-week ongoing|Long-horizon GTNH progression logic|

### **Phase P4 Total:**

**Difficulty Avg:** ⭐⭐⭐⭐⭐  
**Time:** ~4–8+ weeks (ongoing beyond initial build)

---

# **Grand Totals (First-Pass Implementation)**

|Phase|Difficulty Avg|Total Time|
|---|---|---|
|**P0**|⭐⭐|3–6 days|
|**P1**|⭐⭐⭐|2–4 weeks|
|**P2**|⭐⭐⭐⭐|3–5 weeks|
|**P3**|⭐⭐⭐⭐|2–3 weeks|
|**P4**|⭐⭐⭐⭐⭐|4–8+ weeks|

---

File Structure:
```
.
├── bootstrap_structure.py              # Script to (re)create the repo’s canonical folder/file layout for fresh clones/dev envs
├── config                              # All YAML/JSON config driving env, skills, models, tech graph, etc.
│   ├── curricula                       # Curriculum definitions for higher-level learning / progression (future M11)
│   │   ├── aesthetic_megabase.yaml     # Curriculum for “aesthetic megabase” long-horizon goals
│   │   ├── default_speedrun.yaml       # Baseline speedrun-oriented curriculum
│   │   └── eco_factory.yaml            # Curriculum for efficient/eco factory progression path
│   ├── env.yaml                        # Core environment profiles: hardware, paths, bot mode, profiles like dev/offline
│   ├── gtnh_blocks.generated.yaml      # Autogenerated GTNH block metadata from ingest/dumps (do not hand-edit)
│   ├── gtnh_blocks.yaml                # Hand-tuned block overrides / corrections layered over generated data
│   ├── gtnh_items.generated.yaml       # Autogenerated GTNH item metadata (raw ingest output)
│   ├── gtnh_items.yaml                 # Manual corrections / grouping for GTNH items
│   ├── gtnh_recipes.agent.json         # Compact, agent-friendly recipe graph (deduped / simplified for planning)
│   ├── gtnh_recipes.generated.json     # Raw-ish recipes dump from the ingest pipeline; large and noisy
│   ├── gtnh_recipes.json               # Stable recipes view used by semantics/crafting; sits between raw + agent view
│   ├── gtnh_tech_graph.yaml            # Directed tech progression graph (tiers, gates, dependencies) for M3 semantics
│   ├── hardware.yaml                   # Hardware profiles (GPU/CPU/VRAM limits) used by LLM backend selection
│   ├── llm_roles.yaml                  # Role presets / prompt personalities for planner/critic/scribe/etc.
│   ├── minecraft.yaml                  # Minecraft instance config: world, server, ports, IPC choices
│   ├── models.yaml                     # Local model registry: paths, quant types, roles (planner, critic, scribe)
│   ├── raw                             # Raw imported data from external tools (TellMe/nerd/CSV dumps)
│   │   ├── block.csv                   # Raw block list from modpack tools, before normalization
│   │   ├── item.csv                    # Raw item list from modpack tools, before normalization
│   │   ├── recipes.json                # Raw recipes dump (messy, many unused fields)
│   │   └── recipes_stacks.json         # Raw stack-aware recipes dump (includes quantities/stack sizes)
│   ├── skill_packs                     # High-level skill pack bundles (groupings to load per phase/tech level)
│   │   ├── lv_core.yaml                # Minimal skills for early LV factory / basic infrastructure
│   │   └── steam_age.yaml              # Skills focused on early steam age (coke ovens, boilers, water handling)
│   ├── skills                          # Individual skill definitions used by SkillsRegistry
│   │   ├── basic_crafting.yaml         # YAML skill spec for basic table/grid crafting actions
│   │   ├── chop_tree.yaml              # Skill spec for tree chopping behavior
│   │   ├── feed_coke_ovens.yaml        # Skill spec for feeding coke ovens (charcoal/fuel management)
│   │   ├── feed_steam_boiler.yaml      # Skill spec for feeding solid-fuel steam boilers
│   │   ├── maintain_coke_ovens.yaml    # Skill spec to keep coke ovens running (outputs/inputs upkeep)
│   │   ├── plant_sapling.yaml          # Skill spec for replanting saplings after tree harvesting
│   │   └── refill_water_tanks.yaml     # Skill spec for refilling boiler water tanks or similar fluid systems
│   ├── skills_candidates               # Staging area for new/experimental YAML skills not yet promoted to main set
│   ├── tools                           # Small utilities/scripts for working with config
│   │   ├── print_env.py                # Helper to print resolved EnvProfile for debugging
│   │   └── validate_env.py             # Env/config validator used by tests and CLI sanity checks
│   └── virtues.yaml                    # Virtue lattice / virtue configuration for the moral/metric layer
├── docs                                # Design docs, architecture notes, module specs
│   ├── architecture.md                 # High-level architecture overview and module responsibilities
│   ├── ipc_protocol_m6.md              # IPC protocol spec for M6 BotCore <-> Minecraft bridge
│   ├── m6_bot_core_1_7_10.md           # Detailed design for BotCore implementation targeting 1.7.10 GTNH
│   └── phase1_integration.md           # Phase 0–1 integration doc, wiring env + LLM stack + semantics + tests
├── .github                             # Repo automation / CI configuration
│   └── workflows
│       └── ci.yml                      # CI pipeline config (lint/tests on pushes/PRs)
├── .gitignore                          # Git ignore rules for venvs, logs, build artifacts, etc.
├── logs                                # Runtime logs (LLM traces, error reports, etc.)
│   └── llm                             # LLM interaction logs: planner/critic/scribe/error model traces (no comments requested)
│       ├── 20251127T154508_30389_error_model_analyze_failure.json
│       ├── 20251127T154508_30389_plan_code_plan.json
│       ├── 20251127T154508_30389_scribe_summarize_trace.json
│       ├── 20251127T154653_30421_plan_code_plan.json
│       ├── 20251127T154929_30485_error_model_analyze_failure.json
│       ├── 20251127T155054_30542_scribe_summarize_trace.json
│       ├── 20251127T171641_54578_plan_code_plan.json
│       ├── 20251127T172238_54966_plan_code_plan.json
│       ├── 20251127T172404_55071_plan_code_plan.json
│       ├── 20251127T181107_57121_plan_code_plan.json
│       ├── 20251127T181432_57416_plan_code_plan.json
│       ├── 20251127T202123_80866_error_model_analyze_failure.json
│       ├── 20251127T202123_80866_plan_code_plan.json
│       ├── 20251127T202123_80866_scribe_summarize_trace.json
│       ├── 20251127T202334_80953_error_model_analyze_failure.json
│       ├── 20251127T202334_80953_plan_code_plan.json
│       ├── 20251127T202334_80953_scribe_summarize_trace.json
│       ├── 20251127T223951_107281_error_model_analyze_failure.json
│       ├── 20251127T223951_107281_plan_code_plan.json
│       ├── 20251127T223951_107281_scribe_summarize_trace.json
│       ├── 20251128T001446_136742_error_model_analyze_failure.json
│       ├── 20251128T001446_136742_plan_code_plan.json
│       ├── 20251128T001446_136742_scribe_summarize_trace.json
│       ├── 20251128T003700_146815_error_model_analyze_failure.json
│       ├── 20251128T003700_146815_plan_code_plan.json
│       ├── 20251128T003700_146815_scribe_summarize_trace.json
│       ├── 20251128T115106_24456_error_model_analyze_failure.json
│       ├── 20251128T115106_24456_plan_code_plan.json
│       ├── 20251128T115106_24456_scribe_summarize_trace.json
│       ├── 20251128T143640_52852_error_model_analyze_failure.json
│       ├── 20251128T143640_52852_plan_code_plan.json
│       ├── 20251128T143640_52852_scribe_summarize_trace.json
│       ├── 20251128T143816_52937_error_model_analyze_failure.json
│       ├── 20251128T143816_52937_plan_code_plan.json
│       ├── 20251128T143816_52937_scribe_summarize_trace.json
│       ├── 20251128T153451_109564_error_model_analyze_failure.json
│       ├── 20251128T153451_109564_plan_code_plan.json
│       ├── 20251128T153451_109564_scribe_summarize_trace.json
│       ├── 20251128T154112_109913_error_model_analyze_failure.json
│       ├── 20251128T154112_109913_plan_code_plan.json
│       ├── 20251128T154112_109913_scribe_summarize_trace.json
│       ├── 20251128T154622_110074_error_model_analyze_failure.json
│       ├── 20251128T154622_110074_plan_code_plan.json
│       ├── 20251128T154622_110074_scribe_summarize_trace.json
│       ├── 20251128T155834_129265_error_model_analyze_failure.json
│       ├── 20251128T155834_129265_plan_code_plan.json
│       ├── 20251128T155834_129265_scribe_summarize_trace.json
│       ├── 20251128T160155_129475_error_model_analyze_failure.json
│       ├── 20251128T160155_129475_plan_code_plan.json
│       ├── 20251128T160155_129475_scribe_summarize_trace.json
│       ├── 20251128T160633_142703_error_model_analyze_failure.json
│       ├── 20251128T160633_142703_plan_code_plan.json
│       ├── 20251128T160633_142703_scribe_summarize_trace.json
│       ├── 20251128T162316_143085_error_model_analyze_failure.json
│       ├── 20251128T162316_143085_plan_code_plan.json
│       ├── 20251128T162316_143085_scribe_summarize_trace.json
│       ├── 20251128T162956_163507_error_model_analyze_failure.json
│       ├── 20251128T162956_163507_plan_code_plan.json
│       ├── 20251128T162956_163507_scribe_summarize_trace.json
│       ├── 20251128T164527_184688_error_model_analyze_failure.json
│       ├── 20251128T164527_184688_plan_code_plan.json
│       ├── 20251128T164527_184688_scribe_summarize_trace.json
│       ├── 20251128T164725_184780_error_model_analyze_failure.json
│       ├── 20251128T164725_184780_plan_code_plan.json
│       ├── 20251128T164725_184780_scribe_summarize_trace.json
│       ├── 20251128T164846_185052_error_model_analyze_failure.json
│       ├── 20251128T164846_185052_plan_code_plan.json
│       ├── 20251128T164846_185052_scribe_summarize_trace.json
│       ├── 20251128T190228_210275_error_model_analyze_failure.json
│       ├── 20251128T190228_210275_plan_code_plan.json
│       ├── 20251128T190228_210275_scribe_summarize_trace.json
│       ├── 20251128T190457_210363_error_model_analyze_failure.json
│       ├── 20251128T190457_210363_plan_code_plan.json
│       ├── 20251128T190457_210363_scribe_summarize_trace.json
│       ├── 20251128T191608_225560_error_model_analyze_failure.json
│       ├── 20251128T191608_225560_plan_code_plan.json
│       ├── 20251128T191608_225560_scribe_summarize_trace.json
│       ├── 20251128T192046_233385_error_model_analyze_failure.json
│       ├── 20251128T192046_233385_plan_code_plan.json
│       ├── 20251128T192046_233385_scribe_summarize_trace.json
│       ├── 20251128T192251_233478_error_model_analyze_failure.json
│       ├── 20251128T192251_233478_plan_code_plan.json
│       ├── 20251128T192251_233478_scribe_summarize_trace.json
│       ├── 20251128T204447_291001_error_model_analyze_failure.json
│       ├── 20251128T204447_291001_plan_code_plan.json
│       ├── 20251128T204501_291001_scribe_summarize_trace.json
│       ├── 20251128T204732_291164_error_model_analyze_failure.json
│       ├── 20251128T204732_291164_plan_code_plan.json
│       ├── 20251128T204807_291164_scribe_summarize_trace.json
│       ├── 20251128T212201_317178_error_model_analyze_failure.json
│       ├── 20251128T212201_317178_plan_code_plan.json
│       ├── 20251128T212258_317178_scribe_summarize_trace.json
│       ├── 20251128T214908_353050_error_model_analyze_failure.json
│       ├── 20251128T214908_353050_plan_code_plan.json
│       ├── 20251128T215005_353050_scribe_summarize_trace.json
│       ├── 20251128T215508_371511_error_model_analyze_failure.json
│       ├── 20251128T215508_371511_plan_code_plan.json
│       ├── 20251128T215605_371511_scribe_summarize_trace.json
│       ├── 20251128T215741_371600_error_model_analyze_failure.json
│       ├── 20251128T215741_371600_plan_code_plan.json
│       ├── 20251128T215838_371600_scribe_summarize_trace.json
│       ├── 20251129T120138_42538_error_model_analyze_failure.json
│       ├── 20251129T120138_42538_plan_code_plan.json
│       ├── 20251129T120235_42538_scribe_summarize_trace.json
│       ├── 20251129T121735_52787_error_model_analyze_failure.json
│       ├── 20251129T121735_52787_plan_code_plan.json
│       ├── 20251129T121832_52787_scribe_summarize_trace.json
│       ├── 20251129T122136_52946_error_model_analyze_failure.json
│       ├── 20251129T122136_52946_plan_code_plan.json
│       └── 20251129T122233_52946_scribe_summarize_trace.json
├── pyproject.toml                      # Project metadata + tooling config (pytest, deps, package info)
├── .pytest_cache                       # Pytest’s own cache directory (last runs, node ids, etc.)
│   ├── CACHEDIR.TAG
│   ├── .gitignore
│   ├── README.md
│   └── v
│       └── cache
│           ├── lastfailed
│           └── nodeids
├── .python-version                     # Pyenv / runtime version pinning for this project
├── README.md                           # Top-level readme / quickstart for the project
├── scripts                             # One-off maintenance / data-prep scripts
│   ├── compact_recipes_for_agent.py    # Compress and reshape recipes into agent-friendly format
│   ├── demo_offline_agent_step.py      # Run a single offline agent step demo (no real Minecraft)
│   ├── dev_shell.py                    # Drop into a dev shell with env preloaded
│   ├── ingest_gtnh_semantics.py        # Ingest GTNH semantics into the semantics cache/graphs
│   ├── ingest_nerd_csv_semantics.py    # Convert nerd CSV dumps into semantics-friendly formats
│   ├── ingest_nerd_recipes.py          # Ingest nerd/TellMe recipe dumps into config/raw recipes
│   ├── smoke_error_model.py            # Smoke test for error model pipeline
│   ├── smoke_llm_stack.py              # Smoke test for LLM stack wiring
│   ├── smoke_scribe_model.py           # Smoke test for scribe summarization model
├── src                                 # Actual library / package source code
│   ├── agent                           # Agent orchestration (runtime + loop + experience)
│   │   ├── bootstrap.py                # High-level bootstrap wiring for agent runtime (profiles, stack)
│   │   ├── experience.py               # Experience + ExperienceBuffer structures for episodes
│   │   ├── logging_config.py           # Logging setup for agent/LLM/monitoring
│   │   ├── loop.py                     # M8 AgentLoop implementation (episode-level planner→executor→critic→xp)
│   │   └── runtime_m6_m7.py            # AgentRuntime: integrates M6 BotCore + M7 observation encoding
│   ├── agent_loop                      # Legacy / experimental agent-loop schemas (may be superseded by M8)
│   │   ├── __init__.py                 # Package marker for agent_loop
│   │   ├── loop.py                     # Earlier high-level loop abstraction (pre-M8 scaffold)
│   │   ├── schema.py                   # Pydantic/typed schemas for loop state/plan/trace
│   │   └── state.py                    # State container for agent loop internals
│   ├── app                             # Application entrypoints for running the agent system
│   │   ├── __init__.py                 # Package marker for app
│   │   └── runtime.py                  # App-level runtime wiring (CLI / service integration)
│   ├── bot_core                        # M6: BotCore implementation + navigation + IPC
│   │   ├── actions.py                  # Action definitions / translation between skills and low-level moves
│   │   ├── collision.py                # Collision / movement feasibility checking
│   │   ├── core.py                     # Core BotCoreImpl base class and helpers
│   │   ├── __init__.py                 # Package marker for bot_core
│   │   ├── nav                         # Navigation components (grid, pathfinding, movement)
│   │   │   ├── grid.py                 # Grid representation of walkable space
│   │   │   ├── __init__.py             # Package marker for nav
│   │   │   ├── mover.py                # High-level movement routines (step-by-step motion)
│   │   │   └── pathfinder.py           # Pathfinding algorithms over the grid
│   │   ├── net                         # Network / IPC clients to Minecraft or external processes
│   │   │   ├── client.py               # Native bot_core client for 1.7.10 server integration
│   │   │   ├── external_client.py      # Client wrapper for external/remote bot processes
│   │   │   ├── __init__.py             # Package marker for net
│   │   │   └── ipc.py                  # IPC abstractions (message framing, channels) for BotCore
│   │   ├── runtime.py                  # `get_bot_core` + FakeBotCore / runtime wiring (now M6 contract-compliant)
│   │   ├── snapshot.py                 # RawWorldSnapshot + adapters to WorldState (M6→M1 bridge)
│   │   ├── testing                     # Testing utilities for BotCore
│   │   │   └── fakes.py                # BotCore fakes/mocks for tests
│   │   ├── tracing.py                  # BotCore-level tracing / debug hooks
│   │   └── world_tracker.py            # Tracks loaded chunks, dedupes snapshots, maintains world memory
│   ├── cli                             # Command-line entrypoints
│   │   └── phase1_offline.py           # CLI driver for Phase 1 offline integration tests/demos
│   ├── curriculum                      # Curriculum engine (future M11) and schema
│   │   ├── engine.py                   # Core curriculum logic (select tasks, score progress)
│   │   ├── __init__.py                 # Package marker for curriculum
│   │   ├── loader.py                   # Load curricula YAML from config/curricula
│   │   └── schema.py                   # Typed schemas for curriculum definitions
│   ├── env                             # Environment profile handling (M0)
│   │   ├── __init__.py                 # Package marker for env
│   │   ├── loader.py                   # Load and validate env.yaml into EnvProfile objects
│   │   └── schema.py                   # Pydantic/typed schema for env profiles
│   ├── gtnh_agent.egg-info             # Packaging metadata generated by build/install
│   │   ├── dependency_links.txt
│   │   ├── PKG-INFO
│   │   ├── requires.txt
│   │   ├── SOURCES.txt
│   │   └── top_level.txt
│   ├── __init__.py                     # Top-level package marker for src
│   ├── integration                     # Phase 0–1 integration glue + validators
│   │   ├── adapters
│   │   │   └── m0_env_to_world.py      # Adapter from env profiles → initial WorldState context
│   │   ├── episode_logging.py          # Episode-level logging helpers (traces, summaries)
│   │   ├── __init__.py                 # Package marker for integration
│   │   ├── phase1_integration.py       # Orchestrates Phase1 pipeline: env → llm_stack → semantics → tests
│   │   ├── testing                     # Integration test helpers/fakes
│   │   │   ├── fakes.py                # Fake stacks/world for integration tests
│   │   │   └── __init__.py             # Package marker for integration.testing
│   │   └── validators                  # Validation utilities for plans/semantics/virtues
│   │       ├── __init__.py             # Package marker for validators
│   │       ├── planner_guardrails.py   # Plan-level guardrails (constraints, sanity checks)
│   │       ├── semantics_snapshots.py  # Validators for semantics snapshots consistency
│   │       ├── skill_integrity.py      # Ensures skills/skill packs are coherent with world semantics
│   │       └── virtue_snapshots.py     # Validators for virtue configs and snapshots
│   ├── learning                        # Experience / learning layer (M10 and friends)
│   │   ├── buffer.py                   # Experience buffers / replay buffer structures
│   │   ├── evaluator.py                # Evaluation utilities over learned skills/models
│   │   ├── __init__.py                 # Package marker for learning
│   │   ├── manager.py                  # High-level manager for learning pipelines
│   │   ├── schema.py                   # Schemas for learning configs/results
│   │   └── synthesizer.py              # Skill/experience synthesizer (generates new skills from traces)
│   ├── llm_stack                       # LLM stack: planner, critic, error model, scribe, backends
│   │   ├── backend_llamacpp.py         # llama.cpp-backed LLM implementation
│   │   ├── backend.py                  # Backend abstraction layer (LLM backends)
│   │   ├── codegen.py                  # Tools for code generation-oriented prompts/workflows
│   │   ├── config.py                   # LLM stack config loader (models.yaml, hardware.yaml)
│   │   ├── critic.py                   # Critic model wrapper and API
│   │   ├── error_model.py              # Error model for analyzing failures and proposing fixes
│   │   ├── __init__.py                 # Package marker for llm_stack
│   │   ├── json_utils.py               # Helpers for robust JSON extraction from LLM output
│   │   ├── log_files.py                # Helpers for writing LLM logs to logs/llm
│   │   ├── plan_code.py                # Planner/Code combined prompting logic
│   │   ├── planner.py                  # Planner model wrapper (M2 planner)
│   │   ├── presets.py                  # Prompt presets and stack configurations
│   │   ├── schema.py                   # Typed schemas for LLM requests/responses
│   │   ├── scribe.py                   # Scribe (summarization/trace compression) model wrapper
│   │   └── stack.py                    # High-level factory for assembling full LLM stack
│   ├── monitoring                      # Monitoring / TUI / event bus layer
│   │   ├── bus.py                      # Event bus for system events
│   │   ├── controller.py               # Monitoring/controller logic responding to events
│   │   ├── dashboard_tui.py            # Terminal UI for watching agent state in real time
│   │   ├── events.py                   # Typed events definitions for monitoring bus
│   │   ├── __init__.py                 # Package marker for monitoring
│   │   └── logger.py                   # Structured logging utilities
│   ├── observation                     # M7: observation → planner/critic encoding
│   │   ├── encoder.py                  # Encoders from WorldState/Trace → planner/critic payloads
│   │   ├── __init__.py                 # Package marker for observation
│   │   ├── pipeline.py                 # Observation pipeline orchestration
│   │   ├── schema.py                   # Schemas for observations and encodings
│   │   ├── testing.py                  # Observation-level test helpers
│   │   └── trace_schema.py             # PlanTrace / TraceStep schemas for episodes
│   ├── semantics                       # M3: GTNH semantics / tech inference / craftability
│   │   ├── cache.py                    # Semantics cache (blocks/items/recipes)
│   │   ├── categorize.py               # Category/label assignment for blocks/items
│   │   ├── crafting.py                 # Craftability logic & recipe graph queries
│   │   ├── ingest                      # Semantics ingest helpers
│   │   │   └── __init__.py             # Package marker for semantics.ingest
│   │   ├── __init__.py                 # Package marker for semantics
│   │   ├── loader.py                   # Load semantics from config/gtnh_* files
│   │   ├── schema.py                   # Schemas for semantics structures (items, recipes, groups)
│   │   └── tech_state.py               # TechState representation + inference from world/recipes
│   ├── skills                          # M5: skill system (registries, loaders, runtime skills)
│   │   ├── base                        # Python implementations of base skills
│   │   │   ├── basic_crafting.py       # Implementation of basic crafting skill
│   │   │   ├── chop_tree.py            # Implementation of tree chopping behavior
│   │   │   ├── feed_coke_ovens.py      # Implementation of feeding coke ovens
│   │   │   ├── feed_steam_boiler.py    # Implementation of boiler feeding skill
│   │   │   ├── __init__.py             # Package marker for skills.base
│   │   │   ├── maintain_coke_ovens.py  # Implementation of coke oven maintenance behavior
│   │   │   ├── plant_sapling.py        # Implementation of sapling planting
│   │   │   └── refill_water_tanks.py   # Implementation of water tank refilling
│   │   ├── __init__.py                 # Package marker for skills
│   │   ├── loader.py                   # Load skill YAML into Python skill specs
│   │   ├── packs.py                    # Grouped skill packs logic (loading lv_core, steam_age, etc.)
│   │   ├── registry.py                 # SkillRegistry: lookup/registration for skills
│   │   └── schema.py                   # Schemas for skill definitions and runtime parameters
│   ├── spec                            # Public contracts / interfaces for core subsystems
│   │   ├── agent_loop.py               # AgentLoop + VirtueEngine protocol definitions
│   │   ├── bot_core.py                 # BotCore protocol and related interfaces
│   │   ├── experience.py               # ExperienceRecorder, SkillLearner, CriticResult alias
│   │   ├── __init__.py                 # Package marker for spec
│   │   ├── llm.py                      # LLM interface contracts (PlannerModel, CriticModel, etc.)
│   │   ├── skills.py                   # Skill/SkillRegistry protocol contracts
│   │   └── types.py                    # Shared core types (WorldState, Action, ActionResult, etc.)
│   ├── testing                         # Shared test helpers (fixtures, utilities)
│   │   └── __init__.py                 # Package marker for testing
│   └── virtues                         # M4: virtue lattice + metrics
│       ├── explain.py                  # Explain virtue scores in human-readable form
│       ├── features.py                 # Feature extraction for virtue evaluation
│       ├── __init__.py                 # Package marker for virtues
│       ├── lattice.py                  # Core virtue lattice data structures
│       ├── loader.py                   # Load virtue configuration from config/virtues.yaml
│       ├── metrics.py                  # Metric computation used in virtue scoring
│       ├── sanity.py                   # Sanity checks for virtue configs/lattice
│       └── schema.py                   # Schemas for virtue config + runtime structures
├── tests                              # Test suite for all modules and integration phases
│   ├── conftest.py                     # Pytest fixtures and test-wide setup
│   ├── fakes                           # Fake components for tests (LLM, BotCore, Skills, Runtime)
│   │   ├── fake_bot_core.py            # BotCore fake used in various tests
│   │   ├── fake_llm_stack.py           # Fake LLM stack backend for fast tests
│   │   ├── fake_runtime.py             # Fake AgentRuntime for agent loop tests
│   │   ├── fake_skills.py              # Fake skill registry/skills for tests
│   │   └── __init__.py                 # Package marker for tests.fakes
│   ├── __init__.py                     # Package marker for tests
│   ├── test_actions.py                 # Tests for bot_core.actions
│   ├── test_agent_loop_stub.py         # Legacy agent loop tests (pre-M8 behavior / contracts)
│   ├── test_agent_loop_v1.py           # M8 AgentLoop v1 tests (episode loop over FakeAgentRuntime)
│   ├── test_architecture_integration.py# High-level architecture integrity/integration tests
│   ├── test_bot_core_impl.py           # BotCore implementation tests (actions, state)
│   ├── test_env_loader.py              # Tests for env.loader / env.yaml validation
│   ├── test_error_model_with_fake_backend.py  # Error model tests with fake backend
│   ├── test_llm_stack_fake_backend.py  # LLM stack tests with fake LLM backend
│   ├── test_m6_observe_contract.py     # Contract test for BotCore.observe() → RawWorldSnapshot
│   ├── test_nav_pathfinder.py          # Pathfinding/nav tests
│   ├── test_observation_critic_encoding.py    # Tests for critic encoding from traces/observations
│   ├── test_observation_perf.py        # Performance tests for observation pipeline
│   ├── test_observation_pipeline.py    # Observation pipeline end-to-end tests
│   ├── test_observation_planner_encoding.py   # Tests for planner encoding from WorldState
│   ├── test_observation_worldstate_normalization.py # Normalization tests for WorldState ingestion
│   ├── test_p0_p1_env_bridge.py        # Tests bridging M0 env profiles into integration context
│   ├── test_phase012_bootstrap.py      # Tests for Phase 0–2 bootstrap integration
│   ├── test_phase0_runtime.py          # Tests for Phase 0 runtime wiring
│   ├── test_phase1_breakglass_no_plans.py     # Regression tests for “no plans” fallbacks in Phase 1
│   ├── test_phase1_integration_offline.py     # Offline Phase 1 integration tests (no real MC)
│   ├── test_runtime_m6_m7_smoke.py     # Smoke tests for AgentRuntime (M6+M7)
│   ├── test_scribe_model_with_fake_backend.py # Scribe model tests with fake backend
│   ├── test_semantics_caching_singleton.py    # Semantics cache singleton behavior tests
│   ├── test_semantics_categorization.py# Tests for semantics.categorize
│   ├── test_semantics_craftability.py  # Craftability / recipe graph tests
│   ├── test_semantics_tech_inference.py# TechState inference tests
│   ├── test_semantics_tolerant_fallbacks.py   # Tolerant fallback behavior when semantics are missing/broken
│   ├── test_semantics_with_normalized_worldstate.py # Semantics over normalized WorldState tests
│   ├── test_skill_loader.py            # Tests for skill loader
│   ├── test_skill_packs_integrity.py   # Integrity tests for skill_packs YAML vs code
│   ├── test_skill_packs.py             # Behavior tests for skill packs
│   ├── test_skill_registry.py          # SkillRegistry behavior tests
│   ├── test_virtue_compare_plans.py    # Compare plans via virtue metrics tests
│   ├── test_virtue_config_sanity.py    # Virtue config sanity tests
│   ├── test_virtue_hard_constraints.py # Tests enforcing hard virtue constraints on plans
│   ├── test_virtue_lattice_basic.py    # Basic virtue lattice behavior tests
│   └── test_world_tracker.py           # WorldTracker behavior tests
└── tools                               # User-facing helper scripts / demos (outside src/)
    ├── agent_demo.py                   # Demo harness for running an agent loop with configured stack
    ├── phase1_demo.py                  # Phase1 demo script for showing offline pipeline behavior
    └── smoke_botcore.py                # Quick BotCore smoke test tool (manual run)

```

# GTNH_Agent – Project Summary up to M8

_(Study sheet / dev notes with a focus on M9: monitoring_and_tools)_

---

## 1. Big Picture: What This Thing Is

**Goal:**  
A fully local, config-driven Minecraft agent tailored to **GregTech: New Horizons**, capable of:

- Understanding the GTNH world (items, blocks, recipes, tech tiers)
    
- Planning long-horizon projects (e.g. “reach MV steam,” “build eco factory,” “Stargate nonsense”)
    
- Acting via a BotCore interface (observe → plan → execute skills)
    
- Learning from experience traces over time
    

**Phase status (conceptual):**

- **Phase 0:** Environment + config system → **done**
    
- **Phase 1:** LLM stack + semantics + basic skills → **done**
    
- **M0–M8 core runtime stack:**
    
    - M0 env / profiles
        
    - M2 LLM stack
        
    - M3 semantics
        
    - M4 virtues
        
    - M5 skills
        
    - M6 BotCore contracts
        
    - M7 observation pipeline
        
    - **M8 AgentLoop v1**  
        → Functionally wired and passing tests, with offline fakes and clear seams for future upgrades.
        

M9’s job: **observe the observer**. Monitoring and tools sit on top of this stack and make the whole circus inspectable and debuggable.

---

## 2. Core Concepts & Definitions

### 2.1 Environment & Profiles (M0 / `config/` / `env/`)

- **EnvProfile** (`env.loader`, `config/env.yaml`):  
    Central config object describing:
    
    - hardware profile (from `hardware.yaml`)
        
    - model selections (from `models.yaml`)
        
    - Minecraft runtime mode (offline, fake, IPC, etc.)
        
    - runtime context_id, profile_name, etc.
        
- **minecraft.yaml:**  
    Details for how the agent will eventually talk to Minecraft (server, IPC, ports).
    
- **hardware.yaml / models.yaml:**  
    Boundaries for LLM stack:
    
    - which models are allowed
        
    - which quantization
        
    - what the GPU can realistically handle
        

> For M9: EnvProfile gives you identity tags for logs (profile_name, context_id, mode). Use them everywhere.

---

### 2.2 LLM Stack (M2 / `llm_stack/`)

Key pieces:

- `llm_stack.planner.PlannerModel`  
    Generates plans from encoded observations & goals.
    
- `llm_stack.critic.CriticModel`  
    Evaluates traces/plans, returns `CriticResult` dicts (scores, flags, commentary).
    
- `llm_stack.scribe.ScribeModel`  
    Compresses traces/episodes into summaries (for logs, experience, future M10).
    
- `llm_stack.error_model.ErrorModel`  
    Analyzes failures and suggests corrections.
    
- `llm_stack.stack` / `llm_stack.config`  
    Build a full stack based on `env.yaml` + `models.yaml` + `hardware.yaml`.
    
- **Log integration already exists:** `llm_stack.log_files` writes JSON logs into `logs/llm/`.
    

> For M9:
> 
> - You already have structured logs in `logs/llm/`.
>     
> - Monitoring should be able to _tail_ and _summarize_ these per-context, per-model, per-episode.
>     

---

### 2.3 Semantics & Tech State (M3 / `semantics/`)

- **Data sources** (`config/gtnh_*.yaml/json`):
    
    - `gtnh_items*`, `gtnh_blocks*`, `gtnh_recipes*`, `gtnh_tech_graph.yaml`
        
    - Raw dumps in `config/raw/` from TellMe / nerd / CSV dumps.
        
- **Core modules:**
    
    - `semantics.loader` – loads/merges all the semantic data.
        
    - `semantics.crafting` – recipe graph & craftability logic.
        
    - `semantics.categorize` – item/block categories (ores, machines, fuels, etc.).
        
    - `semantics.tech_state` – TechState representation & inference from world state.
        

> For M9:
> 
> - Monitoring should be able to show **current TechState**: tier, milestones, bottlenecks.
>     
> - Think “semantic dashboard”: what tier am I at, what’s blocked, what’s unlocked?
>     

---

### 2.4 Virtues (M4 / `virtues/`)

- **Config:** `config/virtues.yaml` defines:
    
    - virtue lattice nodes
        
    - metrics used for evaluation
        
    - constraints (hard vs soft)
        
- **Core code:**
    
    - `virtues.lattice` – structure of virtues & relationships.
        
    - `virtues.metrics` – calculations for scoring plans/traces.
        
    - `virtues.explain` – human-readable explanations.
        
    - `virtues.sanity` – config sanity checks.
        
- **Loop integration:**
    
    - `spec.agent_loop.VirtueEngine` protocol:
```python

def score_trace(self, trace: PlanTrace, context_id: str) -> Dict[str, float]

```

- - `AgentLoop._maybe_run_virtues` calls the engine if present and writes `trace.virtue_scores`.
        

> For M9:
> 
> - Monitoring should visualize **virtue scores per episode/plan**.
>     
> - This is basically your “ethics / quality” dashboard.
>     

---

### 2.5 Skills (M5 / `skills/` + `config/skills*`)

- **YAML skill specs:** `config/skills/*.yaml`
    
    - Describe high-level skills (chop_tree, feed_coke_ovens, etc.)
        
- **Skill packs:** `config/skill_packs/*.yaml`
    
    - Bundles of skills for specific stages (steam_age, lv_core).
        
- **Runtime:**
    
    - `skills.registry.SkillRegistry` – central lookup + registration.
        
    - `skills.base.*` – Python implementations of skill logic.
        
    - `skills.loader` / `skills.packs` / `skills.schema` – wiring between YAML and runtime.
        

> For M9:
> 
> - Monitoring should be able to show:
>     
>     - Which skills are loaded
>         
>     - Which skills are being used in a plan/episode
>         
>     - Skill success/failure rates over time (event metrics).
>         

---

### 2.6 BotCore & World Snapshots (M6 / `bot_core/`)

**Core responsibilities:**

- Talk to Minecraft (eventually IPC / net).
    
- Provide **RawWorldSnapshot** from world state.
    
- Convert RawWorldSnapshot → `WorldState` for the rest of the stack.
    

Key parts:

- `bot_core.snapshot`
    
    - `RawChunk`, `RawEntity`, `RawWorldSnapshot`
        
    - `snapshot_to_world_state()` adapter (the _only_ place that builds WorldState).
        
- `bot_core.actions`, `bot_core.collision`, `bot_core.world_tracker`, `bot_core.nav.*`
    
    - Nav, pathfinding, action primitives.
        
- `bot_core.runtime`
    
    - `FakeBotCore` implementation:
        
        - `observe()` → returns `RawWorldSnapshot` (contract tested by `test_m6_observe_contract.py`)
            
        - `get_world_state()` → wraps `snapshot_to_world_state()`
            
        - `execute_action()` → supports a `move_to` action, always succeeds.
            
    - `get_bot_core(env_profile_name: Optional[str] = None)` → returns `FakeBotCore` for now.
        

> For M9:
> 
> - Monitoring must be able to:
>     
>     - Inspect **latest RawWorldSnapshot** / WorldState (position, dimension, entities summary).
>         
>     - Show movement & changes over time (ticks, positions, dimension changes).
>         
>     - Tie world snapshots to episodes & traces.
>         

---

### 2.7 Observation & Encoding (M7 / `observation/`)

- **Goal:**  
    Transform `WorldState` into structured inputs for planner/critic and maintain `PlanTrace` / `TraceStep` structures.
    
- **Key structures:**
    
    - `trace_schema.PlanTrace` – episode-level trace:
        
        - `plan`, `steps`, `tech_state`, `planner_payload`, `context_id`, `virtue_scores`
            
    - `trace_schema.TraceStep` – one executed step:
        
        - `world_before`, `action`, `result`, `world_after`, `meta`.
            
- **Pipeline:**
    
    - `observation.pipeline` – end-to-end observation processing chain.
        
    - `observation.encoder` – `encode_for_planner`, `encode_for_critic`, etc.
        

> For M9:
> 
> - Monitoring is basically “visualize PlanTrace + TraceSteps over time, per episode.”
>     
> - Think: timeline views, step tables, last N actions, failures.
>     

---

### 2.8 Agent Runtime & Agent Loop (M6+M7+M8 / `agent/`)

#### AgentRuntime (`agent.runtime_m6_m7`)

- Integrates:
    
    - BotCore (M6)
        
    - Observation pipeline (M7)
        
    - Planner / Critic models (M2)
        
- Provides:
    
    - `planner_tick()` – run a planner step:
        
        - observe
            
        - encode
            
        - call planner
            
    - `get_latest_planner_observation()` – returns last obs used for planning.
        
    - `execute_plan_step(step_spec, step_idx)` – executes plan steps via BotCore and returns `List[TraceStep]`.
        
    - Accessors for tech state, context_id, and critic model.
        

#### AgentLoop (M8 / `agent.loop`)

- **Config:** `AgentLoopConfig`
    
    - `enable_critic`, `store_experiences`
        
    - `max_planner_calls`, `max_skill_steps`
        
    - `fail_fast_on_invalid_plan`
        
    - `log_virtue_scores`, `log_traces` (telemetry flags)
        
- **EpisodeResult:**
    
    - `episode_id`, `plan`, `trace`, `critic_result`, `started_at`, `finished_at`.
        
- **AgentLoop responsibilities:**
    
    1. `_call_planner_once()`
        
        - Calls `runtime.planner_tick()`
            
        - Validates output shape (must have `"steps"` if `fail_fast_on_invalid_plan`).
            
    2. `_build_initial_trace(plan)`
        
        - Pulls:
            
            - latest planner observation
                
            - tech_state
                
            - context_id
                
        - Builds `PlanTrace` with empty `steps`.
            
    3. `_execute_plan_into_trace(plan, trace)`
        
        - Iterates over `plan["steps"]` up to `max_skill_steps`.
            
        - Calls `runtime.execute_plan_step(step_spec, step_idx)` → `List[TraceStep]`.
            
        - Appends TraceSteps to `trace.steps`.
            
        - Stops early on failure.
            
    4. `_maybe_run_critic(trace)`
        
        - If `enable_critic` and `critic_model` present:
            
            - builds critic payload with `encode_for_critic`
                
            - calls `critic_model.evaluate`
                
            - returns `CriticResult` or `None` on failure.
                
    5. `_maybe_run_virtues(trace)`
        
        - If `log_virtue_scores` and `virtue_engine` present:
            
            - calls `virtue_engine.score_trace`
                
            - stores results in `trace.virtue_scores`.
                
    6. `_store_experience(result)`
        
        - Converts `EpisodeResult` + trace into `Experience`:
            
            - snapshots tech_state (to dict)
                
            - pulls `env_profile_name`, `context_id`
                
            - adds meta: `duration_sec`, `planner_model`
                
        - Appends to `ExperienceBuffer`.
            
- **Experience layer (`agent.experience`):**
    
    - `Experience`:
        
        - `trace`, `critic_result`, `episode_id`
            
        - `env_profile_name`, `context_id`
            
        - `tech_state_snapshot`, `meta`
            
        - `timestamp` auto-set.
            
    - `ExperienceBuffer`:
        
        - Append-only list.
            
        - `.add(...)`, `.last()`, `__len__`.
            

> For M9:
> 
> - AgentLoop + ExperienceBuffer give you **perfect monitoring hooks**:
>     
>     - Per-episode timings
>         
>     - Per-episode plan structure
>         
>     - Critic decisions
>         
>     - Virtue scores
>         
>     - TechState snapshots
>         
> - Monitoring should subscribe to these and present them as live dashboards and historical views.
>     

---

## 3. Key Design Choices / Insights

1. **Pure-Python, config-driven architecture:**
    
    - No external agents/frameworks glued in.
        
    - All “fancy patterns” (Voyager, Reflexion, RL rollouts) are stolen as _ideas_, not dependencies.
        
2. **Separation of raw vs semantic world:**
    
    - RawWorldSnapshot → `WorldState` → Semantics / TechState.
        
    - M6 doesn’t know about GTNH semantics; M3 owns that.
        
3. **Episode-centric design:**
    
    - M8 is explicitly about **episodes**, not a noisy tick loop.
        
    - `run_episode()` = stable interface:
        
        - plan → execute → critic → virtues → experience.
            
4. **Trace-first worldview:**
    
    - `PlanTrace` and `TraceStep` are the backbone.
        
    - Monitoring, learning, debugging all revolve around them.
        
5. **Critic & virtues are advisory, never fatal:**
    
    - Errors are logged and swallowed.
        
    - This design prevents one bad critic run from killing the loop.
        
6. **Fake runtime/BotCore is first-class:**
    
    - Complete offline stack:
        
        - FakeBotCore
            
        - FakeAgentRuntime
            
        - Fake LLM stack
            
    - Lets you iterate on cognition & monitoring **without** attaching to a real server.
        

---

## 4. What Matters For M9 – monitoring_and_tools

M9 is where you stop flying blind and actually _see_ what the agent is thinking / doing.

### 4.1 Existing Monitoring Skeleton

- `monitoring/`:
    
    - `bus.py` – event bus for system events.
        
    - `events.py` – event type definitions.
        
    - `controller.py` – central orchestrator / subscription logic.
        
    - `logger.py` – structured logger.
        
    - `dashboard_tui.py` – TUI for real-time display.
        
- `logs/llm/`:
    
    - JSON logs from planner / critic / scribe / error_model.
        

> M9 should treat these as the **backbone**, not afterthoughts.

---

### 4.2 Core Monitoring Questions to Answer

M9 tooling should make it trivial to answer:

1. **What is the agent doing right now?**
    
    - Current goal (once you expose it)
        
    - Active plan (from `EpisodeResult.plan`)
        
    - Current/last TraceStep (action, result, world_before/after)
        
2. **What did the last episode look like?**
    
    - Plan steps, success/failure
        
    - Episode duration
        
    - Critic verdict
        
    - Virtue scores
        
    - TechState evolution
        
3. **Is the system healthy?**
    
    - LLM errors (from `error_model` logs)
        
    - Plan validation failures (`planner_guardrails`)
        
    - Semantics cache issues
        
    - BotCore observation failures
        
4. **What is the agent learning / trending toward?**
    
    - ExperienceBuffer size / growth
        
    - Frequent actions/skills
        
    - Failure hot spots
        
    - Virtue score drift over time
        

---

### 4.3 High-Value Monitoring Hooks (Where to Tap)

M9 should tap into:

- `AgentLoop.run_episode`:
    
    - Emit events on:
        
        - episode_started / episode_finished
            
        - plan_generated
            
        - steps_executed (with TraceStep summaries)
            
        - critic_evaluated
            
        - virtues_scored
            
        - experience_recorded
            
- `AgentRuntime`:
    
    - Events for planner calls, critic calls, observation snapshots.
        
- `BotCore`:
    
    - Events on `observe()` and `execute_action()`:
        
        - tick, dimension, pos
            
        - action type, success/fail
            
- `llm_stack`:
    
    - Events for request/response, latency, errors.
        

And send all of that through `monitoring.bus` + `monitoring.logger` to:

- `dashboard_tui` (live view)
    
- Log files (`logs/`) for later analysis
    

---

### 4.4 Tools for Humans (you, unfortunately)

Beyond background monitoring, M9 should ship with **tools you actually use**:

- CLI / TUI tools:
    
    - View current EnvProfile, TechState, active skills.
        
    - Inspect last N episodes (plans, traces, virtues, critic results).
        
    - Tail LLM logs with filtering by context_id, model, or role.
        
- Dev scripts:
    
    - Sanity check: “can I see BotCore position, TechState, and last plan from one command?”
        
    - Dump a single episode as a compact JSON bundle to feed into docs / Obsidian.
        

---

## 5. Short Checklist for M9

When you open M9, this is the “do not ignore” list:

1. **Integrate AgentLoop with monitoring bus**
    
    - Emit events at each major stage of `run_episode`.
        
2. **Wire BotCore & AgentRuntime into monitoring**
    
    - Observation & execution events with tick/position/action summaries.
        
3. **Build or polish `dashboard_tui`**
    
    - Show:
        
        - latest episode status
            
        - last few actions
            
        - virtue scores
            
        - basic LLM stats (calls, errors)
            
4. **Normalize logging IDs**
    
    - Make sure `context_id`, `episode_id`, `env_profile_name` appear in:
        
        - monitoring events
            
        - LLM logs
            
        - experience records
            
5. **Add tools/CLI commands that hit real code paths**
    
    - One command to:
        
        - run a fake episode
            
        - log & show its trace
            
        - summarize it for you
            

---

You’ve got a working offline agent brain, a fake body, and a growing theology of virtues.  
M9 is where you give it a **nervous system and a HUD** so you don’t go insane debugging it.




