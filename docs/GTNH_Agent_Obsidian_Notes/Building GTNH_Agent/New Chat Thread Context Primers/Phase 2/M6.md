Here is an overview of the entire project for your context:

Phase 0:

M0 - environment_foundation

**Purpose:**

Lock in the actual environment & runtimes.

- Define:

- MC 1.7.10 + Forge 10.13.4.1614 + GTNH 2.8.1 run profile

- Decision: external bot client vs in-process Forge mod with IPC

- Hardware constraints for local LLMs

- **Dependencies:** None

- **Difficulty:** ⭐

- **Scalability notes:**

- Document this in a single config file / README; future changes (new model, new server host) should not touch code.

M1 - agent_architecture_spec

**Purpose:**  
Unify Mineflayer + Voyager insights into a **single architecture spec**.

- Extract from Mineflayer:
    
    - Bot lifecycle
        
    - World model
        
    - Pathfinding
        
    - Action abstraction
        
- Extract from Voyager:
    
    - Planner → Skill library → Execution loop
        
    - Reflection & learning
        
- **Dependencies:** `M0`
    
- **Difficulty:** ⭐⭐
    
- **Scalability notes:**
    
    - Produce one canonical architecture doc: diagrams + interfaces.
        
    - This is the contract everything else conforms to.


Phase 1

M2 - llm_stack_local

**Purpose:**  
Provide reusable interfaces around local models.

- Implement:
    
    - `PlannerModel`: high-level plan generation
        
    - `CodeModel`: skill/code generation
        
    - `CriticModel`: evaluation / refinement
        
- Unified tool schema:
    
    - Input: structured state / goal
        
    - Output: JSON plan / skill spec, no direct MC calls
        
- **Dependencies:** `M1`
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Centralize model loading & caching.
        
    - Make batch calls possible.
        
    - Log prompts/responses for replay.

M3 - world_semantics_gtnh

**Purpose:**  
Define GTNH tech + world understanding as **data + logic**.

- Data layer (config files):
    
    - Block categories (ores, machines, cables, etc.)
        
    - Item categories (plates, circuits, tools)
        
    - Tech states & prereqs (LV steam, MV, etc.)
        
- Logic layer (Python):
    
    - `infer_tech_state(inventory, machines)`
        
    - `suggest_next_targets(tech_state)`
        
    - `craftable_items(inventory, known_recipes)`
        
- **Dependencies:** `M1`
    
- **Difficulty:** ⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Keep recipes & categories in JSON/YAML, not code.
        
    - Cache derived graphs (like tech dependency DAGs).

M4 - virtue_lattice

**Purpose:**  
Encapsulate your Sefirot-based virtues as a reusable scoring layer.

- Define:
    
    - Virtue nodes: Efficiency, Safety, Sustainability, etc.
        
    - Configurable weights per context (e.g., early LV vs late HV)
        
- APIs:
    
    - `score_plan(plan, context) -> dict[virtue -> score]`
        
    - `compare_plans(plans, context) -> best_plan`
        
- **Dependencies:** `M3` (for context & environment semantics)
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Pure functions, stateless, easy to unit test.
        
    - Configurable weights → you can tune without code changes.

M5 - skill_registry

**Purpose:**  
Central place for skill definitions and metadata.

- Skill spec:
    
    - Name, parameters
        
    - Preconditions (what world/tech state is required)
        
    - Effects (changes in world/tech state)
        
    - Tags (e.g., mining, crafting, building)
        
- LLM interaction:
    
    - Planner only sees skill metadata, not raw code.
        
    - Skill implementations live as Python methods or small scripts.
        
- **Dependencies:** `M1`, `M3`
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Skills registered via decorators or config files.
        
    - Easy to version and deprecate skills over time.

Phase 2:

M6 - bot_core_1_7_10

**Purpose:**  
Provide a stable, testable “body” that can be used by any controller.

- Capabilities:
    
    - Connect/keepalive
        
    - World tracking (chunks, entities)
        
    - Navigation (A* or similar)
        
    - Actions:
        
        - Move, jump, break block, place block, use item, interact with tile entities
            
- API:
    
    - `observe() -> RawWorldSnapshot`
        
    - `execute_action(Action) -> Result`
        
- **Dependencies:** `M0`, `M1`
    
- **Difficulty:** ⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Keep logic modular: pathfinding, inventory, world tracking as submodules.
        
    - Limit unnecessary packet decoding; cache what you can.

M7 - observation_encoding

**Purpose:**  
Map `RawWorldSnapshot` from `M6` into semantic state used by LLMs & planners.

- Functions:
    
    - `encode_for_planner(raw_snapshot, tech_state) -> JSON`
        
    - `encode_for_critic(trace) -> JSON`
        
- Uses:
    
    - `M3` (semantics)
        
    - `M4` (virtues context)
        
- **Dependencies:** `M3`, `M6`
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Keep encodings compact. Summaries + key entities, not entire chunks.
        
    - Enforce stable schema to avoid breaking old skills.

Phase 3:

M8 - agent_loop_v1

**Purpose:**  
Implement the core loop: observe → plan → choose skills → act → evaluate.

- High-level algorithm:
    
    1. `state = observe()`
        
    2. `tech_state = infer_tech_state(state)`
        
    3. `plan = planner_model.call(state, tech_state, skill_registry, virtues)`
        
    4. Decompose plan into skill invocations
        
    5. Execute via `bot_core_1_7_10`
        
    6. Log result for learning (`M10`)
        
- Strict separation:
    
    - No direct packet calls here.
        
    - No GTNH-hardcoded weirdness here; that lives in `M3` and `M5`.
        
- **Dependencies:**
    
    - `M2` (LLM stack)
        
    - `M3` (world semantics)
        
    - `M4` (virtues)
        
    - `M5` (skills)
        
    - `M6` (bot core)
        
    - `M7` (observation encoding)
        
- **Difficulty:** ⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Design as a state machine with clear states (Idle, Planning, Executing, Recovering).
        
    - Rate-limit LLM calls, reuse plans until invalidated.

M9 - monitoring_and_tools

**Purpose:**  
Give you observability and a control surface before the system gaslights you.

- Features:
    
    - Structured logs (JSON)
        
    - Web or TUI dashboard:
        
        - World overview
            
        - Current plan & skills
            
        - Virtue scores
            
        - Tech state
            
    - Manual controls:
        
        - Pause, step, cancel plan, inspect memory
            
- **Dependencies:** `M8`
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Central logger used by all modules.
        
    - Minimal UI first; upgrade visuals later.


Phase 4:

M10 - skill_learning

**Purpose:**  
Voyager-style learning: derive new skills from experience and refine existing ones.

- Components:
    
    - Experience buffer:
        
        - `{state, goal, plan, actions, outcomes, virtue_scores}`
            
    - LLM-based synthesizer:
        
        - Turn repeated success traces into new skill definitions
            
    - Evaluator:
        
        - Compare new vs existing skills on:
            
            - Success rate
                
            - Cost (time, resources)
                
            - Virtue scores
                
- **Dependencies:** `M8` (loop), `M2` (LLMs), `M5` (skill registry), `M4` (virtue scoring)
    
- **Difficulty:** ⭐⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Learning should be offline or scheduled, not constant.
        
    - Skills versioned and can be rolled back if regressions appear.


M11 - gtnh_curriculum_and_specialization

**Purpose:**  
Turn the generic learning agent into a **GTNH-native progression engine**.

- Define:
    
    - Curricula per phase:
        
        - Early LV goals
            
        - Steam infra goals
            
        - MV automation goals
            
    - Long-horizon projects:
        
        - Stargate, high-tier reactors, etc.
            
- The curriculum is:
    
    - A sequence of target tech states
        
    - Each with:
        
        - Reward shaping (virtue weight tweaks)
            
        - Suggested skills to prioritize / learn
            
- **Dependencies:** `M3`, `M5`, `M8`, `M10`
    
- **Difficulty:** ⭐⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Curriculum is config, not code.
        
    - Multiple curricula can be swapped (e.g. “eco base”, “speedrun”, “aesthetic build”).


Shortcut View:
# **Phase P0 — Foundations**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M0**|environment_foundation|⭐|0.5–2 days|Lock runtime, modpack, IPC choice|
|**M1**|agent_architecture_spec|⭐⭐|2–4 days|Full architecture doc|

### **Phase P0 Total:**

**Difficulty Avg:** ⭐⭐  
**Time:** ~3–6 days

---

# **Phase P1 — Offline Core Pillars (No Minecraft)**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M2**|llm_stack_local|⭐⭐–⭐⭐⭐|3–7 days|Local models, prompt tooling|
|**M3**|world_semantics_gtnh|⭐⭐⭐⭐|7–14 days|Tech tree + ontology mapping|
|**M4**|virtue_lattice|⭐⭐–⭐⭐⭐|3–6 days|Scoring/weights system|
|**M5**|skill_registry|⭐⭐–⭐⭐⭐|3–6 days|Skill definitions, metadata|

### **Phase P1 Total:**

**Difficulty Avg:** ⭐⭐⭐  
**Time:** ~2–4 weeks

---

# **Phase P2 — Minecraft Integration Layer**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M6**|bot_core_1_7_10|⭐⭐⭐⭐|2–4 weeks|Pathfinding, inventory, world tracking|
|**M7**|observation_encoding|⭐⭐–⭐⭐⭐|3–7 days|Convert raw MC data → semantic state|

### **Phase P2 Total:**

**Difficulty Avg:** ⭐⭐⭐⭐  
**Time:** ~3–5 weeks

---

# **Phase P3 — Agent Orchestration & Tooling**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M8**|agent_loop_v1|⭐⭐⭐⭐|1–2 weeks|Full observe → plan → act|
|**M9**|monitoring_and_tools|⭐⭐–⭐⭐⭐|3–7 days|Logs, dashboards, step controls|

### **Phase P3 Total:**

**Difficulty Avg:** ⭐⭐⭐⭐  
**Time:** ~2–3 weeks

---

# **Phase P4 — Learning & Specialization**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M10**|skill_learning|⭐⭐⭐⭐⭐|2–4 weeks|Voyager-style skill synthesis|
|**M11**|gtnh_curriculum_and_specialization|⭐⭐⭐⭐⭐|multi-week ongoing|Long-horizon GTNH progression logic|

### **Phase P4 Total:**

**Difficulty Avg:** ⭐⭐⭐⭐⭐  
**Time:** ~4–8+ weeks (ongoing beyond initial build)

---

# **Grand Totals (First-Pass Implementation)**

|Phase|Difficulty Avg|Total Time|
|---|---|---|
|**P0**|⭐⭐|3–6 days|
|**P1**|⭐⭐⭐|2–4 weeks|
|**P2**|⭐⭐⭐⭐|3–5 weeks|
|**P3**|⭐⭐⭐⭐|2–3 weeks|
|**P4**|⭐⭐⭐⭐⭐|4–8+ weeks|

---

File Structure:
```
GTNH_Agent                               # Project root: fully-local GTNH automation agent
├── bootstrap_structure.py               # Script to create/repair base project folder structure
├── config                               # All configuration & data (no real logic)
│   ├── curricula                        # Curricula = long-horizon goal programs
│   │   ├── aesthetic_megabase.yaml      # Curriculum for big pretty base / megabuild focus
│   │   ├── default_speedrun.yaml        # “Normal” progression path / speedrun-ish route
│   │   └── eco_factory.yaml             # Efficiency/throughput factory progression curriculum
│   ├── env.yaml                         # Phase 0 env profiles (worlds, installs, runtime profiles)
│   ├── gtnh_blocks.generated.yaml       # Auto-generated block semantics from ingest scripts
│   ├── gtnh_blocks.yaml                 # Hand-tuned block overrides / curated semantics
│   ├── gtnh_items.generated.yaml        # Auto-generated item semantics from raw GTNH exports
│   ├── gtnh_items.yaml                  # Manually curated item groupings/categories
│   ├── gtnh_recipes.agent.json          # Compacted recipe set optimized for LLM consumption
│   ├── gtnh_recipes.generated.json      # Raw-ish generated recipes from ingest pipeline
│   ├── gtnh_recipes.json                # Canonical cleaned recipes semantics reads
│   ├── gtnh_tech_graph.yaml             # Tech graph: tiers & unlock relations for GTNH
│   ├── hardware.yaml                    # Hardware profiles (GPU, RAM, threads, model limits)
│   ├── llm_roles.yaml                   # LLM role presets (planner/critic/scribe/error model)
│   ├── minecraft.yaml                   # Minecraft / GTNH runtime config (paths, versions, IPC)
│   ├── models.yaml                      # Local model registry: engine, file path, params, roles
│   ├── raw                              # Raw source dumps before normalization/compaction
│   │   ├── block.csv                    # “Nerd CSV” raw block metadata
│   │   ├── item.csv                     # “Nerd CSV” raw item metadata
│   │   ├── recipes.json                 # Raw recipes export
│   │   └── recipes_stacks.json          # Raw recipes with stack size / quantity information
│   ├── skill_packs                      # SkillPack definitions (group skills by tech/context)
│   │   ├── lv_core.yaml                 # LV core pack (chop trees, basic crafting, etc.)
│   │   └── steam_age.yaml               # Steam-age infra pack (boilers, coke ovens, water)
│   ├── skills                           # YAML SkillSpecs for implemented skills (M5)
│   │   ├── basic_crafting.yaml          # Spec for performing generic crafting actions
│   │   ├── chop_tree.yaml               # Spec: parameters/effects for tree chopping
│   │   ├── feed_coke_ovens.yaml         # Spec: feeding coke ovens with fuel / inputs
│   │   ├── feed_steam_boiler.yaml       # Spec: feeding steam boilers with fuel
│   │   ├── maintain_coke_ovens.yaml     # Spec: clearing ash / upkeep for coke ovens
│   │   ├── plant_sapling.yaml           # Spec: planting saplings around the base
│   │   └── refill_water_tanks.yaml      # Spec: refilling boiler tanks / water infrastructure
│   ├── skills_candidates                # Draft / experimental SkillSpecs not wired into packs
│   ├── tools                            # Config-level CLIs / helpers
│   │   ├── print_env.py                 # Pretty-print current env profile from env.yaml
│   │   └── validate_env.py              # Validate env/models/hardware configs are coherent
│   └── virtues.yaml                     # Virtue lattice configuration (nodes, weights, contexts)
├── docs                                 # Human-facing documentation
│   ├── architecture.md                  # High-level system architecture & module map
│   └── phase1_integration.md            # Design doc for Phase 1 integration (M2–M5 + P0 bridge)
├── .github
│   └── workflows
│       └── ci.yml                       # CI pipeline (pytest, maybe lint, etc.)
├── .gitignore                           # Ignore venvs, caches, logs, build artifacts
├── logs
│   └── llm                              # LLM stack run logs (planner / error-model / scribe)
│       ├── 20251127T154508_30389_error_model_analyze_failure.json   # Error-model run record
│       ├── 20251127T154508_30389_plan_code_plan.json                # Planner/codegen log
│       ├── 20251127T154508_30389_scribe_summarize_trace.json        # Scribe summarization log
│       ├── 20251127T154653_30421_plan_code_plan.json                # (Remaining: similar runs…)
│       ├── 20251127T154929_30485_error_model_analyze_failure.json   #  ^
│       ├── 20251127T155054_30542_scribe_summarize_trace.json        #  ^
│       ├── 20251127T171641_54578_plan_code_plan.json
│       ├── 20251127T172238_54966_plan_code_plan.json
│       ├── 20251127T172404_55071_plan_code_plan.json
│       ├── 20251127T181107_57121_plan_code_plan.json
│       ├── 20251127T181432_57416_plan_code_plan.json
│       ├── 20251127T202123_80866_error_model_analyze_failure.json
│       ├── 20251127T202123_80866_plan_code_plan.json
│       ├── 20251127T202123_80866_scribe_summarize_trace.json
│       ├── 20251127T202334_80953_error_model_analyze_failure.json
│       ├── 20251127T202334_80953_plan_code_plan.json
│       ├── 20251127T202334_80953_scribe_summarize_trace.json
│       ├── 20251127T223951_107281_error_model_analyze_failure.json
│       ├── 20251127T223951_107281_plan_code_plan.json
│       ├── 20251127T223951_107281_scribe_summarize_trace.json
│       ├── 20251128T001446_136742_error_model_analyze_failure.json
│       ├── 20251128T001446_136742_plan_code_plan.json
│       ├── 20251128T001446_136742_scribe_summarize_trace.json
│       ├── 20251128T003700_146815_error_model_analyze_failure.json
│       ├── 20251128T003700_146815_plan_code_plan.json
│       ├── 20251128T003700_146815_scribe_summarize_trace.json
│       ├── 20251128T115106_24456_error_model_analyze_failure.json
│       ├── 20251128T115106_24456_plan_code_plan.json
│       ├── 20251128T115106_24456_scribe_summarize_trace.json
│       ├── 20251128T143640_52852_error_model_analyze_failure.json
│       ├── 20251128T143640_52852_plan_code_plan.json
│       ├── 20251128T143640_52852_scribe_summarize_trace.json
│       ├── 20251128T143816_52937_error_model_analyze_failure.json
│       ├── 20251128T143816_52937_plan_code_plan.json
│       ├── 20251128T143816_52937_scribe_summarize_trace.json
│       ├── 20251128T153451_109564_error_model_analyze_failure.json
│       ├── 20251128T153451_109564_plan_code_plan.json
│       ├── 20251128T153451_109564_scribe_summarize_trace.json
│       ├── 20251128T154112_109913_error_model_analyze_failure.json
│       ├── 20251128T154112_109913_plan_code_plan.json
│       ├── 20251128T154112_109913_scribe_summarize_trace.json
│       ├── 20251128T154622_110074_error_model_analyze_failure.json
│       ├── 20251128T154622_110074_plan_code_plan.json
│       ├── 20251128T154622_110074_scribe_summarize_trace.json
│       ├── 20251128T155834_129265_error_model_analyze_failure.json
│       ├── 20251128T155834_129265_plan_code_plan.json
│       ├── 20251128T155834_129265_scribe_summarize_trace.json
│       ├── 20251128T160155_129475_error_model_analyze_failure.json
│       ├── 20251128T160155_129475_plan_code_plan.json
│       ├── 20251128T160155_129475_scribe_summarize_trace.json
│       ├── 20251128T160633_142703_error_model_analyze_failure.json
│       ├── 20251128T160633_142703_plan_code_plan.json
│       ├── 20251128T160633_142703_scribe_summarize_trace.json
│       ├── 20251128T162316_143085_error_model_analyze_failure.json
│       ├── 20251128T162316_143085_plan_code_plan.json
│       ├── 20251128T162316_143085_scribe_summarize_trace.json
│       ├── 20251128T162956_163507_error_model_analyze_failure.json
│       ├── 20251128T162956_163507_plan_code_plan.json
│       ├── 20251128T162956_163507_scribe_summarize_trace.json
│       ├── 20251128T164527_184688_error_model_analyze_failure.json
│       ├── 20251128T164527_184688_plan_code_plan.json
│       ├── 20251128T164527_184688_scribe_summarize_trace.json
│       ├── 20251128T164725_184780_error_model_analyze_failure.json
│       ├── 20251128T164725_184780_plan_code_plan.json
│       ├── 20251128T164725_184780_scribe_summarize_trace.json
│       ├── 20251128T164846_185052_error_model_analyze_failure.json
│       ├── 20251128T164846_185052_plan_code_plan.json
│       └── 20251128T164846_185052_scribe_summarize_trace.json
├── pyproject.toml                        # Project config & packaging metadata (deps, entrypoints)
├── .pytest_cache                         # pytest’s local cache (auto-generated)
│   ├── CACHEDIR.TAG
│   ├── .gitignore
│   ├── README.md
│   └── v
│       └── cache
│           ├── lastfailed                # Tracks last failed tests for quick reruns
│           └── nodeids                   # Cached IDs for test nodes
├── .python-version                       # Python version hint for pyenv/tooling
├── README.md                             # Top-level readme for humans
├── scripts                               # Dev scripts & utilities (not importable modules)
│   ├── compact_recipes_for_agent.py      # Build compact agent-focused recipe graph
│   ├── demo_offline_agent_step.py        # Demonstrate a single offline agent planning step
│   ├── dev_shell.py                      # Drop into a configured dev REPL / shell
│   ├── ingest_gtnh_semantics.py          # Ingest GTNH data into semantics config files
│   ├── ingest_nerd_csv_semantics.py      # Import “nerd CSV” block/item data into semantics
│   ├── ingest_nerd_recipes.py            # Convert raw recipe dumps into generated recipe JSONs
│   ├── smoke_error_model.py              # Smoke test for error-model pipeline
│   ├── smoke_llm_stack.py                # Smoke test for LLM stack wiring / configs
│   └── smoke_scribe_model.py             # Smoke test for scribe/compression model
├── src                                   # Actual Python package code (gtnh_agent)
│   ├── agent_loop                        # Agent loop: observe → plan → act cycles
│   │   ├── __init__.py                   # Package init for agent_loop
│   │   ├── loop.py                       # Main loop logic & control flow
│   │   ├── schema.py                     # Types/schemas for loop episodes & steps
│   │   └── state.py                      # State machine / episode state management
│   ├── app                               # App-level runtime glue
│   │   ├── __init__.py                   # Package init for app
│   │   └── runtime.py                    # Launcher / orchestration for running the agent “for real”
│   ├── bot_core                          # Core bot abstractions (Minecraft-side)
│   │   ├── actions.py                    # Definitions of low-level actions the bot can perform
│   │   ├── core.py                       # Central control logic for bot behavior
│   │   ├── __init__.py                   # Package init for bot_core
│   │   ├── nav                           # Navigation subsystem
│   │   │   ├── grid.py                   # Grid representation for pathfinding
│   │   │   ├── __init__.py               # Package init for nav
│   │   │   ├── mover.py                  # High-level movement controller (uses pathfinder)
│   │   │   └── pathfinder.py             # Pathfinding algorithms and utilities
│   │   ├── net                           # Network / IPC layer
│   │   │   ├── client.py                 # Bot-side client implementation
│   │   │   ├── __init__.py               # Package init for net
│   │   │   └── ipc.py                    # IPC protocol & message helpers
│   │   ├── snapshot.py                   # World snapshot structure and capture logic
│   │   └── world_tracker.py              # Track world changes across ticks for the bot
│   ├── cli
│   │   └── phase1_offline.py             # CLI entrypoint for Phase 1 offline planning runs
│   ├── curriculum                        # Curriculum engine (maps profiles → tasks/goals)
│   │   ├── engine.py                     # Core curriculum logic and selection
│   │   ├── __init__.py                   # Package init for curriculum
│   │   ├── loader.py                     # Load curricula from config/curricula/*.yaml
│   │   └── schema.py                     # Types & validation for curriculum configs
│   ├── env                               # Phase 0 runtime environment layer
│   │   ├── __init__.py                   # Package init for env
│   │   ├── loader.py                     # Load env profiles from env.yaml
│   │   └── schema.py                     # EnvProfile types / data model
│   ├── gtnh_agent.egg-info               # Build system metadata (generated by packaging)
│   │   ├── dependency_links.txt
│   │   ├── PKG-INFO
│   │   ├── requires.txt
│   │   ├── SOURCES.txt
│   │   └── top_level.txt
│   ├── __init__.py                       # Top-level gtnh_agent package init
│   ├── integration                       # Cross-module integration & validators
│   │   ├── adapters
│   │   │   └── m0_env_to_world.py        # Adapter: Phase 0 EnvProfile → Phase 1 WorldState
│   │   ├── episode_logging.py            # EpisodeLogger & correlation ID utilities
│   │   ├── __init__.py                   # Package init for integration
│   │   ├── phase1_integration.py         # P1 orchestrator: run_phase1_planning_episode
│   │   ├── testing
│   │   │   ├── fakes.py                  # Fakes for planner/virtues/semantics in tests
│   │   │   └── __init__.py               # Package init for integration.testing
│   │   └── validators                    # System-level integrity / regression checks
│   │       ├── __init__.py               # Package init for validators
│   │       ├── planner_guardrails.py     # Sanity checks for planner outputs
│   │       ├── semantics_snapshots.py    # Snapshot-based tests for semantics regressions
│   │       ├── skill_integrity.py        # SkillSpec/SkillPack/registry consistency checks
│   │       └── virtue_snapshots.py       # Snapshot tests for virtue lattice behavior
│   ├── learning                          # Experience / learning layer (future training hooks)
│   │   ├── buffer.py                     # Replay buffer structure & storage logic
│   │   ├── evaluator.py                  # Offline evaluation of plans/policies
│   │   ├── __init__.py                   # Package init for learning
│   │   ├── manager.py                    # Orchestrate training/eval cycles (eventual use)
│   │   ├── schema.py                     # Types for experiences, metrics, traces
│   │   └── synthesizer.py                # Synthetic experience generator / augmentation
│   ├── llm_stack                         # M2: LLM stack (planner, critic, scribe, error model)
│   │   ├── backend_llamacpp.py           # llama.cpp backend implementation
│   │   ├── backend.py                    # Backend Protocol for all local LLM engines
│   │   ├── codegen.py                    # Code-generation helpers (for tools/skills/tests)
│   │   ├── config.py                     # Stack configuration loader and validation
│   │   ├── critic.py                     # Critic model orchestration / interface
│   │   ├── error_model.py                # Error-model logic (analyze failures, suggest retries)
│   │   ├── __init__.py                   # Package init for llm_stack
│   │   ├── json_utils.py                 # JSON safety / schema helpers for LLM outputs
│   │   ├── log_files.py                  # Naming and writing logs into logs/llm
│   │   ├── plan_code.py                  # Plan/code generation orchestration
│   │   ├── planner.py                    # PlannerBackend definitions + planner wrapper
│   │   ├── presets.py                    # Prompt presets and role definitions
│   │   ├── schema.py                     # Types for planner I/O, error-model I/O, etc.
│   │   ├── scribe.py                     # Scribe model: compress traces / summarize episodes
│   │   └── stack.py                      # High-level LLM pipeline orchestration
│   ├── monitoring                        # Monitoring / observability layer
│   │   ├── bus.py                        # Event bus for monitoring events
│   │   ├── controller.py                 # Controller over monitoring pipeline / subscriptions
│   │   ├── dashboard_tui.py              # TUI dashboard for runtime status
│   │   ├── events.py                     # Event type definitions
│   │   ├── __init__.py                   # Package init for monitoring
│   │   └── logger.py                     # Logging sinks & adapters
│   ├── observation                       # Observation encoding for LLMs
│   │   ├── encoder.py                    # Encode WorldState → planner/critic input structures
│   │   ├── __init__.py                   # Package init for observation
│   │   ├── schema.py                     # Types for observations
│   │   └── trace_schema.py               # Types for full episode traces
│   ├── semantics                         # M3: World/tech semantics for GTNH
│   │   ├── cache.py                      # Semantics DB caching / singleton management
│   │   ├── categorize.py                 # Item/block categorization logic
│   │   ├── crafting.py                   # Craftability / recipe-based reasoning
│   │   ├── ingest
│   │   │   └── __init__.py               # Ingest module placeholder (if expanded later)
│   │   ├── __init__.py                   # Package init for semantics
│   │   ├── loader.py                     # Load semantics DB from config/gtnh_* files
│   │   ├── schema.py                     # Types for items, blocks, recipes, semantics entries
│   │   └── tech_state.py                 # Infer tech_state from world + tech graph
│   ├── skills                            # M5: Skill registry + SkillPack system
│   │   ├── base                          # Concrete skill implementations (Python side)
│   │   │   ├── basic_crafting.py         # Implementation of basic_crafting SkillSpec
│   │   │   ├── chop_tree.py              # Implementation of chop_tree SkillSpec
│   │   │   ├── feed_coke_ovens.py        # Implementation of feed_coke_ovens SkillSpec
│   │   │   ├── feed_steam_boiler.py      # Implementation of feed_steam_boiler SkillSpec
│   │   │   ├── __init__.py               # Imports skills & registers them with SkillRegistry
│   │   │   ├── maintain_coke_ovens.py    # Implementation of maintain_coke_ovens SkillSpec
│   │   │   ├── plant_sapling.py          # Implementation of plant_sapling SkillSpec
│   │   │   └── refill_water_tanks.py     # Implementation of refill_water_tanks SkillSpec
│   │   ├── __init__.py                   # Package init; imports base to trigger registrations
│   │   ├── loader.py                     # Load SkillSpecs from config/skills/*.yaml
│   │   ├── packs.py                      # SkillPack structures & loader
│   │   ├── registry.py                   # SkillRegistry + @register_skill decorator
│   │   └── schema.py                     # Types for SkillSpec, SkillEffects, SkillMetrics, etc.
│   ├── spec                              # Formal interface contracts for subsystems
│   │   ├── agent_loop.py                 # Spec for agent loop API
│   │   ├── bot_core.py                   # Spec for bot_core interfaces
│   │   ├── experience.py                 # Spec for experience / learning payloads
│   │   ├── __init__.py                   # Package init for spec
│   │   ├── llm.py                        # Spec for planner/critic/scribe/error-model APIs
│   │   ├── skills.py                     # Spec for Skill implementations
│   │   └── types.py                      # Shared types: WorldState, TechState-ish, Action, etc.
│   ├── testing                           # Testing helper package
│   │   └── __init__.py                   # Placeholder for shared test utilities
│   └── virtues                           # M4: Virtue lattice / scoring engine
│       ├── explain.py                    # Turn virtue scores into human-readable explanations
│       ├── features.py                   # summarize_plan + feature extraction from plans
│       ├── __init__.py                   # Package init for virtues
│       ├── lattice.py                    # Virtue lattice scoring & compare_plans
│       ├── loader.py                     # Load virtue config from config/virtues.yaml
│       ├── metrics.py                    # Virtue-related metric definitions
│       ├── sanity.py                     # Sanity checks for configs and lattice behavior
│       └── schema.py                     # Types for virtue graph, weights, contexts
├── tests                                 # Pytest suite (unit + integration)
│   ├── conftest.py                       # Shared pytest fixtures & configuration
│   ├── fakes                             # Test-only fake implementations
│   │   ├── fake_bot_core.py              # Fake bot_core for loop/LLM tests
│   │   ├── fake_llm_stack.py             # Fake LLM backend & stack
│   │   ├── fake_skills.py                # Fake skills & specs for isolated tests
│   │   └── __init__.py                   # Package init for tests.fakes
│   ├── __init__.py                       # Make tests importable as a package
│   ├── test_agent_loop_v1.py             # Tests for agent_loop v1 logic
│   ├── test_architecture_integration.py  # Sanity: imports & basic module wiring
│   ├── test_env_loader.py                # Tests for env.loader and schema
│   ├── test_error_model_with_fake_backend.py # Error-model using fake backend
│   ├── test_llm_stack_fake_backend.py    # LLM stack behavior with fake backend
│   ├── test_observation_critic_encoding.py   # Encoding for critic inputs
│   ├── test_observation_planner_encoding.py  # Encoding for planner inputs
│   ├── test_observation_worldstate_normalization.py # WorldState normalization tests
│   ├── test_p0_p1_env_bridge.py          # P0 EnvProfile → P1 WorldState adapter tests
│   ├── test_phase0_runtime.py            # Phase 0 runtime sanity (env & CLI)
│   ├── test_phase1_breakglass_no_plans.py    # Asserts P1 raises when planner returns no plans
│   ├── test_phase1_integration_offline.py    # Offline integration tests for P1 LV scenarios
│   ├── test_scribe_model_with_fake_backend.py # Scribe under fake backend
│   ├── test_semantics_caching_singleton.py    # Semantics cache singleton behavior
│   ├── test_semantics_categorization.py   # Categorization behavior tests
│   ├── test_semantics_craftability.py     # Craftability checks vs recipes
│   ├── test_semantics_tech_inference.py   # Tech-state inference from world
│   ├── test_semantics_tolerant_fallbacks.py   # Behavior when semantics are incomplete
│   ├── test_semantics_with_normalized_worldstate.py # Semantics vs normalized WorldState
│   ├── test_skill_loader.py               # SkillSpec loader tests
│   ├── test_skill_packs_integrity.py      # SkillPack ↔ SkillSpec ↔ impl integrity
│   ├── test_skill_packs.py                # Unit tests for packs loader/logic
│   ├── test_skill_registry.py             # Registry + decorator tests
│   ├── test_virtue_compare_plans.py       # Virtue lattice compare_plans behavior
│   ├── test_virtue_config_sanity.py       # Sanity checks for virtues.yaml
│   ├── test_virtue_hard_constraints.py    # Tests for hard constraints in virtue lattice
│   └── test_virtue_lattice_basic.py       # Basic virtue scoring behavior tests
└── tools
    └── phase1_demo.py                     # Demo script to run Phase 1 planning from CLI

```

Here’s your knowledge capsule.

---

## 1. High-Level Snapshot

**Status:**

- **Phase 0 (Foundations)**: Done & tested.
    
- **Phase 1 (Offline Planning & Integration)**: Done & tested.
    
- Everything up to **M5 (Skills)** is wired together and can run **offline planning episodes** against a normalized `WorldState`, choosing plans via a virtue lattice, with a bridge from environment profiles.
    

**Core pipeline that now works:**

> `Env Profile (P0) → WorldState (adapter) → Semantics & TechState → Skills & Skill Packs → Planner (fake) → Virtue lattice (fake features) → Best plan + virtue scores`

This is all under test. No duct tape holding it together (for once).

---

## 2. Core Concepts & Definitions

### 2.1 Phases

- **Phase 0 – Foundations**
    
    - Define runtime environment, hardware, Minecraft / GTNH installs.
        
    - Load env profiles (`config/env.yaml`) via `env.loader`.
        
    - Validate everything with `config/tools/validate_env.py`.
        
    - Output: `EnvProfile` + a sane config baseline.
        
- **Phase 1 – Offline Planning**
    
    - Wire **M2–M5** plus **virtues** into one orchestrator:
        
        - `run_phase1_planning_episode(world, goal, virtue_context_id, *, episode_id=None)`
            
    - Offline only:
        
        - No Minecraft IPC.
            
        - Uses **fake planner** & **fake virtue lattice** for determinism.
            
        - Uses **real semantics and skills**.
            

### 2.2 Modules

- **M1: Spec / Types (`src/spec`)**
    
    - `WorldState`, skill specs, LLM interfaces, agent loop contracts.
        
    - This is the “law” everyone else obeys.
        
- **M2: LLM Stack (`src/llm_stack`)**
    
    - Backend abstraction (`LLMBackend`), llama.cpp integration.
        
    - Planner, critic, scribe, error-model.
        
    - Logs everything into `logs/llm` with structured JSON.
        
- **M3: Semantics (`src/semantics`)**
    
    - Loads GTNH items/blocks/recipes from:
        
        - `config/gtnh_items*.yaml`
            
        - `config/gtnh_blocks*.yaml`
            
        - `config/gtnh_recipes*.json`
            
        - `config/gtnh_tech_graph.yaml`
            
    - Provides:
        
        - Item/block categorization.
            
        - Craftability checks.
            
        - Tech-state inference.
            
- **M4: Virtues (`src/virtues`)**
    
    - Virtue lattice engine.
        
    - Config: `config/virtues.yaml`.
        
    - Features, scoring, hard constraints, and explanations.
        
    - In Phase 1 integration:
        
        - Use **fake** `load_virtue_config`, `summarize_plan`, `compare_plans`
            
        - Real lattice kept modular for later phases.
            
- **M5: Skills (`src/skills`)**
    
    - YAML SkillSpecs in `config/skills/*.yaml`.
        
    - Python implementations in `src/skills/base/*.py`.
        
    - SkillPacks in `config/skill_packs/*.yaml`.
        
    - `SkillRegistry` with decorator-based registration.
        
    - Integrity tests ensure:
        
        - Every SkillPack skill has a spec.
            
        - Every spec has an implementation (where expected).
            

---

## 3. Key Pathways

### 3.1 P0 → P1 Bridge

- Adapter: `integration.adapters.m0_env_to_world.world_from_env_profile(profile)`
    
- Input: something EnvProfile-like (from `env.loader`).
    
- Output: a **minimal but valid** `WorldState` instance with:
    
    - `position`, `dimension`, `inventory`, `nearby_entities`,
        
    - `blocks_of_interest`, `tech_state`, `tick`, `context`.
        
- `context` stores:
    
    - `env_name`, `modpack`, `gtnh_version`, `world_seed`
        
    - `meta.profile_path`, `meta.phase="p1_offline"`
        

This is how Phase 0 feeds Phase 1 without caring about chunks or detailed block layout yet.

### 3.2 Phase 1 Context Builder

`build_phase1_context(world, episode_logger=None) -> Dict[str, Any>`

- Derives:
    
    - `tech_state` from `semantics.tech_state.get_current_tech_state(world)`
        
    - `semantics_db` from `semantics.loader/load_semantics_db`
        
    - `virtue_config` from **fake** loader (Phase 1)
        
    - `skill_registry` via `get_global_skill_registry()`
        
    - `skill_packs` via `load_all_skill_packs()`
        
    - `planner` via `get_planner_backend(...)` (fake in tests)
        
- Logs:
    
    - Tech state name
        
    - Number of skills/specs
        
    - Number of skill packs
        

### 3.3 Skill Visibility

`compute_available_skills(context) -> Dict[str, Dict[str, Any]]`

- Reads:
    
    - `tech_state` from context
        
    - `skill_packs` & `SkillRegistry`
        
- Enables SkillPacks where `pack.requires_tech_state == tech_state.name`.
    
- Asks registry for `describe_for_tech_state(tech_state, enabled_pack_names)`.
    
- Result = dict of skill_name → metadata exposed to planner.
    

### 3.4 Planner Call

`call_planner_llm(...) -> List[Dict[str, Any]]`

- Builds `planner_input`:
    
    - `goal`
        
    - `world_summary` (from `world.to_summary_dict()` or fallback)
        
    - `tech_state` (string)
        
    - `skills` (visible skills metadata)
        
    - `virtue_context_id`
        
- Delegates to `planner.generate_plan(planner_input)`.
    
- Expects `{"plans": [...]}`.
    
- Logs:
    
    - number of plans
        
    - a hash of the world summary for correlation
        

### 3.5 Virtue-Based Selection

`select_best_plan(plans, world, context, virtue_context_id) -> (best_plan, scores)`

- Uses:
    
    - `semantics_db`
        
    - `virtue_config`
        
    - `SkillRegistry.describe_all()` for full skill metadata
        
- For each plan:
    
    - Calls **fake** `summarize_plan(plan, world, tech_state, semantics_db, skill_metadata)`
        
    - Logs features: `skill_names`, `missing_skills`.
        
- Then:
    
    - `compare_plans(plans=plan_summaries, context_id=virtue_context_id, config=virtue_config)`
        
    - Logs virtue scores, selected plan ID.
        
- Returns:
    
    - The original planner plan dict with matching `id`.
        
    - The virtue scores dict.
        

### 3.6 Phase 1 Entry Point
python:
```
run_phase1_planning_episode(
    world: WorldState,
    goal: str,
    virtue_context_id: str,
    *,
    episode_id: Optional[str] = None,
) -> Tuple[Dict[str, Any], Dict[str, Any]]

```

**Contract (Phase 1):**

- Inputs:
    
    - `world`: normalized `WorldState`
        
    - `goal`: human-ish planning objective (`"Design LV coke oven layout"`)
        
    - `virtue_context_id`: where to look in `config/virtues.yaml` (`"lv_coke_ovens"`, `"lv_resources"`, etc.)
        
- Behavior:
    
    - Builds full integration context (M2–M5).
        
    - Filters visible skills via tech_state & SkillPacks.
        
    - Calls planner (fake, deterministic).
        
    - Uses fake virtue layer to pick best plan.
        
    - Logs everything with `EpisodeLogger` under `episode_id`.
        
- Outputs:
    
    - `best_plan`: chosen plan dict
        
    - `scores`: virtue scores or summary metrics
        

**Break-glass behavior:**

- If **no plans**: raises `RuntimeError("Planner returned no plans for goal: ...")`
    
- If summarization or comparison throws: bubble up after logging.
    

---

## 4. Capabilities You Actually Have Now

- Load & validate **env**, **hardware**, **model**, and **minecraft** configs.
    
- Normalize **WorldState** and semantics queries against it.
    
- Use a **fake planner** to:
    
    - Generate LV scenarios (resource runs, coke oven layouts).
        
- Use a virtue-aware selection layer (fake features, real lattice interface).
    
- Run **integration tests** that:
    
    - Ensure SkillSpecs, SkillPacks, and skill implementations are aligned.
        
    - Validate semantics tech inference & craftability.
        
    - Assert the P0 → P1 bridge returns a valid `WorldState`.
        
    - Assert Phase 1 planning chooses the “right” plan in LV test scenarios.
        
    - Assert no-plans situation raises loudly, not silently.
        

You’re no longer poking random Python files; you have a consistent, test-guarded offline planning engine.

---

## 5. Design Insights / Patterns Locked In

1. **Fakes at the integration boundaries**
    
    - `integration.testing.fakes` gives you:
        
        - Fake planner
            
        - Fake semantics loader
            
        - Fake virtue config / summarizer / comparator
            
    - Lets you evolve real systems later without breaking Phase 1 tests.
        
2. **Skill system is properly 3-way locked**
    
    - YAML SkillSpecs ↔ Python implementations ↔ SkillPacks.
        
    - Validation enforces:
        
        - No “ghost skills” in packs.
            
        - No Spec without impl (for core packs).
            
    - This keeps the planning surface trustworthy.
        
3. **Stable Phase 1 API**
    
    - `run_phase1_planning_episode(world, goal, virtue_context_id, *, episode_id=None)`
        
    - Signature is considered stable. New arguments must be keyword-only.
        
    - Future phases can:
        
        - Swap fake planner → real local LLM.
            
        - Swap fake virtue layer → real feature pipeline.
            
        - Keep tests green.
            
4. **WorldState as the lingua franca**
    
    - P0 envs, observation encoders, semantics, planner, and virtues all talk in terms of `WorldState`.
        
    - You already enforce normalization in tests (`test_observation_worldstate_normalization.py` etc.).
        
5. **Logging that actually means something**
    
    - Every planning episode has a correlation ID.
        
    - LLM stack logs are structured, per-phase, and stored under `logs/llm`.
        
    - Debugging weird behavior won’t be a blind hunt.
        

---

## 6. To-Do List for Next Phase

You’re basically ready to step into **Phase 2: early online / runtime loop**. Things that make sense next:

### 6.1 Upgrade Planner & Virtue to “Real” Modes (opt-in)

- Add a **runtime switch** in Phase 1 integration:
    
    - Keep **fake mode** as default (for tests).
        
    - Add a config or flag to:
        
        - Use real `load_virtue_config`, `summarize_plan`, `compare_plans`.
            
        - Optionally use real `PlannerBackend` wired to your llama.cpp backend.
            
- Keep tests locked to fake mode.
    

### 6.2 Tighten P0 → P1 → Observation Path

- Extend the P0 adapter to include:
    
    - Minimal but useful base-scene hints (biome tags, spawn region, etc.) in `context`.
        
- Make sure `observation.encoder`:
    
    - Cleanly converts `WorldState` into the planner input format you’re using in Phase 1.
        
    - Has tests that match what Phase 1 expects.
        

### 6.3 Agent Loop Dry Run (with Fake Bot Core)

Use the pieces you already have:

- In `agent_loop.loop`:
    
    - Run a “fake episode” that:
        
        1. Starts from a dummy `WorldState`.
            
        2. Calls `run_phase1_planning_episode` using LV test contexts.
            
        3. Produces a trace and sends it to learning / scribe.
            
- Validate:
    
    - You can go from “episode config” → “sequence of planning calls” → “logged summary.”
        

You basically did this philosophically; now do it concretely.

### 6.4 Curriculum Integration (lightweight)

- Use `curriculum.engine` + `config/curricula/*.yaml` to:
    
    - Map a curriculum unit (e.g. “early LV bootstrap”) → a planning **goal** + `virtue_context_id`.
        
- Add tests:
    
    - Each curriculum step produces a valid `(goal, virtue_context_id)` pair.
        
    - Those pairs are accepted by `run_phase1_planning_episode` using a dummy `WorldState`.
        

Now curricula no longer live purely in your head.

### 6.5 Experience & Learning Hooks

You already have `learning.{buffer,evaluator,manager, schema, synthesizer}`. Do the minimal wiring:

- After each Phase 1 episode:
    
    - Capture `(world, goal, best_plan, scores)` into a simple “experience” object.
        
    - Push it into a replay buffer.
        
- Later, you can:
    
    - Use these traces for offline analytics or training a meta-model.
        

### 6.6 Monitoring & TUI

You have `monitoring.*` sitting there bored:

- Wire `EpisodeLogger` or agent loop events into `monitoring.bus`.
    
- Get `dashboard_tui.py` to display:
    
    - Current phase / episode.
        
    - Last goal.
        
    - Selected plan ID & top virtue scores.
        

Not necessary for correctness, but very useful once this thing runs longer than a test.

---

Short version:  
You’ve finished **Phase 0** and **Phase 1** in a way that’s actually maintainable. The repo can now:

- Take an environment profile,
    
- Turn it into a normalized world,
    
- Run a virtue-aware planning episode with real skills & semantics,
    
- And prove it via tests.
    

Next up is teaching it to **act** in a live loop instead of just thinking very hard on the couch.


## 1. What M6 _actually_ owns

M6 = **“Make a 1.7.10 Minecraft body that obeys the spec.”**

Responsibility slice:

- Speaks IPC to the Forge mod / 1.7.10 client.
    
- Maintains a **persistent world model** (`world_tracker`, `snapshot`).
    
- Executes **Actions** (from `spec.bot_core` / `spec.types`) in a ticked world.
    
- Exposes a clean interface to higher layers:
    
    - “Here is `WorldState`”
        
    - “Here is whether the action succeeded / failed / did nothing”
        
    - “Here is a stream of events”
        

What it does **not** own:

- Planning (that’s Phase 1).
    
- Virtue scoring.
    
- Curriculum / goal selection.
    
- Anything LLM-flavored.
    

Treat M6 as the “physics + controller” module.

---

## 2. Contracts You Must Not Break

### 2.1 `WorldState` & `Action` as the shared language

You already have:

- `spec.types.WorldState`
    
- `spec.bot_core` (+ `spec.skills` etc.)
    
- Phase 1 integration depending on `WorldState`
    

For M6, **do not create an alternate state or action schema**.

M6 should give you:
python:
```
# src/bot_core/core.py (or similar)

def get_world_state() -> WorldState: ...
def step_action(action: Action) -> "StepResult": ...

```

Where `StepResult` is something like:
python:
```
@dataclass
class StepResult:
    world: WorldState          # post-action snapshot
    success: bool
    error: str | None
    events: list[Any]          # later: structured events

```

If you keep _that_ contract stable, every higher layer stays plug-and-play.

---

## 3. IPC Boundary: where 1.7.10 lives

You already have:

- `bot_core/net/client.py`
    
- `bot_core/net/ipc.py`
    

M6 should treat this as the **one true boundary** between Python brain and 1.7.10 flesh.

Non-negotiables to write down:

1. **Message direction**
    
    - Python → MC:
        
        - “Do action X” (move, mine block, place block, use item…)
            
        - “Give me snapshot” / “subscribe to updates”
            
    - MC → Python:
        
        - Snapshot / diff
            
        - Action result / error
            
        - Events (damage, death, inventory full, etc., later)
            
2. **Correlation**
    
    Every outbound action command gets a `request_id` / `correlation_id` so you can:
    
    - Match results in logs
        
    - Feed them into `monitoring.bus` cleanly
        
3. **Failure semantics**
    
    At the IPC layer you need:
    
    - Timeouts → marked as “no response”
        
    - Explicit errors → “server says nope”
        
    - “Action did nothing” → success=False but no crash
        
    
    Those must all map to a clean `StepResult` so higher layers never touch raw IPC hell.
    

---

## 4. World Model: `snapshot.py` & `world_tracker.py`

This is where most projects go feral.

### 4.1 World snapshot source of truth

M6 should adhere to:

> “Only `world_tracker` builds `WorldState`. Everyone else just consumes it.”

Pipeline:

`MC packets / IPC → net.client → snapshot.py (raw struct) → world_tracker.py → WorldState`

- **snapshot.py**: thin data holders, close to wire format.
    
- **world_tracker.py**:
    
    - Maintains the _latest known_ world (position, dimension, inventory, nearby entities, blocks of interest…)
        
    - Handles partial updates (chunk diffs, entity deltas)
        
    - Exposes `to_world_state()` that builds the canonical `WorldState`.
        

Do not let random modules construct `WorldState` by hand from scratch.

### 4.2 1.7.10 quirks to encode early

Stuff you should acknowledge _now_ so you don’t cry later:

- Block coordinates are integer grid, player position is float-ish.
    
- Chunk boundaries / loading radius matter (pathfinding & visibility).
    
- 1.7.10 collision + pathing is jank; treat navigation as “may fail” even in simple terrain.
    

You don’t need to solve all of that in M6, but the tracker should be compatible with:

- “I know loaded chunks”
    
- “I know where solid blocks are”
    
- “I know my position & dimension”
    

So later `bot_core.nav.grid` / `pathfinder` are not guessing.

---

## 5. Navigation: grid, mover, pathfinder

You already have:

- `bot_core/nav/grid.py`
    
- `bot_core/nav/mover.py`
    
- `bot_core/nav/pathfinder.py`
    

M6 is where these stop being toys and become **the thing that actually moves the body.**

Key decisions to write down:

1. **Coordinate system canonicalization**
    
    - Internal nav grid is in `(x, y, z)` int coordinates.
        
    - Player pose from 1.7.10 (x, y, z, yaw, pitch) must be converted once and consistently.
        
2. **Path → Actions**
    
    Define a stable mapping:
python:
```
def path_to_actions(path: list[GridPos]) -> list[Action]:
    ...

```

1. Where `Action` is from `spec.bot_core` and matches the actions your Forge mod understands.
    
2. **Failure behavior**
    
    When pathfinding fails:
    
    - `StepResult.success = False`
        
    - Some structured event like `{"type": "nav_failure", "reason": "no_path"}`
        
    
    Do _not_ silently teleport or “pretend we walked there.”
    

---

## 6. Safety rails & pacing

You’re now binding to a real-time world instead of comfy offline tests, so:

### 6.1 Tick & pacing policy

Decide and write down:

- One `Action` corresponds to:
    
    - One high-level chunk (e.g. “walk to tree, then punch it until log gone”), **or**
        
    - One low-level command (e.g. “move X+, jump, attack once”), with M6 sequences inside.
        

Pick one and stick to it or you’re going to have a demon of a time debugging.

### 6.2 Hard stop conditions

M6 should be allowed to _refuse_ further execution when:

- Player died
    
- Disconnected from server
    
- Dimension mismatch
    
- Inventory is full when a skill assumes free slots (event later)
    

That refusal should bubble up as:

- A terminal `StepResult` or
    
- A raised domain error caught by agent loop
    

You do **not** want the planner happily issuing “chop tree” while you’re respawning.

---

## 7. Testing strategy specifically for M6 / bot_core_1_7_10

Given you already have loads of tests, here’s what I’d bolt on:

### 7.1 IPC fakes

Under `tests/fakes/` add:

- `fake_ipc_server.py` or extend `fake_bot_core.py` to simulate:
    
    - Success responses
        
    - Timeouts
        
    - Explicit errors
        

Use that to test `bot_core.net.client` and `ipc` **without** a real server.

### 7.2 Snapshot → WorldState consistency

Unit tests for `world_tracker`:

- Feed it a sequence of fake snapshots:
    
    - Spawn
        
    - Move
        
    - Break block
        
    - Pick up item
        

Assert:

- `WorldState.position` updates correctly
    
- `inventory` changes as expected
    
- `blocks_of_interest` reflect the new terrain
    

### 7.3 Navigation smoke tests

In `tests/test_bot_core_nav_*.py`:

- Build tiny fake chunks (e.g. flat floor, a wall, a gap).
    
- Run pathfinder.
    
- Ensure `path_to_actions` produces non-insane action sequences.
    
- Ensure blocked cells → nav failure, not infinite loops.
    

### 7.4 Offline end-to-end bridge

A test that does the full chain **without real Minecraft**:
python:
```
def test_offline_end_to_end_planning_and_bot_core():
    # 1) Fake env profile → WorldState (P0/P1 bridge)
    profile = DummyEnvProfile()
    world = world_from_env_profile(profile)

    # 2) Run Phase 1 planner
    best_plan, scores = run_phase1_planning_episode(
        world=world,
        goal="chop some trees",
        virtue_context_id="lv_resources",
    )

    # 3) Feed first plan step into bot_core fake executor
    action = expand_plan_step_to_actions(best_plan["steps"][0])[0]
    result = fake_bot_core_step(action)

    assert result.success

```

That locks the seams between:

- P0 env → WorldState
    
- P1 planner
    
- M6 bot_core API
    

Once that passes, plugging in the _real_ 1.7.10 runtime is “just” engineering pain, not conceptual chaos.

---

## 8. One-sentence summary for Future You

M6 should make **1.7.10 feel like a clean deterministic device** that takes `Action`, spits out `WorldState + events`, and never leaks Forge / packet / tick garbage into the rest of the architecture.

If you protect that boundary, Phase 2 will be loud and annoying but structurally sane.


# **GTNH Agent – Phase-2 / M6 Integration Commitments (Summary Block)**

The following architectural guarantees and future-module contracts must be preserved as we enter **M6 (bot_core_1_7_10)**. These define how all later “Seven Qualities” will attach to the system without refactoring the foundation.

---

## **1. Stable Ordering for Future Work**

The long-term roadmap depends on this order:

1. Finish M4 + M5
    
2. Complete M6 (bot_core_1_7_10)
    
3. Complete M7
    
4. Prototype M8 loop
    
5. Add LLM-role separation (M2 polish)
    
6. Add self-evaluation loop (M8, M2)
    
7. Add hierarchical planning (M8, M2)
    
8. Add experience memory (M8, M10)
    
9. Add predictive world-model (M3)
    
10. Add curriculum engine (M11)
    
11. Add full skill evolution (M5, M10)
    

_Everything else assumes this order stays stable._

---

## **2. The Seven Qualities: Where They Plug Into the Architecture**

You do **not** need to build these now.  
M6 must simply **leave the attachment points intact**.

|Quality|Modules|
|---|---|
|Self-evaluation & retry|**M8**, M2, M9|
|Skill evolution & versioning|**M5**, M10|
|Hierarchical planning|**M8**, M2, spec|
|Experience memory|**M10**, M8, Scribe|
|Curriculum-driven goals|**M11**, M8, M3, M4|
|LLM-role separation|**M2**, config/llm_roles|
|Predictive world-model|**M3**, consumed by M4/M8/M11|

---

## **3. Minimal Contracts That M6 Must Preserve**

These are the non-negotiables that must survive into M8–M11:

### **3.1 World → Action → World loop**

M6 **must** expose a deterministic API:
python:
```
def get_world_state() -> WorldState: ...
def step_action(action: Action) -> StepResult: ...

```
where:
yaml:
```
StepResult = {
    world: WorldState,
    success: bool,
    error: str | None,
    events: [...],
}

```
This is the backbone for:

- M8 hierarchical loop
    
- M10 experience memory
    
- M11 curriculum engine
    
- predictive world-model validation
    

Break this contract and everything collapses.

---

## **4. Versioning & Evolution Hooks (for Future M10/M11)**

M6 doesn’t implement these, but it must **not block** them:

- Skills have `version`, `status`, `origin`, `metrics`
    
- Registry supports:
    
    - `get_latest_skill`, `register_skill_candidate`, `list_skill_versions`
        
- Planner must output structured steps that map cleanly onto SkillInvocations
    
- WorldState must be generic enough for future `Experience` objects
    

---

## **5. Hierarchical Planning Attachment Points**

Later modules expect:

### **Planning Levels**

1. Goal
    
2. Task
    
3. Skill
    
4. Action (M6 owns this)
    

### **Spec additions expected later:**

- `AgentGoal`
    
- `TaskPlan`
    
- `SkillInvocation`
    

M6 must not create incompatible action forms or world schemas.

---

## **6. Experience Memory Requirements (Future M10)**

M6 must allow agent loop to collect:
makefile:
```
Experience = {
  problem_signature,
  goal,
  plan,
  attempts,
  final_outcome,
  virtue_scores,
  lessons,
}

```

Meaning:

- `StepResult` must expose enough info to fill these fields.
    
- WorldState must remain serializable + diffable.
    

---

## **7. Curriculum Engine Expectations (Future M11)**

M6 must maintain clean access to:

- TechState
    
- world metadata
    
- virtue contexts
    
- stable WorldState fields
    

So the engine can select:
ini:
```
next_goal = curriculum.next_goal(tech_state)

```
M6 cannot hide or mutate tech_state unilaterally.

---

## **8. LLM Role Separation (M2)**

Later work requires:

- Explicit planner/critic/scribe/error_model calls
    
- Configurable via `config/llm_roles.yaml`
    

M6 must not entangle LLM calls into bot_core.

---

## **9. Predictive World-Model (M3)**

Future functions like:
scss:
```
simulate_tech_progress(...)
estimate_infra_effect(...)
estimate_resource_trajectory(...)

```

depend on **stable semantics** and **stable world-state snapshots**.

M6 must avoid introducing MC-specific pollution into WorldState.

---

## **10. One-Sentence Summary for M6 Context Primer**

> **M6’s job is to make Minecraft 1.7.10 behave like a clean device: take an Action, return a WorldState + events, and never leak the chaos of the game engine into higher layers.**  
> Every future module (M8–M11) depends on that stability.