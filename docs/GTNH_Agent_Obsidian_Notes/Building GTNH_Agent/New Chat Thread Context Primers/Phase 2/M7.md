Here is an overview of the entire project for your context:

Phase 0:

M0 - environment_foundation

**Purpose:**

Lock in the actual environment & runtimes.

- Define:

- MC 1.7.10 + Forge 10.13.4.1614 + GTNH 2.8.1 run profile

- Decision: external bot client vs in-process Forge mod with IPC

- Hardware constraints for local LLMs

- **Dependencies:** None

- **Difficulty:** ⭐

- **Scalability notes:**

- Document this in a single config file / README; future changes (new model, new server host) should not touch code.

M1 - agent_architecture_spec

**Purpose:**  
Unify Mineflayer + Voyager insights into a **single architecture spec**.

- Extract from Mineflayer:
    
    - Bot lifecycle
        
    - World model
        
    - Pathfinding
        
    - Action abstraction
        
- Extract from Voyager:
    
    - Planner → Skill library → Execution loop
        
    - Reflection & learning
        
- **Dependencies:** `M0`
    
- **Difficulty:** ⭐⭐
    
- **Scalability notes:**
    
    - Produce one canonical architecture doc: diagrams + interfaces.
        
    - This is the contract everything else conforms to.


Phase 1

M2 - llm_stack_local

**Purpose:**  
Provide reusable interfaces around local models.

- Implement:
    
    - `PlannerModel`: high-level plan generation
        
    - `CodeModel`: skill/code generation
        
    - `CriticModel`: evaluation / refinement
        
- Unified tool schema:
    
    - Input: structured state / goal
        
    - Output: JSON plan / skill spec, no direct MC calls
        
- **Dependencies:** `M1`
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Centralize model loading & caching.
        
    - Make batch calls possible.
        
    - Log prompts/responses for replay.

M3 - world_semantics_gtnh

**Purpose:**  
Define GTNH tech + world understanding as **data + logic**.

- Data layer (config files):
    
    - Block categories (ores, machines, cables, etc.)
        
    - Item categories (plates, circuits, tools)
        
    - Tech states & prereqs (LV steam, MV, etc.)
        
- Logic layer (Python):
    
    - `infer_tech_state(inventory, machines)`
        
    - `suggest_next_targets(tech_state)`
        
    - `craftable_items(inventory, known_recipes)`
        
- **Dependencies:** `M1`
    
- **Difficulty:** ⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Keep recipes & categories in JSON/YAML, not code.
        
    - Cache derived graphs (like tech dependency DAGs).

M4 - virtue_lattice

**Purpose:**  
Encapsulate your Sefirot-based virtues as a reusable scoring layer.

- Define:
    
    - Virtue nodes: Efficiency, Safety, Sustainability, etc.
        
    - Configurable weights per context (e.g., early LV vs late HV)
        
- APIs:
    
    - `score_plan(plan, context) -> dict[virtue -> score]`
        
    - `compare_plans(plans, context) -> best_plan`
        
- **Dependencies:** `M3` (for context & environment semantics)
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Pure functions, stateless, easy to unit test.
        
    - Configurable weights → you can tune without code changes.

M5 - skill_registry

**Purpose:**  
Central place for skill definitions and metadata.

- Skill spec:
    
    - Name, parameters
        
    - Preconditions (what world/tech state is required)
        
    - Effects (changes in world/tech state)
        
    - Tags (e.g., mining, crafting, building)
        
- LLM interaction:
    
    - Planner only sees skill metadata, not raw code.
        
    - Skill implementations live as Python methods or small scripts.
        
- **Dependencies:** `M1`, `M3`
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Skills registered via decorators or config files.
        
    - Easy to version and deprecate skills over time.

Phase 2:

M6 - bot_core_1_7_10

**Purpose:**  
Provide a stable, testable “body” that can be used by any controller.

- Capabilities:
    
    - Connect/keepalive
        
    - World tracking (chunks, entities)
        
    - Navigation (A* or similar)
        
    - Actions:
        
        - Move, jump, break block, place block, use item, interact with tile entities
            
- API:
    
    - `observe() -> RawWorldSnapshot`
        
    - `execute_action(Action) -> Result`
        
- **Dependencies:** `M0`, `M1`
    
- **Difficulty:** ⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Keep logic modular: pathfinding, inventory, world tracking as submodules.
        
    - Limit unnecessary packet decoding; cache what you can.

M7 - observation_encoding

**Purpose:**  
Map `RawWorldSnapshot` from `M6` into semantic state used by LLMs & planners.

- Functions:
    
    - `encode_for_planner(raw_snapshot, tech_state) -> JSON`
        
    - `encode_for_critic(trace) -> JSON`
        
- Uses:
    
    - `M3` (semantics)
        
    - `M4` (virtues context)
        
- **Dependencies:** `M3`, `M6`
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Keep encodings compact. Summaries + key entities, not entire chunks.
        
    - Enforce stable schema to avoid breaking old skills.

Phase 3:

M8 - agent_loop_v1

**Purpose:**  
Implement the core loop: observe → plan → choose skills → act → evaluate.

- High-level algorithm:
    
    1. `state = observe()`
        
    2. `tech_state = infer_tech_state(state)`
        
    3. `plan = planner_model.call(state, tech_state, skill_registry, virtues)`
        
    4. Decompose plan into skill invocations
        
    5. Execute via `bot_core_1_7_10`
        
    6. Log result for learning (`M10`)
        
- Strict separation:
    
    - No direct packet calls here.
        
    - No GTNH-hardcoded weirdness here; that lives in `M3` and `M5`.
        
- **Dependencies:**
    
    - `M2` (LLM stack)
        
    - `M3` (world semantics)
        
    - `M4` (virtues)
        
    - `M5` (skills)
        
    - `M6` (bot core)
        
    - `M7` (observation encoding)
        
- **Difficulty:** ⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Design as a state machine with clear states (Idle, Planning, Executing, Recovering).
        
    - Rate-limit LLM calls, reuse plans until invalidated.

M9 - monitoring_and_tools

**Purpose:**  
Give you observability and a control surface before the system gaslights you.

- Features:
    
    - Structured logs (JSON)
        
    - Web or TUI dashboard:
        
        - World overview
            
        - Current plan & skills
            
        - Virtue scores
            
        - Tech state
            
    - Manual controls:
        
        - Pause, step, cancel plan, inspect memory
            
- **Dependencies:** `M8`
    
- **Difficulty:** ⭐⭐–⭐⭐⭐
    
- **Scalability/perf:**
    
    - Central logger used by all modules.
        
    - Minimal UI first; upgrade visuals later.


Phase 4:

M10 - skill_learning

**Purpose:**  
Voyager-style learning: derive new skills from experience and refine existing ones.

- Components:
    
    - Experience buffer:
        
        - `{state, goal, plan, actions, outcomes, virtue_scores}`
            
    - LLM-based synthesizer:
        
        - Turn repeated success traces into new skill definitions
            
    - Evaluator:
        
        - Compare new vs existing skills on:
            
            - Success rate
                
            - Cost (time, resources)
                
            - Virtue scores
                
- **Dependencies:** `M8` (loop), `M2` (LLMs), `M5` (skill registry), `M4` (virtue scoring)
    
- **Difficulty:** ⭐⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Learning should be offline or scheduled, not constant.
        
    - Skills versioned and can be rolled back if regressions appear.


M11 - gtnh_curriculum_and_specialization

**Purpose:**  
Turn the generic learning agent into a **GTNH-native progression engine**.

- Define:
    
    - Curricula per phase:
        
        - Early LV goals
            
        - Steam infra goals
            
        - MV automation goals
            
    - Long-horizon projects:
        
        - Stargate, high-tier reactors, etc.
            
- The curriculum is:
    
    - A sequence of target tech states
        
    - Each with:
        
        - Reward shaping (virtue weight tweaks)
            
        - Suggested skills to prioritize / learn
            
- **Dependencies:** `M3`, `M5`, `M8`, `M10`
    
- **Difficulty:** ⭐⭐⭐⭐⭐
    
- **Scalability/perf:**
    
    - Curriculum is config, not code.
        
    - Multiple curricula can be swapped (e.g. “eco base”, “speedrun”, “aesthetic build”).


Shortcut View:
# **Phase P0 — Foundations**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M0**|environment_foundation|⭐|0.5–2 days|Lock runtime, modpack, IPC choice|
|**M1**|agent_architecture_spec|⭐⭐|2–4 days|Full architecture doc|

### **Phase P0 Total:**

**Difficulty Avg:** ⭐⭐  
**Time:** ~3–6 days

---

# **Phase P1 — Offline Core Pillars (No Minecraft)**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M2**|llm_stack_local|⭐⭐–⭐⭐⭐|3–7 days|Local models, prompt tooling|
|**M3**|world_semantics_gtnh|⭐⭐⭐⭐|7–14 days|Tech tree + ontology mapping|
|**M4**|virtue_lattice|⭐⭐–⭐⭐⭐|3–6 days|Scoring/weights system|
|**M5**|skill_registry|⭐⭐–⭐⭐⭐|3–6 days|Skill definitions, metadata|

### **Phase P1 Total:**

**Difficulty Avg:** ⭐⭐⭐  
**Time:** ~2–4 weeks

---

# **Phase P2 — Minecraft Integration Layer**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M6**|bot_core_1_7_10|⭐⭐⭐⭐|2–4 weeks|Pathfinding, inventory, world tracking|
|**M7**|observation_encoding|⭐⭐–⭐⭐⭐|3–7 days|Convert raw MC data → semantic state|

### **Phase P2 Total:**

**Difficulty Avg:** ⭐⭐⭐⭐  
**Time:** ~3–5 weeks

---

# **Phase P3 — Agent Orchestration & Tooling**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M8**|agent_loop_v1|⭐⭐⭐⭐|1–2 weeks|Full observe → plan → act|
|**M9**|monitoring_and_tools|⭐⭐–⭐⭐⭐|3–7 days|Logs, dashboards, step controls|

### **Phase P3 Total:**

**Difficulty Avg:** ⭐⭐⭐⭐  
**Time:** ~2–3 weeks

---

# **Phase P4 — Learning & Specialization**

|Module|Name|Difficulty|Est. Time|Notes|
|---|---|---|---|---|
|**M10**|skill_learning|⭐⭐⭐⭐⭐|2–4 weeks|Voyager-style skill synthesis|
|**M11**|gtnh_curriculum_and_specialization|⭐⭐⭐⭐⭐|multi-week ongoing|Long-horizon GTNH progression logic|

### **Phase P4 Total:**

**Difficulty Avg:** ⭐⭐⭐⭐⭐  
**Time:** ~4–8+ weeks (ongoing beyond initial build)

---

# **Grand Totals (First-Pass Implementation)**

|Phase|Difficulty Avg|Total Time|
|---|---|---|
|**P0**|⭐⭐|3–6 days|
|**P1**|⭐⭐⭐|2–4 weeks|
|**P2**|⭐⭐⭐⭐|3–5 weeks|
|**P3**|⭐⭐⭐⭐|2–3 weeks|
|**P4**|⭐⭐⭐⭐⭐|4–8+ weeks|

---

File Structure:
```
GTNH_Agent                          # Root of the GTNH Agent project (local Minecraft automation agent)
├── bootstrap_structure.py          # One-shot script to create the initial repo folder/file skeleton
├── config                          # All declarative configuration: env, models, skills, curricula, raw GTNH data
│   ├── curricula                   # Curriculum definitions for training / guiding the agent
│   │   ├── aesthetic_megabase.yaml # Long-horizon “aesthetic megabase” curriculum (late-game / aspirational goals)
│   │   ├── default_speedrun.yaml   # Baseline progression-focused curriculum (mainline GTNH progression)
│   │   └── eco_factory.yaml        # Curriculum tuned for efficient, clean factory / eco-style play
│   ├── env.yaml                    # Environment profiles: runtime mode, bot_mode, world profile, paths, etc.
│   ├── gtnh_blocks.generated.yaml  # Auto-generated block semantics extracted from raw GTNH data (do not edit by hand)
│   ├── gtnh_blocks.yaml            # Hand-authored overrides / curated block semantics layered on generated data
│   ├── gtnh_items.generated.yaml   # Auto-generated item metadata from GTNH exports
│   ├── gtnh_items.yaml             # Hand-maintained item overrides / corrections / extra tags
│   ├── gtnh_recipes.agent.json     # Recipes compressed / transformed for agent reasoning (post-processing)
│   ├── gtnh_recipes.generated.json # Raw-ish recipes generated from GTNH data ingestion scripts
│   ├── gtnh_recipes.json           # Canonical recipe dataset the semantics/skills use at runtime
│   ├── gtnh_tech_graph.yaml        # Tech progression DAG: tiers, unlock dependencies, and milestones
│   ├── hardware.yaml               # Local hardware profile: GPU/CPU, VRAM, concurrency limits, etc.
│   ├── llm_roles.yaml              # Role presets and prompt templates for different LLM personas (planner, scribe, critic)
│   ├── minecraft.yaml              # Minecraft instance configuration: save paths, version, launch profile metadata
│   ├── models.yaml                 # LLM model catalog: local engines, quantizations, temperatures, usage per role
│   ├── raw                         # Raw GTNH export data before normalization
│   │   ├── block.csv               # Raw block list from GTNH data dumper
│   │   ├── item.csv                # Raw item list from GTNH data dumper
│   │   ├── recipes.json            # Raw crafting/machine recipes straight from GTNH exports
│   │   └── recipes_stacks.json     # Variant of recipes including stack size / quantity metadata
│   ├── skill_packs                 # Bundles of skills grouped by progression / domain
│   │   ├── lv_core.yaml            # LV-tier core skill pack (early GTNH automation repertoire)
│   │   └── steam_age.yaml          # Steam-age skill pack (pre-LV, boilers, coke ovens, etc.)
│   ├── skills                      # Declarative skill specs (YAML) mirrored by Python skill implementations
│   │   ├── basic_crafting.yaml     # Logical description of the basic_crafting skill
│   │   ├── chop_tree.yaml          # Logical description of the chop_tree skill
│   │   ├── feed_coke_ovens.yaml    # Logical description of the feed_coke_ovens skill
│   │   ├── feed_steam_boiler.yaml  # Logical description of the feed_steam_boiler skill
│   │   ├── maintain_coke_ovens.yaml# Logical description of the maintain_coke_ovens skill
│   │   ├── plant_sapling.yaml      # Logical description of the plant_sapling skill
│   │   └── refill_water_tanks.yaml # Logical description of the refill_water_tanks skill
│   ├── skills_candidates           # Staging area for new/experimental skills before promotion to main skill set
│   ├── tools                       # Config-related utility scripts
│   │   ├── print_env.py            # Helper to load & pretty-print environment config for debugging
│   │   └── validate_env.py         # Sanity checks for env/hardware/model config; test harness for M0/M1
│   └── virtues.yaml                # Kabbalistic virtue lattice configuration (values, weights, mappings)
├── docs                            # Human-facing documentation for architecture, modules, and integration
│   ├── architecture.md             # High-level architecture overview of the agent’s phases/modules
│   ├── ipc_protocol_m6.md          # IPC protocol spec between Forge mod / external client and bot_core (M6)
│   ├── m6_bot_core_1_7_10.md       # Detailed design & public API reference for M6 bot_core
│   └── phase1_integration.md       # Documentation for Phase 1 (offline integration of LLM/semantics/skills)
├── .github                         # GitHub-related CI/CD configuration
│   └── workflows
│       └── ci.yml                  # CI pipeline config (pytest, lint, etc.) for this repo
├── .gitignore                      # Ignore rules for git (venv, cache, compiled artifacts, etc.)
├── logs                            # Runtime logs (mostly LLM stack traces, plans, and summaries)
│   └── llm                         # LLM-specific log outputs for error_model / planner / scribe
│       ├── 20251127T154508_30389_error_model_analyze_failure.json  # Error-model analysis for a failing run
│       ├── 20251127T154508_30389_plan_code_plan.json              # Planner output (plan_code) for same run
│       ├── 20251127T154508_30389_scribe_summarize_trace.json      # Scribe’s summary of that run’s trace
│       ├── 20251127T154653_30421_plan_code_plan.json              # Planner output for a later run
│       ├── 20251127T154929_30485_error_model_analyze_failure.json # Error-model analysis for another failure
│       ├── 20251127T155054_30542_scribe_summarize_trace.json      # Scribe summary of that trace
│       ├── 20251127T171641_54578_plan_code_plan.json              # Planner log (phase1 / offline)
│       ├── 20251127T172238_54966_plan_code_plan.json              # Planner log
│       ├── 20251127T172404_55071_plan_code_plan.json              # Planner log
│       ├── 20251127T181107_57121_plan_code_plan.json              # Planner log
│       ├── 20251127T181432_57416_plan_code_plan.json              # Planner log
│       ├── 20251127T202123_80866_error_model_analyze_failure.json # Error-model analysis
│       ├── 20251127T202123_80866_plan_code_plan.json              # Planner log
│       ├── 20251127T202123_80866_scribe_summarize_trace.json      # Scribe summary
│       ├── 20251127T202334_80953_error_model_analyze_failure.json # Error-model analysis
│       ├── 20251127T202334_80953_plan_code_plan.json              # Planner log
│       ├── 20251127T202334_80953_scribe_summarize_trace.json      # Scribe summary
│       ├── 20251127T223951_107281_error_model_analyze_failure.json# Error-model analysis
│       ├── 20251127T223951_107281_plan_code_plan.json             # Planner log
│       ├── 20251127T223951_107281_scribe_summarize_trace.json     # Scribe summary
│       ├── 20251128T001446_136742_error_model_analyze_failure.json# Error-model analysis
│       ├── 20251128T001446_136742_plan_code_plan.json             # Planner log
│       ├── 20251128T001446_136742_scribe_summarize_trace.json     # Scribe summary
│       ├── 20251128T003700_146815_error_model_analyze_failure.json# Error-model analysis
│       ├── 20251128T003700_146815_plan_code_plan.json             # Planner log
│       ├── 20251128T003700_146815_scribe_summarize_trace.json     # Scribe summary
│       ├── 20251128T115106_24456_error_model_analyze_failure.json # Error-model analysis
│       ├── 20251128T115106_24456_plan_code_plan.json              # Planner log
│       ├── 20251128T115106_24456_scribe_summarize_trace.json      # Scribe summary
│       ├── 20251128T143640_52852_error_model_analyze_failure.json # Error-model analysis
│       ├── 20251128T143640_52852_plan_code_plan.json              # Planner log
│       ├── 20251128T143640_52852_scribe_summarize_trace.json      # Scribe summary
│       ├── 20251128T143816_52937_error_model_analyze_failure.json # Error-model analysis
│       ├── 20251128T143816_52937_plan_code_plan.json              # Planner log
│       ├── 20251128T143816_52937_scribe_summarize_trace.json      # Scribe summary
│       ├── 20251128T153451_109564_error_model_analyze_failure.json# Error-model analysis
│       ├── 20251128T153451_109564_plan_code_plan.json             # Planner log
│       ├── 20251128T153451_109564_scribe_summarize_trace.json     # Scribe summary
│       ├── 20251128T154112_109913_error_model_analyze_failure.json# Error-model analysis
│       ├── 20251128T154112_109913_plan_code_plan.json             # Planner log
│       ├── 20251128T154112_109913_scribe_summarize_trace.json     # Scribe summary
│       ├── 20251128T154622_110074_error_model_analyze_failure.json# Error-model analysis
│       ├── 20251128T154622_110074_plan_code_plan.json             # Planner log
│       ├── 20251128T154622_110074_scribe_summarize_trace.json     # Scribe summary
│       ├── 20251128T155834_129265_error_model_analyze_failure.json# Error-model analysis
│       ├── 20251128T155834_129265_plan_code_plan.json             # Planner log
│       ├── 20251128T155834_129265_scribe_summarize_trace.json     # Scribe summary
│       ├── 20251128T160155_129475_error_model_analyze_failure.json# Error-model analysis
│       ├── 20251128T160155_129475_plan_code_plan.json             # Planner log
│       ├── 20251128T160155_129475_scribe_summarize_trace.json     # Scribe summary
│       ├── 20251128T160633_142703_error_model_analyze_failure.json# Error-model analysis
│       ├── 20251128T160633_142703_plan_code_plan.json             # Planner log
│       ├── 20251128T160633_142703_scribe_summarize_trace.json     # Scribe summary
│       ├── 20251128T162316_143085_error_model_analyze_failure.json# Error-model analysis
│       ├── 20251128T162316_143085_plan_code_plan.json             # Planner log
│       ├── 20251128T162316_143085_scribe_summarize_trace.json     # Scribe summary
│       ├── 20251128T162956_163507_error_model_analyze_failure.json# Error-model analysis
│       ├── 20251128T162956_163507_plan_code_plan.json             # Planner log
│       ├── 20251128T162956_163507_scribe_summarize_trace.json     # Scribe summary
│       ├── 20251128T164527_184688_error_model_analyze_failure.json# Error-model analysis
│       ├── 20251128T164527_184688_plan_code_plan.json             # Planner log
│       ├── 20251128T164527_184688_scribe_summarize_trace.json     # Scribe summary
│       ├── 20251128T164725_184780_error_model_analyze_failure.json# Error-model analysis
│       ├── 20251128T164725_184780_plan_code_plan.json             # Planner log
│       ├── 20251128T164725_184780_scribe_summarize_trace.json     # Scribe summary
│       ├── 20251128T164846_185052_error_model_analyze_failure.json# Error-model analysis
│       ├── 20251128T164846_185052_plan_code_plan.json             # Planner log
│       ├── 20251128T164846_185052_scribe_summarize_trace.json     # Scribe summary
│       ├── 20251128T190228_210275_error_model_analyze_failure.json# Error-model analysis
│       ├── 20251128T190228_210275_plan_code_plan.json             # Planner log
│       ├── 20251128T190228_210275_scribe_summarize_trace.json     # Scribe summary
│       ├── 20251128T190457_210363_error_model_analyze_failure.json# Error-model analysis
│       ├── 20251128T190457_210363_plan_code_plan.json             # Planner log
│       ├── 20251128T190457_210363_scribe_summarize_trace.json     # Scribe summary
│       ├── 20251128T191608_225560_error_model_analyze_failure.json# Error-model analysis
│       ├── 20251128T191608_225560_plan_code_plan.json             # Planner log
│       ├── 20251128T191608_225560_scribe_summarize_trace.json     # Scribe summary
│       ├── 20251128T192046_233385_error_model_analyze_failure.json# Error-model analysis
│       ├── 20251128T192046_233385_plan_code_plan.json             # Planner log
│       ├── 20251128T192046_233385_scribe_summarize_trace.json     # Scribe summary
│       ├── 20251128T192251_233478_error_model_analyze_failure.json# Error-model analysis
│       ├── 20251128T192251_233478_plan_code_plan.json             # Planner log
│       └── 20251128T192251_233478_scribe_summarize_trace.json     # Scribe summary
├── pyproject.toml                  # Project configuration for packaging, dependencies, and tooling
├── .pytest_cache                   # Pytest’s internal cache directory (test state, lastfailed, etc.)
│   ├── CACHEDIR.TAG                # Marker file indicating a cache directory
│   ├── .gitignore                  # Local ignore rules so this cache can exist but not be versioned deeply
│   ├── README.md                   # Pytest cache directory description
│   └── v
│       └── cache
│           ├── lastfailed          # Map of tests that failed in the last run
│           └── nodeids             # List of collected test node IDs
├── .python-version                 # Python version pin for pyenv / tooling
├── README.md                       # Top-level project readme and quickstart overview
├── scripts                         # One-off helper scripts for data ingestion/testing/demos
│   ├── compact_recipes_for_agent.py    # Compress / normalize recipe data into agent-friendly format
│   ├── demo_offline_agent_step.py      # Demonstration of a single offline agent loop step (Phase 1)
│   ├── dev_shell.py                    # Convenience REPL/CLI setup for interactive development
│   ├── ingest_gtnh_semantics.py        # Pipeline to ingest GTNH data into semantics layer
│   ├── ingest_nerd_csv_semantics.py    # Import “nerd” CSV semantics (external curated data) into the system
│   ├── ingest_nerd_recipes.py          # Import external/nerd recipe datasets into canonical format
│   ├── smoke_error_model.py            # Quick smoke test for error_model LLM component
│   ├── smoke_llm_stack.py              # Smoke test for LLM stack end-to-end
│   └── smoke_scribe_model.py           # Smoke test for scribe (summarization/trace compression) model
├── src                              # Main Python package source tree
│   ├── agent_loop                   # Core agent loop logic (M8+)
│   │   ├── __init__.py              # Package marker for agent_loop
│   │   ├── loop.py                  # Main agent loop implementation (observe → plan → act)
│   │   ├── schema.py                # Typed schemas for loop configuration and state
│   │   └── state.py                 # Data structures for agent internal state across steps/episodes
│   ├── app                          # Top-level runtime wiring (entrypoints, main app harness)
│   │   ├── __init__.py              # Package marker for app
│   │   └── runtime.py               # Application runtime that wires CLI, env, agent, and monitoring
│   ├── bot_core                     # M6 body controller for Minecraft 1.7.10
│   │   ├── actions.py               # High-level actions → packets; nav + action guards
│   │   ├── collision.py             # Block collision profile and default is_solid_block implementation
│   │   ├── core.py                  # BotCoreImpl: unified interface over transport, tracker, actions, tracing
│   │   ├── __init__.py              # Package marker and convenient exports for bot_core
│   │   ├── nav                      # Navigation subsystem (NavGrid + A* + mover)
│   │   │   ├── grid.py              # NavGrid: walkability checks from RawWorldSnapshot + collision fn
│   │   │   ├── __init__.py          # Nav exports (NavGrid, Coord, find_path, path_to_actions, current_coord)
│   │   │   ├── mover.py             # Path → sequence of move_to steps for ActionExecutor
│   │   │   └── pathfinder.py        # A* implementation and pathfinding Result structs
│   │   ├── net                      # Network/IPC abstraction for talking to Minecraft
│   │   │   ├── client.py            # Base PacketClient protocol and common helpers
│   │   │   ├── external_client.py   # External full-protocol client implementation (non-Forge)
│   │   │   ├── __init__.py          # Exports for net subpackage (PacketClient, factory function)
│   │   │   └── ipc.py               # Forge mod IPC client (sockets/ZeroMQ) implementation
│   │   ├── snapshot.py              # RawWorldSnapshot type + snapshot_to_world_state adapter
│   │   ├── testing
│   │   │   └── fakes.py             # FakePacketClient and other test doubles for bot_core
│   │   ├── tracing.py               # ActionTracer and ActionTraceRecord for metrics/logging
│   │   └── world_tracker.py         # Incremental world tracker that consumes packet events
│   ├── cli                          # CLI entrypoints and command-line utilities
│   │   └── phase1_offline.py        # CLI for running Phase 1 offline agent experiments
│   ├── curriculum                   # Curriculum engine for task decomposition & scoring
│   │   ├── engine.py                # Core curriculum scheduling and unit selection logic
│   │   ├── __init__.py              # Package marker for curriculum
│   │   ├── loader.py                # Load curricula from YAML into typed structures
│   │   └── schema.py                # Dataclasses / types that represent curriculum configs
│   ├── env                          # Environment profile system (Phase 0)
│   │   ├── __init__.py              # Package marker for env
│   │   ├── loader.py                # Load/validate env.yaml & hardware.yaml into EnvProfile
│   │   └── schema.py                # EnvProfile types and validation schema
│   ├── gtnh_agent.egg-info          # Packaging metadata generated by build system
│   │   ├── dependency_links.txt     # Dependencies metadata for the built package
│   │   ├── PKG-INFO                 # Package metadata (name, version, description) generated by build
│   │   ├── requires.txt             # Python dependencies required by this package
│   │   ├── SOURCES.txt              # List of source files included in the distribution
│   │   └── top_level.txt            # Top-level package names exposed by the distribution
│   ├── __init__.py                  # Root package marker for `gtnh_agent` Python package
│   ├── integration                  # Glue code connecting phases and subsystems for Phase 1
│   │   ├── adapters
│   │   │   └── m0_env_to_world.py   # Adapter that bridges env profiles to world/observation config
│   │   ├── episode_logging.py       # High-level episode logging utilities (across the agent loop)
│   │   ├── __init__.py              # Package marker for integration
│   │   ├── phase1_integration.py    # Coordination of semantics, skills, LLM stack, and bot_core offline
│   │   ├── testing
│   │   │   ├── fakes.py             # Fakes/mocks for integration tests
│   │   │   └── __init__.py          # Package marker for integration.testing
│   │   └── validators               # Guardrail validators for plans, semantics, virtues
│   │       ├── __init__.py          # Package marker for validators
│   │       ├── planner_guardrails.py# Checks on LLM-generated plans before execution
│   │       ├── semantics_snapshots.py# Validation that semantics + world snapshots stay consistent
│   │       ├── skill_integrity.py   # Ensure skills configs & implementations stay sane
│   │       └── virtue_snapshots.py  # Snapshot and validate virtue scoring consistency
│   ├── learning                     # Experience/learning layer (M10-ish)
│   │   ├── buffer.py                # Replay buffer / experience storage
│   │   ├── evaluator.py             # Evaluation routines for skills/plans across episodes
│   │   ├── __init__.py              # Package marker for learning
│   │   ├── manager.py               # High-level coordination of learning lifecycle
│   │   ├── schema.py                # Typed schemas for experience records and learning configs
│   │   └── synthesizer.py           # Synthetic data / trace generator for training and augmentation
│   ├── llm_stack                    # M2: LLM orchestration stack (planner, critic, scribe, backend)
│   │   ├── backend_llamacpp.py      # llama.cpp backend integration for local models
│   │   ├── backend.py               # Backend protocol abstraction for LLM engines
│   │   ├── codegen.py               # Code generation utilities / helpers
│   │   ├── config.py                # LLM stack configuration loader/merger
│   │   ├── critic.py                # Critic model wrapper (reviewing plans, code, etc.)
│   │   ├── error_model.py           # Error-model predicting failures and analyzing traces
│   │   ├── __init__.py              # Package marker & exports for llm_stack
│   │   ├── json_utils.py            # JSON parsing/validation helpers for robust LLM I/O
│   │   ├── log_files.py             # Logging helpers for LLM stack runs (plan, error, scribe logs)
│   │   ├── plan_code.py             # Planning + code-writing orchestrator
│   │   ├── planner.py               # Thin wrapper around planning LLM calls
│   │   ├── presets.py               # Prompt presets for planning/critique/scribe roles
│   │   ├── schema.py                # Typed models for LLM requests/responses
│   │   ├── scribe.py                # Summarization / trace compression LLM wrapper
│   │   └── stack.py                 # Full stack orchestrator (backend + roles + logging)
│   ├── monitoring                   # Monitoring bus & visualization tools (M9-ish)
│   │   ├── bus.py                   # Event bus for monitoring events
│   │   ├── controller.py            # Control plane for monitoring the running agent
│   │   ├── dashboard_tui.py         # Text-based dashboard for agent metrics
│   │   ├── events.py                # Event types used in monitoring subsystem
│   │   ├── __init__.py              # Package marker for monitoring
│   │   └── logger.py                # Structured logging helpers for monitoring
│   ├── observation                  # Observation encoding & schema (how world becomes LLM input)
│   │   ├── encoder.py               # Encodes WorldState/trace into LLM-friendly formats
│   │   ├── __init__.py              # Package marker for observation
│   │   ├── schema.py                # Observation schema seen by planner/critic
│   │   └── trace_schema.py          # Schemas for multi-step traces / episode logs
│   ├── semantics                    # M3: world semantics & tech-aware reasoning over GTNH
│   │   ├── cache.py                 # Semantics cache for fast queries
│   │   ├── categorize.py            # Item/block categorization (e.g. “fuel”, “wood”, “ore”)
│   │   ├── crafting.py              # Craftability logic and recipe reasoning
│   │   ├── ingest
│   │   │   └── __init__.py          # Package marker for semantics.ingest
│   │   ├── __init__.py              # Package marker for semantics
│   │   ├── loader.py                # Load/generate semantics from raw GTNH data files
│   │   ├── schema.py                # Typed structures for semantics entities & graphs
│   │   └── tech_state.py            # Tech tier inference and progression state logic
│   ├── skills                       # Skill system (declarative configs + Python implementations)
│   │   ├── base                     # Core skills matching config/skills/*.yaml
│   │   │   ├── basic_crafting.py    # Implementation of basic_crafting skill
│   │   │   ├── chop_tree.py         # Implementation of chop_tree skill
│   │   │   ├── feed_coke_ovens.py   # Implementation of feed_coke_ovens skill
│   │   │   ├── feed_steam_boiler.py # Implementation of feed_steam_boiler skill
│   │   │   ├── __init__.py          # Package marker for base skills
│   │   │   ├── maintain_coke_ovens.py# Implementation of maintain_coke_ovens skill
│   │   │   ├── plant_sapling.py     # Implementation of plant_sapling skill
│   │   │   └── refill_water_tanks.py# Implementation of refill_water_tanks skill
│   │   ├── __init__.py              # Package marker & exports for skills
│   │   ├── loader.py                # Load skills from YAML into Python skill objects
│   │   ├── packs.py                 # Logic for loading/combining skill packs
│   │   ├── registry.py              # Central registry of all skills available to the agent
│   │   └── schema.py                # Typed schemas for skills and parameters
│   ├── spec                         # Stable “interfaces” for cross-module contracts
│   │   ├── agent_loop.py            # Agent loop spec (what higher-level code expects)
│   │   ├── bot_core.py              # BotCore interface definition (implemented by BotCoreImpl)
│   │   ├── experience.py            # Spec for experience records used by learning layer
│   │   ├── __init__.py              # Package marker for spec
│   │   ├── llm.py                   # LLM stack interfaces for backends and roles
│   │   ├── skills.py                # Skill interface contracts (inputs/outputs/error semantics)
│   │   └── types.py                 # Shared foundational types (Action, ActionResult, WorldState, etc.)
│   ├── testing                      # Shared test utilities/helpers
│   │   └── __init__.py              # Package marker for testing utilities
│   └── virtues                      # Virtue lattice system & metrics (alignment layer)
│       ├── explain.py               # Pretty-print / explain virtue scores and decisions
│       ├── features.py              # Feature extraction functions feeding virtue evaluation
│       ├── __init__.py              # Package marker for virtues
│       ├── lattice.py               # Core virtue lattice logic (tree of Sefirot + scoring)
│       ├── loader.py                # Load virtue config (virtues.yaml) into typed structures
│       ├── metrics.py               # Virtue-related metrics and scoring outputs
│       ├── sanity.py                # Sanity checks for virtue configuration and behavior
│       └── schema.py                # Typed definitions for virtues, constraints, lattice edges
├── tests                           # Full pytest suite covering all phases and subsystems
│   ├── conftest.py                 # Pytest fixtures and shared test configuration
│   ├── fakes                       # Shared test doubles for high-level tests
│   │   ├── fake_bot_core.py        # Fake BotCore for tests that don’t need real M6
│   │   ├── fake_llm_stack.py       # Fake LLM stack used in integration tests
│   │   ├── fake_skills.py          # Fake skills for testing pipelines without real skill code
│   │   └── __init__.py             # Package marker for tests.fakes
│   ├── __init__.py                 # Package marker for tests
│   ├── test_actions.py             # Unit tests for ActionExecutor behavior and packets
│   ├── test_agent_loop_v1.py       # Tests for agent loop logic (M8)
│   ├── test_architecture_integration.py # High-level architectural integration tests
│   ├── test_bot_core_impl.py       # End-to-end tests for BotCoreImpl with fakes
│   ├── test_env_loader.py          # Tests for env.loader behavior and validation
│   ├── test_error_model_with_fake_backend.py # Error-model tests using fake backend
│   ├── test_llm_stack_fake_backend.py       # LLM stack tests with fake backend
│   ├── test_nav_pathfinder.py      # A* pathfinding tests (walls, obstacles, failure modes)
│   ├── test_observation_critic_encoding.py  # Critic observation encoding tests
│   ├── test_observation_planner_encoding.py # Planner observation encoding tests
│   ├── test_observation_worldstate_normalization.py # WorldState normalization tests
│   ├── test_p0_p1_env_bridge.py    # Bridge tests between Phase 0 envs and Phase 1 runtime
│   ├── test_phase0_runtime.py      # Tests for Phase 0 runtime behavior
│   ├── test_phase1_breakglass_no_plans.py   # Safety behavior when no valid plans are produced
│   ├── test_phase1_integration_offline.py   # Offline integration tests for Phase 1 stack
│   ├── test_scribe_model_with_fake_backend.py# Scribe model tests with fake backend
│   ├── test_semantics_caching_singleton.py  # Semantics cache singleton behavior tests
│   ├── test_semantics_categorization.py     # Item/block categorization tests
│   ├── test_semantics_craftability.py       # Craftability & recipe reasoning tests
│   ├── test_semantics_tech_inference.py     # Tech progression/tech-state inference tests
│   ├── test_semantics_tolerant_fallbacks.py # Tolerant semantics behavior when data is missing
│   ├── test_semantics_with_normalized_worldstate.py # Semantics integrated with WorldState
│   ├── test_skill_loader.py        # Skill loader tests (YAML → Python)
│   ├── test_skill_packs_integrity.py# Integrity tests for skill pack definitions
│   ├── test_skill_packs.py         # Behavior tests for skill packs logic
│   ├── test_skill_registry.py      # Registry behavior and skill lookups
│   ├── test_virtue_compare_plans.py# Compare plans using virtue metrics tests
│   ├── test_virtue_config_sanity.py# Sanity tests for virtue configuration
│   ├── test_virtue_hard_constraints.py# Tests for hard virtue constraints
│   ├── test_virtue_lattice_basic.py# Basic lattice structure behavior tests
│   └── test_world_tracker.py       # Tests for WorldTracker event handling and snapshot building
└── tools                          # Top-level dev/demo utilities
    ├── phase1_demo.py             # Simple demo script for running Phase 1 in a “showcase” mode
    └── smoke_botcore.py           # M6 smoke test harness using FakePacketClient or real IPC

```

## 1. Big Picture: What This Thing Is

**Goal:**  
A fully local, LLM-driven Minecraft agent specialized for **GregTech: New Horizons (GTNH)** that:

- Understands the world as **data + semantics**
    
- Operates via a **body controller (M6 bot_core)**
    
- Chooses and executes **skills** under a **virtue-guided curriculum**
    

You’re basically building a Minecraft-specific cognitive architecture with:

- **Perception:** env configs, world tracker, semantics, observation encoding
    
- **Body:** bot_core (M6) + navigation + IPC
    
- **Mind:** LLM stack, planner, critic, scribe, virtues, curriculum, skills
    
- **Meta:** monitoring, learning, replay buffers
    

M6 just finished turning “we should make the bot move” into “the bot moves, logs, and is testable.”

---

## 2. Phase / Module Status (High Level)

Very rough mental map:

- **M0 – environment_foundation:**
    
    - `config/env.yaml`, `hardware.yaml`, `minecraft.yaml`, `models.yaml`
        
    - `env.loader` + `validate_env.py`
        
    - Result: you can load a sane **EnvProfile** and hardware/model constraints.
        
- **M1 – shared types & specs (distributed across `spec/*`):**
    
    - Core types: `Action`, `ActionResult`, `WorldState`, `RawWorldSnapshot`, `BotCore`, etc.
        
    - This is the **contract layer** all modules speak.
        
- **M2 – llm_stack:**
    
    - `llm_stack/backend*.py`, `stack.py`, `planner.py`, `critic.py`, `scribe.py`, `error_model.py`
        
    - Operates on **structured schemas** and logs all of it into `logs/llm/*.json`.
        
    - Result: you have a configurable, local LLM pipeline with planning, critiquing, and summarization.
        
- **M3 – semantics:**
    
    - GTNH data ingestion: `config/raw/*`, `scripts/ingest_*`, `semantics/loader.py`
        
    - Semantic graph: `gtnh_items*.yaml`, `gtnh_blocks*.yaml`, `gtnh_recipes*.json`, `gtnh_tech_graph.yaml`
        
    - Logic: `semantics/categorize.py`, `crafting.py`, `tech_state.py`, `cache.py`
        
    - Result: stable GTNH-aware world model: items, blocks, recipes, tech tiers.
        
- **M4/M5 – observation & integration groundwork:**
    
    - `observation/*` – encoders & schemas for planner / critic input
        
    - `integration/*` – offline Phase 1 integration + validators
        
    - `virtues/*` – virtue lattice, scoring, sanity checks
        
    - `curriculum/*` – curricula, engine, schema
        
    - `skills/*` + `config/skills*, skill_packs` – skill layer definitions & implementations
        
- **M6 – bot_core_1_7_10 (NEW & DONE):**
    
    - `bot_core/*`, `docs/m6_bot_core_1_7_10.md`, `tools/smoke_botcore.py`
        
    - Result: a concrete, tested “body controller” that:
        
        - Talks to the world via **PacketClient / Forge IPC**
            
        - Tracks **RawWorldSnapshot**
            
        - Produces **WorldState**
            
        - Executes **Actions** with **nav, guards, and tracing**
            

M7 will build on all of that, likely tightening **online integration** between M2/M3/M4/M6/skills.

---

## 3. Core Definitions (You Actually Use These)

### EnvProfile & Runtime Config (M0/M1)

From `env/loader.py` & `config/env.yaml`:

- Defines:
    
    - `bot_mode` (e.g. `forge_mod`)
        
    - Minecraft profile & directory paths
        
    - Model profiles & hardware constraints
        
- Used by:
    
    - `BotCoreImpl` to choose connection mode
        
    - `llm_stack` to pick models/backends
        
    - Scripts/tools to select runtime context
        

### RawWorldSnapshot (M6)

From `bot_core.snapshot`:

Minimal raw view of the world, built by `WorldTracker`:

- `tick: int`
    
- `dimension: str`
    
- `player_pos: {x, y, z}`
    
- `player_yaw: float`
    
- `player_pitch: float`
    
- `on_ground: bool`
    
- `chunks: {(cx, cz) -> RawChunk}` (currently thin)
    
- `entities: [RawEntity]`
    
- `inventory: [...]`
    
- `context: {env_profile_name, bot_mode, ...}`
    

**Rules:**

- No semantics, no tech, no virtue logic here.
    
- Incrementally maintained by packet events only.
    

### WorldState (M1/M3/M6 bridge)

From `spec.types` + `snapshot_to_world_state`:

- Semantic, agent-friendly view:
    
    - `tick`
        
    - `position {x,y,z}`
        
    - `dimension`
        
    - `inventory`
        
    - `nearby_entities`
        
    - `blocks_of_interest`
        
    - `tech_state`
        
    - `context`
        

Built from `RawWorldSnapshot` and enriched by semantics & adapters.

### Action & ActionResult

From `spec.types`:

- `Action`:
    
    - `type: str` (e.g. `"move_to"`, `"break_block"`)
        
    - `params: dict[str, Any]`
        
- `ActionResult`:
    
    - `success: bool`
        
    - `error: Optional[str]`
        
    - `details: dict[str, Any]`
        

**M6 guarantees** that `execute_action` always returns a well-formed `ActionResult`.

---

## 4. M6 – Bot Core: What It Guarantees

### BotCoreImpl (src/bot_core/core.py)

Public API:

- `connect()`: uses `EnvProfile` to set up IPC/transport
    
- `disconnect()`
    
- `tick()`: pump client, feed `WorldTracker`
    
- `observe() -> RawWorldSnapshot`
    
- `get_world_state() -> WorldState`
    
- `execute_action(Action) -> ActionResult`
    
- `get_action_traces() -> list[ActionTraceRecord]`
    

Error channel:

- **Connection / transport / tick failures** → `BotCoreError(code, details)`
    
- **Action-level failures** → `ActionResult.success=False, error="..."`
    

### Transport / IPC

- Uses `PacketClient` abstraction:
    
    - `connect`, `disconnect`, `tick`, `send_packet`, `on_packet`
        
- Two conceptual modes (env-driven):
    
    1. `external_client` (full protocol client)
        
    2. `forge_mod` (IPC over sockets/ZeroMQ)
        

You chose **Forge mod IPC** for the real thing, but tests/smoke harness use `FakePacketClient`.

### World Tracking

`WorldTracker` subscribes to normalized events:

- `time_update`
    
- `position_update`
    
- `chunk_data`
    
- `spawn_entity` / `destroy_entities`
    
- `window_items` / `set_slot`
    

It:

- Maintains incremental internal state
    
- Builds `RawWorldSnapshot` on demand
    
- Never creates `WorldState` itself
    
- Never embeds semantics
    

### Navigation & Collision

`bot_core.nav`:

- `NavGrid(snapshot, is_solid_block)`
    
- A* search (`find_path`) with:
    
    - Manhattan heuristic
        
    - 4-direction neighbors
        
    - `max_steps` guard
        
- `mover.py` converts paths → `move_step` actions.
    

Collision:

- `BlockSolidFn(x, y, z, snapshot) -> bool`
    
- Current default: **flat-floor hack** via `BlockCollisionProfile`:
    
    - “air” above a default Y is walkable
        
    - everything below treated as solid
        

Hook point:

- You can inject a real `is_solid_block` using M3 semantics later:'
python:
```
bot = BotCoreImpl(is_solid_block=gtnh_is_solid_block)

```

### ActionExecutor

Supports:

- `"move_to"`
    
- `"break_block"`
    
- `"place_block"`
    
- `"use_item"`
    
- `"interact"`
    

Config (`ActionExecutorConfig`):

- `max_nav_steps`
    
- `default_move_radius`
    
- `max_move_steps`
    
- `max_move_duration_s`
    
- `max_dig_duration_s` (future async dig)
    

Error codes:

- `"invalid_params"`
    
- `"unsupported_action"`
    
- `"nav_failure"`
    
- `"nav_too_long"` (path too long for single action)
    
- `"move_timeout"` (runtime guard while sending steps)
    
- `"io_error"`
    
- `"execution_exception"`
    
- `"botcore_execute_exception"`
    
- `"invalid_executor_result"`
    

All of these bubble up via `ActionResult.error`.

### Tracing & Logging

`bot_core.tracing.ActionTracer`:

Each `execute_action` produces an `ActionTraceRecord`:

- `timestamp`
    
- `duration_s`
    
- `action_type`
    
- `params` (shallow copy)
    
- `success`
    
- `error`
    
- `tick`, `dimension`
    
- `position {x,y,z}`
    

Also logs a structured one-line summary via logger `bot_core.action`.

These traces are the future food for:

- M9 monitoring
    
- M10 learning / replay buffer
    
- Debugging when the bot acts drunk
    

### Smoke Harness

`tools/smoke_botcore.py`:

- `--mode fake`:
    
    - Uses `FakePacketClient`
        
    - Emits a couple fake packets
        
    - Calls:
        
        - `observe()`
            
        - `get_world_state()`
            
        - `execute_action(move_to)`
            
        - `execute_action(break_block)`
            
    - Prints snapshots, results, and sent packets
        
- `--mode real` stub is ready to use once Forge IPC server is running.
    

You ran fake mode. It passed. The body is alive.

---

## 5. Other Subsystems That Matter for M7

You’ve also quietly built a lot of infrastructure M7 will lean on:

- **Semantics (`semantics/*`)**
    
    - Complete GTNH item/block/recipe/tech graph.
        
    - Cached, test-covered, and already normalized.
        
- **Skills (`skills/*` + `config/skills*.yaml`)**
    
    - Base skills implemented in Python with matching YAML definitions.
        
    - Skill packs for Steam Age / LV progression.
        
    - Registry, loader, and schema all tested.
        
- **Virtues (`virtues/*`, `config/virtues.yaml`)**
    
    - Virtue lattice implemented with metrics & sanity checks.
        
    - Can score plans / actions on alignment with your value system.
        
- **Curriculum (`curriculum/*`, `config/curricula/*`)**
    
    - Abstract curriculum engine + specific GTNH curricula configured.
        
- **Observation (`observation/*`)**
    
    - Encoders + schemas for turning `WorldState`/traces into LLM inputs.
        
    - This is the bridge between “raw world” and “planner sees something structured.”
        
- **LLM stack (`llm_stack/*`)**
    
    - Fully modular local stack with:
        
        - Multiple roles (planner, critic, scribe, error model)
            
        - Presets, backends, logging, schemas
            
    - Everything logs into JSON so you can replay/debug.
        
- **Integration (`integration/*`)**
    
    - Offline Phase 1 integration (no bot_core required) is already scaffolded.
        
    - Validators for plans, semantics, skills, virtues.
        

When M7 shows up, it is not starting from scratch. It’s landing in a mostly-built city.

---

## 6. Important Design Decisions (That M7 Must Respect)

Here’s where the real constraints are:

1. **Connection mode:**
    
    - Chosen: **Forge mod IPC** (`bot_mode: forge_mod`).
        
    - Implication: M7 should treat Minecraft as “things happen via `BotCoreImpl`” and not care if it’s IPC or protocol.
        
2. **Action granularity:**
    
    - Chosen: **high-level atomic-ish actions** (`move_to`, `break_block`, etc.).
        
    - Implication: M7’s planner/skills reason in terms of these actions, not raw packets or single-step movements.
        
3. **Nav ownership:**
    
    - Chosen: **Python nav** (NavGrid/A* in M6).
        
    - Implication: M7 must let M6 handle low-level navigation and treat `"nav_failure" / "nav_too_long" / "move_timeout"` as **signals for re-planning**, not try to micro-control movement.
        
4. **Pacing:**
    
    - Chosen: **One `execute_action` per whole operation.**
        
    - Implication: The agent loop in M7/M8 should think in discrete “Action episodes,” not nibble-sized partial moves.
        
5. **Failure semantics:**
    
    - Chosen: **explicit, structured failures via `ActionResult.error`.**
        
    - Implication: M7 must:
        
        - Always inspect `ActionResult`
            
        - Branch on these error codes
            
        - Never assume an action succeeded unless `success=True`.
            
6. **Semantic boundary for M6:**
    
    - Chosen: M6 is intentionally **thin**:
        
        - No tech semantics
            
        - No virtue scoring
            
        - No skill logic
            
    - Implication: M7 is where semantic-aware decision-making starts to matter live; M6 doesn’t know or care what a Coke Oven is.
        

---

## 7. What M7 Should Do (Guided by All This)

You didn’t explicitly define M7 yet, but given the state of the repo, M7 is naturally the “**online control & observation glue**” between:

- `BotCoreImpl` (body)
    
- `WorldState` / `RawWorldSnapshot`
    
- `observation.encoder` (what LLM sees)
    
- `llm_stack` (planner/critic/scribe/error_model)
    
- `skills` & `virtues` & `curriculum`
    

So, for M7, you probably want to:

### 7.1 Define a Clean “Control Surface” over BotCore

Something like:

- `BotRuntime` or `ControlLoop` that:
    
    - Calls `bot.tick()`
        
    - Fetches `WorldState`
        
    - Executes **one Action or one Skill step** per loop
        
    - Returns:
        
        - Updated `WorldState`
            
        - `ActionResult`
            
        - Trace slice for observation/learning
            

### 7.2 Standardize Observation Packets to Planner

Use `observation.encoder`:

- Input:
    
    - `WorldState`
        
    - Recent `ActionTraceRecord`s
        
    - Optional curriculum/virtue context
        
- Output:
    
    - A structured “observation bundle” fed into planner/critic.
        

M7 should define **one canonical function** like:
python:
```
encode_observation(world_state, recent_traces, tech_state, curriculum_state) -> Observation

```

### 7.3 Finalize Error Handling Policy

M7 should **codify** how each `ActionResult.error` feeds into planning:

Examples:

- `"nav_failure"` → “replan with different goal / try alternative route”
    
- `"nav_too_long"` → “split task, choose intermediate waypoint”
    
- `"move_timeout"` → “backoff + re-evaluate world (lag / obstruction)”
    
- `"io_error"` / `"botcore_execute_exception"` → “panic mode / abort episode”
    

Write this as a **small table** in M7 docs so future-you doesn’t guess.

### 7.4 Decide Skill Granularity vs Action Granularity

Skills bridge LLM → bot_core.

For M7, decide:

- Does a **Skill**:
    
    - Execute **one** `Action` per invocation?
        
    - Or manage a **small sequence** (e.g. “chop_tree” = move → break_block → collect)?
        

Given M6’s design, your life is easier if:

- Skills are **small finite action programs** over `BotCoreImpl`
    
- Planner operates at **skill level**, not individual `Action`s most of the time
    

### 7.5 Wire Tracing into Learning / Monitoring Paths

M7 should:

- Pull from `bot.get_action_traces()` or subscribe to events
    
- Convert them into:
    
    - Monitoring events for M9
        
    - Experience records for M10 (`learning/buffer.py`)
        

You already built enough infrastructure that this is “just wiring,” not research.

---

## 8. TL;DR for M7

If future-you reads nothing else:

- **M6 is stable.**
    
    - Don’t mess with bot_core APIs unless you enjoy chasing breakage across half the repo.
        
- Use:
    
    - `BotCoreImpl` as the **only** interface to the body.
        
    - `WorldState` as your **default perception** object.
        
    - `ActionResult.error` as your **ground truth for failure modes**.
        
- Treat nav/collision as **M6-internal**, with only one hook:
    
    - `is_solid_block(x, y, z, snapshot) -> bool`
        
- Lean on `observation/*`, `semantics/*`, `skills/*`, `virtues/*`, `curriculum/*`, `llm_stack/*` instead of inventing more glue hacks.
    
- Design M7 as:
    
    - The first serious **online coordination layer** that speaks:
        
        - World → Observation → LLM → Plan → Skill/Action → BotCore → Trace
            

You’ve basically built the skeleton and the nervous system.  
M7 is where you start teaching the thing to behave like something other than a drunk Roomba.